{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neutral Machine Translation English to French Attention Model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNUrjotL4n8beoWRhfUN5Pi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/truong2710-cyber/NMT-LSTM-Attention-Model/blob/main/Neutral_Machine_Translation_English_to_French_Attention_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0G8PEfRiM4iY",
        "outputId": "602c2940-4a6b-419d-fe31-c0c2d2df30f9"
      },
      "source": [
        "pip show tensorflow\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.0.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: grpcio, astor, protobuf, termcolor, wheel, opt-einsum, gast, absl-py, numpy, wrapt, keras-preprocessing, six, google-pasta, tensorflow-estimator, keras-applications, tensorboard\n",
            "Required-by: kapre\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8BlgsRBM7Ce",
        "outputId": "87b56fb3-d209-4176-acde-6f4bb79f8080"
      },
      "source": [
        "!pip uninstall tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.0.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.0.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow_core/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSO1We1XNK0B",
        "outputId": "fb6059dc-efe1-4dc9-f881-e56a7e396e7f"
      },
      "source": [
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0\n",
            "  Using cached https://files.pythonhosted.org/packages/2a/5c/f1d66de5dde6f3ff528f6ea1fd0757a0e594d17debb3ec7f82daa967ea9a/tensorflow-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (3.12.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (2.0.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (3.3.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (2.0.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.34.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (0.36.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (0.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0) (57.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.31.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.23.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==2.0.0) (1.5.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.7.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.8)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.4.1)\n",
            "Installing collected packages: tensorflow\n",
            "Successfully installed tensorflow-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YybTux8vNYte",
        "outputId": "674b786c-a7d6-4737-8ec1-ccef2536349b"
      },
      "source": [
        "pip show tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.0.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: numpy, six, absl-py, tensorflow-estimator, google-pasta, termcolor, wheel, protobuf, tensorboard, astor, keras-applications, wrapt, opt-einsum, keras-preprocessing, grpcio, gast\n",
            "Required-by: kapre\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_lI8NARNzCo",
        "outputId": "76f758d2-9875-4db2-b630-4871ee2be9d1"
      },
      "source": [
        "pip install d2l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: d2l in /usr/local/lib/python3.7/dist-packages (0.16.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from d2l) (1.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from d2l) (2.23.0)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from d2l) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from d2l) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from d2l) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->d2l) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->d2l) (2018.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->d2l) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->d2l) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->d2l) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->d2l) (2021.5.30)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (5.2.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (7.6.3)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (4.10.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (5.6.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (5.1.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (5.3.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->d2l) (1.15.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->d2l) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->d2l) (1.0.18)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->d2l) (5.3.5)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->d2l) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l) (5.1.3)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l) (5.0.5)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l) (1.0.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l) (5.1.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (4.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (1.4.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (0.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (0.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (3.3.0)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (2.11.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (0.7.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->d2l) (0.2.0)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->d2l) (22.1.0)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->d2l) (1.9.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l) (1.5.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l) (0.10.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->d2l) (0.2.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->d2l) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->d2l) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->d2l) (57.0.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->d2l) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->d2l) (4.8.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->d2l) (2.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->d2l) (20.9)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->d2l) (0.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.4->nbconvert->jupyter->d2l) (2.0.1)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->d2l) (0.7.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx1ps8FpNsqu"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from d2l import tensorflow as d2l\n",
        "from tensorflow.keras.layers import Dense, RepeatVector, Activation, Bidirectional, BatchNormalization, LSTM, Concatenate,Dot,Softmax,Input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STXuuRy6Nugy",
        "outputId": "06678f41-c7f6-407c-cdca-6260ac1ef34b"
      },
      "source": [
        "#@save\n",
        "d2l.DATA_HUB['fra-eng'] = (d2l.DATA_URL + 'fra-eng.zip',\n",
        "                           '94646ad1522d915e7b0f9296181140edcf86a4f5')\n",
        "\n",
        "#@save\n",
        "def read_data_nmt():\n",
        "    \"\"\"Load the English-French dataset.\"\"\"\n",
        "    data_dir = d2l.download_extract('fra-eng')\n",
        "    with open(os.path.join(data_dir, 'fra.txt'), 'r') as f:\n",
        "        return f.read()\n",
        "\n",
        "raw_text = read_data_nmt()\n",
        "print(raw_text[:75])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go.\tVa !\n",
            "Hi.\tSalut !\n",
            "Run!\tCours !\n",
            "Run!\tCourez !\n",
            "Who?\tQui ?\n",
            "Wow!\tÇa alors !\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMSTuirlNwCT",
        "outputId": "0f3bea8b-63be-4265-dbeb-4e5d9f31e59d"
      },
      "source": [
        "#@save\n",
        "def preprocess_nmt(text):\n",
        "    \"\"\"Preprocess the English-French dataset.\"\"\"\n",
        "    def no_space(char, prev_char):\n",
        "        return char in set(',.!?') and prev_char != ' '\n",
        "\n",
        "    # Replace non-breaking space with space, and convert uppercase letters to\n",
        "    # lowercase ones\n",
        "    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower()\n",
        "    # Insert space between words and punctuation marks\n",
        "    out = [\n",
        "        ' ' + char if i > 0 and no_space(char, text[i - 1]) else char\n",
        "        for i, char in enumerate(text)]\n",
        "    return ''.join(out)\n",
        "\n",
        "text = preprocess_nmt(raw_text)\n",
        "print(text[:80])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "go .\tva !\n",
            "hi .\tsalut !\n",
            "run !\tcours !\n",
            "run !\tcourez !\n",
            "who ?\tqui ?\n",
            "wow !\tça alors !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvo0wLhkN6ll",
        "outputId": "8948e51b-3e67-41de-ead6-e692097d60df"
      },
      "source": [
        "#@save\n",
        "def tokenize_nmt(text, num_examples=None):\n",
        "    \"\"\"Tokenize the English-French dataset.\"\"\"\n",
        "    source, target = [], []\n",
        "    for i, line in enumerate(text.split('\\n')):\n",
        "        if num_examples and i > num_examples:\n",
        "            break\n",
        "        parts = line.split('\\t')\n",
        "        if len(parts) == 2:\n",
        "            source.append(parts[0].split(' '))\n",
        "            target.append(parts[1].split(' '))\n",
        "    return source, target\n",
        "\n",
        "source, target = tokenize_nmt(text)\n",
        "print(len(source))\n",
        "source[:6], target[:6]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "167130\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([['go', '.'],\n",
              "  ['hi', '.'],\n",
              "  ['run', '!'],\n",
              "  ['run', '!'],\n",
              "  ['who', '?'],\n",
              "  ['wow', '!']],\n",
              " [['va', '!'],\n",
              "  ['salut', '!'],\n",
              "  ['cours', '!'],\n",
              "  ['courez', '!'],\n",
              "  ['qui', '?'],\n",
              "  ['ça', 'alors', '!']])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "TZ23ZffEN9Fd",
        "outputId": "bfc9042f-8b64-4877-d284-8f99832fa939"
      },
      "source": [
        "d2l.set_figsize()\n",
        "_, _, patches = d2l.plt.hist([[len(l)\n",
        "                               for l in source], [len(l) for l in target]],\n",
        "                             label=['source', 'target'])\n",
        "for patch in patches[1].patches:\n",
        "    patch.set_hatch('/')\n",
        "d2l.plt.legend(loc='upper right')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f28afb45610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 252x180 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"166.978125pt\" version=\"1.1\" viewBox=\"0 0 260.642231 166.978125\" width=\"260.642231pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 166.978125 \nL 260.642231 166.978125 \nL 260.642231 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 52.375 143.1 \nL 247.675 143.1 \nL 247.675 7.2 \nL 52.375 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path clip-path=\"url(#p9587f35e66)\" d=\"M 61.252273 143.1 \nL 68.499026 143.1 \nL 68.499026 13.671429 \nL 61.252273 13.671429 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path clip-path=\"url(#p9587f35e66)\" d=\"M 79.369156 143.1 \nL 86.615909 143.1 \nL 86.615909 69.112838 \nL 79.369156 69.112838 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path clip-path=\"url(#p9587f35e66)\" d=\"M 97.486039 143.1 \nL 104.732792 143.1 \nL 104.732792 138.560551 \nL 97.486039 138.560551 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path clip-path=\"url(#p9587f35e66)\" d=\"M 115.602922 143.1 \nL 122.849675 143.1 \nL 122.849675 142.652168 \nL 115.602922 142.652168 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path clip-path=\"url(#p9587f35e66)\" d=\"M 133.719805 143.1 \nL 140.966558 143.1 \nL 140.966558 143.045112 \nL 133.719805 143.045112 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path clip-path=\"url(#p9587f35e66)\" d=\"M 151.836688 143.1 \nL 159.083442 143.1 \nL 159.083442 143.083783 \nL 151.836688 143.083783 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path clip-path=\"url(#p9587f35e66)\" d=\"M 169.953571 143.1 \nL 177.200325 143.1 \nL 177.200325 143.092515 \nL 169.953571 143.092515 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path clip-path=\"url(#p9587f35e66)\" d=\"M 188.070455 143.1 \nL 195.317208 143.1 \nL 195.317208 143.098753 \nL 188.070455 143.098753 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path clip-path=\"url(#p9587f35e66)\" d=\"M 206.187338 143.1 \nL 213.434091 143.1 \nL 213.434091 143.097505 \nL 206.187338 143.097505 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path clip-path=\"url(#p9587f35e66)\" d=\"M 224.304221 143.1 \nL 231.550974 143.1 \nL 231.550974 143.1 \nL 224.304221 143.1 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_13\">\n    <path clip-path=\"url(#p9587f35e66)\" d=\"M 68.499026 143.1 \nL 75.745779 143.1 \nL 75.745779 26.397854 \nL 68.499026 26.397854 \nz\n\" style=\"fill:url(#h142ac8a39a);\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path clip-path=\"url(#p9587f35e66)\" d=\"M 86.615909 143.1 \nL 93.862662 143.1 \nL 93.862662 59.453878 \nL 86.615909 59.453878 \nz\n\" style=\"fill:url(#h142ac8a39a);\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path clip-path=\"url(#p9587f35e66)\" d=\"M 104.732792 143.1 \nL 111.979545 143.1 \nL 111.979545 136.044456 \nL 104.732792 136.044456 \nz\n\" style=\"fill:url(#h142ac8a39a);\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path clip-path=\"url(#p9587f35e66)\" d=\"M 122.849675 143.1 \nL 130.096429 143.1 \nL 130.096429 142.176891 \nL 122.849675 142.176891 \nz\n\" style=\"fill:url(#h142ac8a39a);\"/>\n   </g>\n   <g id=\"patch_17\">\n    <path clip-path=\"url(#p9587f35e66)\" d=\"M 140.966558 143.1 \nL 148.213312 143.1 \nL 148.213312 142.993967 \nL 140.966558 142.993967 \nz\n\" style=\"fill:url(#h142ac8a39a);\"/>\n   </g>\n   <g id=\"patch_18\">\n    <path clip-path=\"url(#p9587f35e66)\" d=\"M 159.083442 143.1 \nL 166.330195 143.1 \nL 166.330195 143.058834 \nL 159.083442 143.058834 \nz\n\" style=\"fill:url(#h142ac8a39a);\"/>\n   </g>\n   <g id=\"patch_19\">\n    <path clip-path=\"url(#p9587f35e66)\" d=\"M 177.200325 143.1 \nL 184.447078 143.1 \nL 184.447078 143.097505 \nL 177.200325 143.097505 \nz\n\" style=\"fill:url(#h142ac8a39a);\"/>\n   </g>\n   <g id=\"patch_20\">\n    <path clip-path=\"url(#p9587f35e66)\" d=\"M 195.317208 143.1 \nL 202.563961 143.1 \nL 202.563961 143.097505 \nL 195.317208 143.097505 \nz\n\" style=\"fill:url(#h142ac8a39a);\"/>\n   </g>\n   <g id=\"patch_21\">\n    <path clip-path=\"url(#p9587f35e66)\" d=\"M 213.434091 143.1 \nL 220.680844 143.1 \nL 220.680844 143.097505 \nL 213.434091 143.097505 \nz\n\" style=\"fill:url(#h142ac8a39a);\"/>\n   </g>\n   <g id=\"patch_22\">\n    <path clip-path=\"url(#p9587f35e66)\" d=\"M 231.550974 143.1 \nL 238.797727 143.1 \nL 238.797727 143.096258 \nL 231.550974 143.096258 \nz\n\" style=\"fill:url(#h142ac8a39a);\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m4396b95410\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.970269\" xlink:href=\"#m4396b95410\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(49.789019 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"117.673423\" xlink:href=\"#m4396b95410\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 20 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(111.310923 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"182.376577\" xlink:href=\"#m4396b95410\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 40 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(176.014077 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"247.079731\" xlink:href=\"#m4396b95410\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 60 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(240.717231 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_5\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mcb5d7ba7e6\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#mcb5d7ba7e6\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0 -->\n      <g transform=\"translate(39.0125 146.899219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#mcb5d7ba7e6\" y=\"118.151116\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 20000 -->\n      <g transform=\"translate(13.5625 121.950335)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#mcb5d7ba7e6\" y=\"93.202233\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 40000 -->\n      <g transform=\"translate(13.5625 97.001451)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#mcb5d7ba7e6\" y=\"68.253349\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 60000 -->\n      <g transform=\"translate(13.5625 72.052568)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#mcb5d7ba7e6\" y=\"43.304465\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 80000 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(13.5625 47.103684)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#mcb5d7ba7e6\" y=\"18.355581\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 100000 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(7.2 22.1548)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_23\">\n    <path d=\"M 52.375 143.1 \nL 52.375 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_24\">\n    <path d=\"M 247.675 143.1 \nL 247.675 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_25\">\n    <path d=\"M 52.375 143.1 \nL 247.675 143.1 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_26\">\n    <path d=\"M 52.375 7.2 \nL 247.675 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_27\">\n     <path d=\"M 175.471875 44.55625 \nL 240.675 44.55625 \nQ 242.675 44.55625 242.675 42.55625 \nL 242.675 14.2 \nQ 242.675 12.2 240.675 12.2 \nL 175.471875 12.2 \nQ 173.471875 12.2 173.471875 14.2 \nL 173.471875 42.55625 \nQ 173.471875 44.55625 175.471875 44.55625 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"patch_28\">\n     <path d=\"M 177.471875 23.798438 \nL 197.471875 23.798438 \nL 197.471875 16.798438 \nL 177.471875 16.798438 \nz\n\" style=\"fill:#1f77b4;\"/>\n    </g>\n    <g id=\"text_11\">\n     <!-- source -->\n     <defs>\n      <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n      <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n      <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n      <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n     </defs>\n     <g transform=\"translate(205.471875 23.798438)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"52.099609\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"113.28125\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"176.660156\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"215.523438\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"270.503906\" xlink:href=\"#DejaVuSans-101\"/>\n     </g>\n    </g>\n    <g id=\"patch_29\">\n     <path d=\"M 177.471875 38.476562 \nL 197.471875 38.476562 \nL 197.471875 31.476562 \nL 177.471875 31.476562 \nz\n\" style=\"fill:url(#h142ac8a39a);\"/>\n    </g>\n    <g id=\"text_12\">\n     <!-- target -->\n     <defs>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 45.40625 27.984375 \nQ 45.40625 37.75 41.375 43.109375 \nQ 37.359375 48.484375 30.078125 48.484375 \nQ 22.859375 48.484375 18.828125 43.109375 \nQ 14.796875 37.75 14.796875 27.984375 \nQ 14.796875 18.265625 18.828125 12.890625 \nQ 22.859375 7.515625 30.078125 7.515625 \nQ 37.359375 7.515625 41.375 12.890625 \nQ 45.40625 18.265625 45.40625 27.984375 \nz\nM 54.390625 6.78125 \nQ 54.390625 -7.171875 48.1875 -13.984375 \nQ 42 -20.796875 29.203125 -20.796875 \nQ 24.46875 -20.796875 20.265625 -20.09375 \nQ 16.0625 -19.390625 12.109375 -17.921875 \nL 12.109375 -9.1875 \nQ 16.0625 -11.328125 19.921875 -12.34375 \nQ 23.78125 -13.375 27.78125 -13.375 \nQ 36.625 -13.375 41.015625 -8.765625 \nQ 45.40625 -4.15625 45.40625 5.171875 \nL 45.40625 9.625 \nQ 42.625 4.78125 38.28125 2.390625 \nQ 33.9375 0 27.875 0 \nQ 17.828125 0 11.671875 7.65625 \nQ 5.515625 15.328125 5.515625 27.984375 \nQ 5.515625 40.671875 11.671875 48.328125 \nQ 17.828125 56 27.875 56 \nQ 33.9375 56 38.28125 53.609375 \nQ 42.625 51.21875 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nz\n\" id=\"DejaVuSans-103\"/>\n     </defs>\n     <g transform=\"translate(205.471875 38.476562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"100.488281\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"139.851562\" xlink:href=\"#DejaVuSans-103\"/>\n      <use x=\"203.328125\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"264.851562\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p9587f35e66\">\n   <rect height=\"135.9\" width=\"195.3\" x=\"52.375\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n <defs>\n  <pattern height=\"72\" id=\"h142ac8a39a\" patternUnits=\"userSpaceOnUse\" width=\"72\" x=\"0\" y=\"0\">\n   <rect fill=\"#ff7f0e\" height=\"73\" width=\"73\" x=\"0\" y=\"0\"/>\n   <path d=\"M -36 36 \nL 36 -36 \nM -24 48 \nL 48 -24 \nM -12 60 \nL 60 -12 \nM 0 72 \nL 72 0 \nM 12 84 \nL 84 12 \nM 24 96 \nL 96 24 \nM 36 108 \nL 108 36 \n\" style=\"fill:#000000;stroke:#000000;stroke-linecap:butt;stroke-linejoin:miter;stroke-width:1.0;\"/>\n  </pattern>\n </defs>\n</svg>\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGStlaZKN_Ia",
        "outputId": "a07601d1-9fdd-4524-a29c-9fd3a6dea92b"
      },
      "source": [
        "src_vocab = d2l.Vocab(source, min_freq=2,\n",
        "                      reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
        "# dictionary for source\n",
        "src_vocab[['you','are']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6, 26]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTBFnh7gOA3k",
        "outputId": "c8fd6253-c174-4f40-b435-3db22e6a871c"
      },
      "source": [
        "#@save\n",
        "def truncate_pad(line, num_steps, padding_token):\n",
        "    \"\"\"Truncate or pad sequences.\"\"\"\n",
        "    if len(line) > num_steps:\n",
        "        return line[:num_steps]  # Truncate\n",
        "    return line + [padding_token] * (num_steps - len(line))  # Pad\n",
        "\n",
        "truncate_pad(src_vocab[source[0]], 10, src_vocab['<pad>'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[47, 4, 1, 1, 1, 1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBTYSmzVOCiI"
      },
      "source": [
        "#@save\n",
        "def build_array_nmt(lines, vocab, num_steps):\n",
        "    \"\"\"Transform text sequences of machine translation into minibatches.\"\"\"\n",
        "    lines = [vocab[l] for l in lines]\n",
        "    lines = [l + [vocab['<eos>']] for l in lines]\n",
        "    array = tf.constant([\n",
        "        truncate_pad(l, num_steps, vocab['<pad>']) for l in lines])\n",
        "    valid_len = tf.reduce_sum(tf.cast(array != vocab['<pad>'], tf.int32), 1)\n",
        "    return array, valid_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcVbbzHMOENl"
      },
      "source": [
        "#@save\n",
        "def load_data_nmt(batch_size, num_steps, num_examples=167130):\n",
        "    \"\"\"Return the iterator and the vocabularies of the translation dataset.\"\"\"\n",
        "    text = preprocess_nmt(read_data_nmt())\n",
        "    source, target = tokenize_nmt(text, num_examples)\n",
        "    src_vocab = d2l.Vocab(source, min_freq=2,\n",
        "                          reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
        "    tgt_vocab = d2l.Vocab(target, min_freq=2,\n",
        "                          reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
        "    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)\n",
        "    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)\n",
        "    src_array=tf.one_hot(src_array,depth=len(src_vocab),axis=-1)\n",
        "    tgt_array=tf.one_hot(tgt_array,depth=len(tgt_vocab),axis=-1)\n",
        "    data_arrays = (src_array, tgt_array,)\n",
        "    data_iter = d2l.load_array(data_arrays, batch_size)\n",
        "    return data_iter, src_vocab, tgt_vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DyZAjyzOGHA",
        "outputId": "abc22d77-221e-42dd-c80f-c4ae2d5010f5"
      },
      "source": [
        "\n",
        "batch_size=10000\n",
        "train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size=batch_size, num_steps=8,num_examples=10000)\n",
        "Tx=8\n",
        "Ty=8\n",
        "src_vocab_size=len(src_vocab)\n",
        "tgt_vocab_size=len(tgt_vocab)\n",
        "print(src_vocab_size)\n",
        "\n",
        "for X_iter, Y_iter  in train_iter:\n",
        "    X=X_iter\n",
        "    Y=Y_iter\n",
        "    print('X:', X)\n",
        "    \n",
        "    print('Y:', Y)\n",
        "    \n",
        "    break\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1505\n",
            "X: tf.Tensor(\n",
            "[[[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]]], shape=(10000, 8, 1505), dtype=float32)\n",
            "Y: tf.Tensor(\n",
            "[[[1. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]]], shape=(10000, 8, 2252), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVbS5kwkOIBf"
      },
      "source": [
        "repeator=RepeatVector(Tx)\n",
        "concatenator=Concatenate()\n",
        "densor1=Dense(10,activation='tanh')\n",
        "densor2=Dense(1,activation='relu')\n",
        "activator=Softmax(axis=1)\n",
        "dotor=Dot(axes=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df4Td5P8OJtD"
      },
      "source": [
        "def one_step_attention(a,s_prev):\n",
        "    \"\"\"\n",
        "    Perform one step of attention\n",
        "    a: output of pre-attention BiLSTM layer, shape=(m,Tx,2*n_a)\n",
        "    s_prev: previous hidden state of post-attention LSTM, shape=(m,n_s)\n",
        "    \"\"\"\n",
        "    s=repeator(s_prev)               # now s.shape=(m,Tx,n_s)\n",
        "    input_to_dense=concatenator([s,a]) # input_to_dense.shape=(m,Tx, n_s+2*n_a)\n",
        "    out1=densor1(input_to_dense)              # out1.shape=(m,Tx,10)\n",
        "    e=densor2(out1)                  # e.shape=(m,Tx,1)\n",
        "    alphas=activator(e)              # aphas.shape=(m,Tx,1)\n",
        "    context=dotor([alphas,a])         # context.shape=(m,1,2*n_a)\n",
        "    return context"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmavpefpOLWs"
      },
      "source": [
        "n_a=32\n",
        "n_s=64\n",
        "post_attention_LSTM_cell=LSTM(n_s,return_state=True)\n",
        "output_layer=Dense(len(tgt_vocab),activation=Softmax(axis=-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx-sSPnIOR9q"
      },
      "source": [
        "def my_model(Tx,Ty,n_a,n_s,src_vocab_size,tgt_vocab_size):\n",
        "    '''\n",
        "    Tx: length of input sentence\n",
        "    Ty: length of output sentence\n",
        "    n_a: hidden state size of pre-attention BiLSTM\n",
        "    n_s: hidden state size of post-attention LSTM\n",
        "    src_vocab_size: source vocab size (English)\n",
        "    tgt_vocab_size: target vocab size (French)\n",
        "    '''\n",
        "    X=Input(shape=(Tx,src_vocab_size))\n",
        "    s0=Input(shape=(n_s,))\n",
        "    c0=Input(shape=(n_s,))\n",
        "    s=s0\n",
        "    c=c0\n",
        "    outputs=[]\n",
        "    # Pre-attention BiLSTM, output shape = (m,Tx,2*n_a)\n",
        "    a=Bidirectional(LSTM(units=n_a,return_sequences=True))(X)\n",
        "\n",
        "    for t in range(Ty):\n",
        "        context=one_step_attention(a,s)\n",
        "        s,y,c=post_attention_LSTM_cell(inputs=context,initial_state=[s, c])\n",
        "        out=output_layer(inputs=s)\n",
        "        outputs.append(out)\n",
        "    \n",
        "\n",
        "    model=tf.keras.models.Model(inputs=[X,s0,c0],outputs=outputs)\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4_44eBwOTY_",
        "outputId": "77cb1852-ee8a-4f8b-8001-818cbd77e3c3"
      },
      "source": [
        "model=my_model(Tx,Ty,n_a,n_s,src_vocab_size,tgt_vocab_size)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            [(None, 8, 1505)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector (RepeatVector)    (None, 8, 64)        0           input_2[0][0]                    \n",
            "                                                                 lstm[0][0]                       \n",
            "                                                                 lstm[1][0]                       \n",
            "                                                                 lstm[2][0]                       \n",
            "                                                                 lstm[3][0]                       \n",
            "                                                                 lstm[4][0]                       \n",
            "                                                                 lstm[5][0]                       \n",
            "                                                                 lstm[6][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 8, 64)        393728      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8, 128)       0           repeat_vector[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[1][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[2][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[3][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[4][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[5][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[6][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[7][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 8, 10)        1290        concatenate[0][0]                \n",
            "                                                                 concatenate[1][0]                \n",
            "                                                                 concatenate[2][0]                \n",
            "                                                                 concatenate[3][0]                \n",
            "                                                                 concatenate[4][0]                \n",
            "                                                                 concatenate[5][0]                \n",
            "                                                                 concatenate[6][0]                \n",
            "                                                                 concatenate[7][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 8, 1)         11          dense[0][0]                      \n",
            "                                                                 dense[1][0]                      \n",
            "                                                                 dense[2][0]                      \n",
            "                                                                 dense[3][0]                      \n",
            "                                                                 dense[4][0]                      \n",
            "                                                                 dense[5][0]                      \n",
            "                                                                 dense[6][0]                      \n",
            "                                                                 dense[7][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Softmax)               (None, 8, 1)         0           dense_1[0][0]                    \n",
            "                                                                 dense_1[1][0]                    \n",
            "                                                                 dense_1[2][0]                    \n",
            "                                                                 dense_1[3][0]                    \n",
            "                                                                 dense_1[4][0]                    \n",
            "                                                                 dense_1[5][0]                    \n",
            "                                                                 dense_1[6][0]                    \n",
            "                                                                 dense_1[7][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 1, 64)        0           softmax[0][0]                    \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 softmax[1][0]                    \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 softmax[2][0]                    \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 softmax[3][0]                    \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 softmax[4][0]                    \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 softmax[5][0]                    \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 softmax[6][0]                    \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 softmax[7][0]                    \n",
            "                                                                 bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 64), (None,  33024       dot[0][0]                        \n",
            "                                                                 input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 dot[1][0]                        \n",
            "                                                                 lstm[0][0]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "                                                                 dot[2][0]                        \n",
            "                                                                 lstm[1][0]                       \n",
            "                                                                 lstm[1][2]                       \n",
            "                                                                 dot[3][0]                        \n",
            "                                                                 lstm[2][0]                       \n",
            "                                                                 lstm[2][2]                       \n",
            "                                                                 dot[4][0]                        \n",
            "                                                                 lstm[3][0]                       \n",
            "                                                                 lstm[3][2]                       \n",
            "                                                                 dot[5][0]                        \n",
            "                                                                 lstm[4][0]                       \n",
            "                                                                 lstm[4][2]                       \n",
            "                                                                 dot[6][0]                        \n",
            "                                                                 lstm[5][0]                       \n",
            "                                                                 lstm[5][2]                       \n",
            "                                                                 dot[7][0]                        \n",
            "                                                                 lstm[6][0]                       \n",
            "                                                                 lstm[6][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 2252)         146380      lstm[0][0]                       \n",
            "                                                                 lstm[1][0]                       \n",
            "                                                                 lstm[2][0]                       \n",
            "                                                                 lstm[3][0]                       \n",
            "                                                                 lstm[4][0]                       \n",
            "                                                                 lstm[5][0]                       \n",
            "                                                                 lstm[6][0]                       \n",
            "                                                                 lstm[7][0]                       \n",
            "==================================================================================================\n",
            "Total params: 574,433\n",
            "Trainable params: 574,433\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7XCgtD8OVPG"
      },
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate=0.005,beta_1=0.9,beta_2=0.999,decay=0.01) \n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qftMF4zMOdw_",
        "outputId": "85effb3f-d219-40b0-b85f-71ec56a46efb"
      },
      "source": [
        "\n",
        "s0=np.zeros((batch_size,n_s))\n",
        "c0=np.zeros((batch_size,n_s))\n",
        "outputs = list(tf.transpose(Y, [1, 0, 2]))\n",
        "model.fit([X,s0,c0],outputs,epochs=300,verbose=1,batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10000 samples\n",
            "Epoch 1/300\n",
            "10000/10000 [==============================] - 51s 5ms/sample - loss: 26.8972 - dense_2_loss: 5.2930 - dense_2_1_loss: 6.1659 - dense_2_2_loss: 6.0242 - dense_2_3_loss: 3.9884 - dense_2_4_loss: 2.4881 - dense_2_5_loss: 1.4550 - dense_2_6_loss: 0.8634 - dense_2_7_loss: 0.6096 - dense_2_accuracy: 0.1513 - dense_2_1_accuracy: 0.0263 - dense_2_2_accuracy: 0.0774 - dense_2_3_accuracy: 0.2445 - dense_2_4_accuracy: 0.3648 - dense_2_5_accuracy: 0.6559 - dense_2_6_accuracy: 0.8701 - dense_2_7_accuracy: 0.9604\n",
            "Epoch 2/300\n",
            "10000/10000 [==============================] - 29s 3ms/sample - loss: 22.6872 - dense_2_loss: 4.5176 - dense_2_1_loss: 5.6945 - dense_2_2_loss: 5.4535 - dense_2_3_loss: 3.3697 - dense_2_4_loss: 1.9545 - dense_2_5_loss: 1.0154 - dense_2_6_loss: 0.4755 - dense_2_7_loss: 0.2027 - dense_2_accuracy: 0.1953 - dense_2_1_accuracy: 0.0631 - dense_2_2_accuracy: 0.1192 - dense_2_3_accuracy: 0.4026 - dense_2_4_accuracy: 0.5366 - dense_2_5_accuracy: 0.7173 - dense_2_6_accuracy: 0.8833 - dense_2_7_accuracy: 0.9638\n",
            "Epoch 3/300\n",
            "10000/10000 [==============================] - 29s 3ms/sample - loss: 21.9170 - dense_2_loss: 4.3634 - dense_2_1_loss: 5.5457 - dense_2_2_loss: 5.3308 - dense_2_3_loss: 3.2338 - dense_2_4_loss: 1.8429 - dense_2_5_loss: 0.9563 - dense_2_6_loss: 0.4556 - dense_2_7_loss: 0.1893 - dense_2_accuracy: 0.1953 - dense_2_1_accuracy: 0.0636 - dense_2_2_accuracy: 0.1395 - dense_2_3_accuracy: 0.4293 - dense_2_4_accuracy: 0.5915 - dense_2_5_accuracy: 0.7501 - dense_2_6_accuracy: 0.8851 - dense_2_7_accuracy: 0.9636\n",
            "Epoch 4/300\n",
            "10000/10000 [==============================] - 29s 3ms/sample - loss: 21.5213 - dense_2_loss: 4.2953 - dense_2_1_loss: 5.4731 - dense_2_2_loss: 5.2589 - dense_2_3_loss: 3.1590 - dense_2_4_loss: 1.7833 - dense_2_5_loss: 0.9262 - dense_2_6_loss: 0.4438 - dense_2_7_loss: 0.1836 - dense_2_accuracy: 0.1954 - dense_2_1_accuracy: 0.0709 - dense_2_2_accuracy: 0.1472 - dense_2_3_accuracy: 0.4467 - dense_2_4_accuracy: 0.6161 - dense_2_5_accuracy: 0.7636 - dense_2_6_accuracy: 0.8887 - dense_2_7_accuracy: 0.9637\n",
            "Epoch 5/300\n",
            "10000/10000 [==============================] - 29s 3ms/sample - loss: 21.2883 - dense_2_loss: 4.2533 - dense_2_1_loss: 5.4190 - dense_2_2_loss: 5.2140 - dense_2_3_loss: 3.1165 - dense_2_4_loss: 1.7544 - dense_2_5_loss: 0.9097 - dense_2_6_loss: 0.4371 - dense_2_7_loss: 0.1795 - dense_2_accuracy: 0.1958 - dense_2_1_accuracy: 0.0792 - dense_2_2_accuracy: 0.1549 - dense_2_3_accuracy: 0.4512 - dense_2_4_accuracy: 0.6266 - dense_2_5_accuracy: 0.7720 - dense_2_6_accuracy: 0.8891 - dense_2_7_accuracy: 0.9636\n",
            "Epoch 6/300\n",
            "10000/10000 [==============================] - 29s 3ms/sample - loss: 21.1162 - dense_2_loss: 4.2246 - dense_2_1_loss: 5.3803 - dense_2_2_loss: 5.1785 - dense_2_3_loss: 3.0861 - dense_2_4_loss: 1.7344 - dense_2_5_loss: 0.8996 - dense_2_6_loss: 0.4321 - dense_2_7_loss: 0.1784 - dense_2_accuracy: 0.1978 - dense_2_1_accuracy: 0.0834 - dense_2_2_accuracy: 0.1644 - dense_2_3_accuracy: 0.4532 - dense_2_4_accuracy: 0.6340 - dense_2_5_accuracy: 0.7765 - dense_2_6_accuracy: 0.8917 - dense_2_7_accuracy: 0.9637\n",
            "Epoch 7/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 20.9741 - dense_2_loss: 4.2004 - dense_2_1_loss: 5.3476 - dense_2_2_loss: 5.1475 - dense_2_3_loss: 3.0623 - dense_2_4_loss: 1.7171 - dense_2_5_loss: 0.8930 - dense_2_6_loss: 0.4284 - dense_2_7_loss: 0.1775 - dense_2_accuracy: 0.2006 - dense_2_1_accuracy: 0.0842 - dense_2_2_accuracy: 0.1733 - dense_2_3_accuracy: 0.4586 - dense_2_4_accuracy: 0.6388 - dense_2_5_accuracy: 0.7814 - dense_2_6_accuracy: 0.8930 - dense_2_7_accuracy: 0.9637\n",
            "Epoch 8/300\n",
            "10000/10000 [==============================] - 29s 3ms/sample - loss: 20.8525 - dense_2_loss: 4.1732 - dense_2_1_loss: 5.3168 - dense_2_2_loss: 5.1267 - dense_2_3_loss: 3.0452 - dense_2_4_loss: 1.7011 - dense_2_5_loss: 0.8842 - dense_2_6_loss: 0.4259 - dense_2_7_loss: 0.1766 - dense_2_accuracy: 0.2035 - dense_2_1_accuracy: 0.0894 - dense_2_2_accuracy: 0.1830 - dense_2_3_accuracy: 0.4644 - dense_2_4_accuracy: 0.6460 - dense_2_5_accuracy: 0.7846 - dense_2_6_accuracy: 0.8940 - dense_2_7_accuracy: 0.9636\n",
            "Epoch 9/300\n",
            "10000/10000 [==============================] - 29s 3ms/sample - loss: 20.7504 - dense_2_loss: 4.1516 - dense_2_1_loss: 5.2920 - dense_2_2_loss: 5.1063 - dense_2_3_loss: 3.0282 - dense_2_4_loss: 1.6967 - dense_2_5_loss: 0.8804 - dense_2_6_loss: 0.4235 - dense_2_7_loss: 0.1755 - dense_2_accuracy: 0.2057 - dense_2_1_accuracy: 0.0941 - dense_2_2_accuracy: 0.1861 - dense_2_3_accuracy: 0.4700 - dense_2_4_accuracy: 0.6458 - dense_2_5_accuracy: 0.7851 - dense_2_6_accuracy: 0.8956 - dense_2_7_accuracy: 0.9636\n",
            "Epoch 10/300\n",
            "10000/10000 [==============================] - 29s 3ms/sample - loss: 20.6590 - dense_2_loss: 4.1324 - dense_2_1_loss: 5.2692 - dense_2_2_loss: 5.0871 - dense_2_3_loss: 3.0133 - dense_2_4_loss: 1.6880 - dense_2_5_loss: 0.8745 - dense_2_6_loss: 0.4206 - dense_2_7_loss: 0.1751 - dense_2_accuracy: 0.2084 - dense_2_1_accuracy: 0.1003 - dense_2_2_accuracy: 0.1915 - dense_2_3_accuracy: 0.4828 - dense_2_4_accuracy: 0.6487 - dense_2_5_accuracy: 0.7873 - dense_2_6_accuracy: 0.8946 - dense_2_7_accuracy: 0.9638\n",
            "Epoch 11/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 20.5641 - dense_2_loss: 4.1122 - dense_2_1_loss: 5.2498 - dense_2_2_loss: 5.0694 - dense_2_3_loss: 3.0030 - dense_2_4_loss: 1.6760 - dense_2_5_loss: 0.8667 - dense_2_6_loss: 0.4164 - dense_2_7_loss: 0.1731 - dense_2_accuracy: 0.2107 - dense_2_1_accuracy: 0.1043 - dense_2_2_accuracy: 0.1960 - dense_2_3_accuracy: 0.4885 - dense_2_4_accuracy: 0.6526 - dense_2_5_accuracy: 0.7903 - dense_2_6_accuracy: 0.8958 - dense_2_7_accuracy: 0.9640\n",
            "Epoch 12/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 20.4979 - dense_2_loss: 4.0921 - dense_2_1_loss: 5.2306 - dense_2_2_loss: 5.0524 - dense_2_3_loss: 2.9916 - dense_2_4_loss: 1.6736 - dense_2_5_loss: 0.8657 - dense_2_6_loss: 0.4166 - dense_2_7_loss: 0.1737 - dense_2_accuracy: 0.2121 - dense_2_1_accuracy: 0.1103 - dense_2_2_accuracy: 0.1961 - dense_2_3_accuracy: 0.4909 - dense_2_4_accuracy: 0.6520 - dense_2_5_accuracy: 0.7910 - dense_2_6_accuracy: 0.8948 - dense_2_7_accuracy: 0.9638\n",
            "Epoch 13/300\n",
            "10000/10000 [==============================] - 39s 4ms/sample - loss: 20.4227 - dense_2_loss: 4.0799 - dense_2_1_loss: 5.2159 - dense_2_2_loss: 5.0383 - dense_2_3_loss: 2.9805 - dense_2_4_loss: 1.6633 - dense_2_5_loss: 0.8585 - dense_2_6_loss: 0.4124 - dense_2_7_loss: 0.1726 - dense_2_accuracy: 0.2132 - dense_2_1_accuracy: 0.1116 - dense_2_2_accuracy: 0.1985 - dense_2_3_accuracy: 0.4908 - dense_2_4_accuracy: 0.6545 - dense_2_5_accuracy: 0.7937 - dense_2_6_accuracy: 0.8958 - dense_2_7_accuracy: 0.9636\n",
            "Epoch 14/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 20.3623 - dense_2_loss: 4.0639 - dense_2_1_loss: 5.1988 - dense_2_2_loss: 5.0243 - dense_2_3_loss: 2.9753 - dense_2_4_loss: 1.6590 - dense_2_5_loss: 0.8574 - dense_2_6_loss: 0.4120 - dense_2_7_loss: 0.1716 - dense_2_accuracy: 0.2147 - dense_2_1_accuracy: 0.1127 - dense_2_2_accuracy: 0.2029 - dense_2_3_accuracy: 0.4919 - dense_2_4_accuracy: 0.6571 - dense_2_5_accuracy: 0.7939 - dense_2_6_accuracy: 0.8966 - dense_2_7_accuracy: 0.9641\n",
            "Epoch 15/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 20.3052 - dense_2_loss: 4.0500 - dense_2_1_loss: 5.1872 - dense_2_2_loss: 5.0150 - dense_2_3_loss: 2.9668 - dense_2_4_loss: 1.6541 - dense_2_5_loss: 0.8538 - dense_2_6_loss: 0.4092 - dense_2_7_loss: 0.1710 - dense_2_accuracy: 0.2154 - dense_2_1_accuracy: 0.1133 - dense_2_2_accuracy: 0.2039 - dense_2_3_accuracy: 0.4927 - dense_2_4_accuracy: 0.6586 - dense_2_5_accuracy: 0.7956 - dense_2_6_accuracy: 0.8972 - dense_2_7_accuracy: 0.9643\n",
            "Epoch 16/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 20.2526 - dense_2_loss: 4.0383 - dense_2_1_loss: 5.1749 - dense_2_2_loss: 5.0024 - dense_2_3_loss: 2.9582 - dense_2_4_loss: 1.6497 - dense_2_5_loss: 0.8506 - dense_2_6_loss: 0.4089 - dense_2_7_loss: 0.1712 - dense_2_accuracy: 0.2168 - dense_2_1_accuracy: 0.1134 - dense_2_2_accuracy: 0.2070 - dense_2_3_accuracy: 0.4945 - dense_2_4_accuracy: 0.6592 - dense_2_5_accuracy: 0.7964 - dense_2_6_accuracy: 0.8971 - dense_2_7_accuracy: 0.9643\n",
            "Epoch 17/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 20.1997 - dense_2_loss: 4.0263 - dense_2_1_loss: 5.1628 - dense_2_2_loss: 4.9957 - dense_2_3_loss: 2.9467 - dense_2_4_loss: 1.6418 - dense_2_5_loss: 0.8472 - dense_2_6_loss: 0.4072 - dense_2_7_loss: 0.1702 - dense_2_accuracy: 0.2212 - dense_2_1_accuracy: 0.1137 - dense_2_2_accuracy: 0.2074 - dense_2_3_accuracy: 0.4969 - dense_2_4_accuracy: 0.6590 - dense_2_5_accuracy: 0.7948 - dense_2_6_accuracy: 0.8974 - dense_2_7_accuracy: 0.9640\n",
            "Epoch 18/300\n",
            "10000/10000 [==============================] - 29s 3ms/sample - loss: 20.1504 - dense_2_loss: 4.0159 - dense_2_1_loss: 5.1518 - dense_2_2_loss: 4.9880 - dense_2_3_loss: 2.9381 - dense_2_4_loss: 1.6382 - dense_2_5_loss: 0.8447 - dense_2_6_loss: 0.4069 - dense_2_7_loss: 0.1698 - dense_2_accuracy: 0.2216 - dense_2_1_accuracy: 0.1142 - dense_2_2_accuracy: 0.2076 - dense_2_3_accuracy: 0.4978 - dense_2_4_accuracy: 0.6637 - dense_2_5_accuracy: 0.7980 - dense_2_6_accuracy: 0.8975 - dense_2_7_accuracy: 0.9643\n",
            "Epoch 19/300\n",
            "10000/10000 [==============================] - 29s 3ms/sample - loss: 20.1116 - dense_2_loss: 4.0045 - dense_2_1_loss: 5.1431 - dense_2_2_loss: 4.9780 - dense_2_3_loss: 2.9300 - dense_2_4_loss: 1.6332 - dense_2_5_loss: 0.8421 - dense_2_6_loss: 0.4054 - dense_2_7_loss: 0.1692 - dense_2_accuracy: 0.2235 - dense_2_1_accuracy: 0.1151 - dense_2_2_accuracy: 0.2094 - dense_2_3_accuracy: 0.4991 - dense_2_4_accuracy: 0.6616 - dense_2_5_accuracy: 0.7966 - dense_2_6_accuracy: 0.8980 - dense_2_7_accuracy: 0.9651\n",
            "Epoch 20/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 20.0756 - dense_2_loss: 3.9985 - dense_2_1_loss: 5.1363 - dense_2_2_loss: 4.9727 - dense_2_3_loss: 2.9230 - dense_2_4_loss: 1.6306 - dense_2_5_loss: 0.8397 - dense_2_6_loss: 0.4046 - dense_2_7_loss: 0.1688 - dense_2_accuracy: 0.2260 - dense_2_1_accuracy: 0.1156 - dense_2_2_accuracy: 0.2089 - dense_2_3_accuracy: 0.4996 - dense_2_4_accuracy: 0.6618 - dense_2_5_accuracy: 0.7964 - dense_2_6_accuracy: 0.8968 - dense_2_7_accuracy: 0.9652\n",
            "Epoch 21/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 20.0339 - dense_2_loss: 3.9863 - dense_2_1_loss: 5.1264 - dense_2_2_loss: 4.9666 - dense_2_3_loss: 2.9152 - dense_2_4_loss: 1.6254 - dense_2_5_loss: 0.8382 - dense_2_6_loss: 0.4041 - dense_2_7_loss: 0.1689 - dense_2_accuracy: 0.2281 - dense_2_1_accuracy: 0.1160 - dense_2_2_accuracy: 0.2106 - dense_2_3_accuracy: 0.5015 - dense_2_4_accuracy: 0.6640 - dense_2_5_accuracy: 0.7972 - dense_2_6_accuracy: 0.8973 - dense_2_7_accuracy: 0.9646\n",
            "Epoch 22/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.9937 - dense_2_loss: 3.9765 - dense_2_1_loss: 5.1189 - dense_2_2_loss: 4.9625 - dense_2_3_loss: 2.9087 - dense_2_4_loss: 1.6197 - dense_2_5_loss: 0.8337 - dense_2_6_loss: 0.4029 - dense_2_7_loss: 0.1682 - dense_2_accuracy: 0.2285 - dense_2_1_accuracy: 0.1157 - dense_2_2_accuracy: 0.2094 - dense_2_3_accuracy: 0.5030 - dense_2_4_accuracy: 0.6661 - dense_2_5_accuracy: 0.7979 - dense_2_6_accuracy: 0.8980 - dense_2_7_accuracy: 0.9644\n",
            "Epoch 23/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.9628 - dense_2_loss: 3.9690 - dense_2_1_loss: 5.1109 - dense_2_2_loss: 4.9580 - dense_2_3_loss: 2.9023 - dense_2_4_loss: 1.6173 - dense_2_5_loss: 0.8332 - dense_2_6_loss: 0.4024 - dense_2_7_loss: 0.1681 - dense_2_accuracy: 0.2297 - dense_2_1_accuracy: 0.1158 - dense_2_2_accuracy: 0.2090 - dense_2_3_accuracy: 0.5013 - dense_2_4_accuracy: 0.6674 - dense_2_5_accuracy: 0.7982 - dense_2_6_accuracy: 0.8970 - dense_2_7_accuracy: 0.9644\n",
            "Epoch 24/300\n",
            "10000/10000 [==============================] - 29s 3ms/sample - loss: 19.9266 - dense_2_loss: 3.9595 - dense_2_1_loss: 5.1045 - dense_2_2_loss: 4.9490 - dense_2_3_loss: 2.8960 - dense_2_4_loss: 1.6139 - dense_2_5_loss: 0.8297 - dense_2_6_loss: 0.4011 - dense_2_7_loss: 0.1676 - dense_2_accuracy: 0.2309 - dense_2_1_accuracy: 0.1169 - dense_2_2_accuracy: 0.2104 - dense_2_3_accuracy: 0.5016 - dense_2_4_accuracy: 0.6683 - dense_2_5_accuracy: 0.8002 - dense_2_6_accuracy: 0.8989 - dense_2_7_accuracy: 0.9646\n",
            "Epoch 25/300\n",
            "10000/10000 [==============================] - 29s 3ms/sample - loss: 19.8937 - dense_2_loss: 3.9504 - dense_2_1_loss: 5.1010 - dense_2_2_loss: 4.9464 - dense_2_3_loss: 2.8921 - dense_2_4_loss: 1.6105 - dense_2_5_loss: 0.8287 - dense_2_6_loss: 0.4007 - dense_2_7_loss: 0.1672 - dense_2_accuracy: 0.2319 - dense_2_1_accuracy: 0.1169 - dense_2_2_accuracy: 0.2104 - dense_2_3_accuracy: 0.5041 - dense_2_4_accuracy: 0.6687 - dense_2_5_accuracy: 0.8017 - dense_2_6_accuracy: 0.8983 - dense_2_7_accuracy: 0.9645\n",
            "Epoch 26/300\n",
            "10000/10000 [==============================] - 29s 3ms/sample - loss: 19.8595 - dense_2_loss: 3.9427 - dense_2_1_loss: 5.0939 - dense_2_2_loss: 4.9396 - dense_2_3_loss: 2.8835 - dense_2_4_loss: 1.6064 - dense_2_5_loss: 0.8272 - dense_2_6_loss: 0.3994 - dense_2_7_loss: 0.1671 - dense_2_accuracy: 0.2322 - dense_2_1_accuracy: 0.1172 - dense_2_2_accuracy: 0.2102 - dense_2_3_accuracy: 0.5041 - dense_2_4_accuracy: 0.6667 - dense_2_5_accuracy: 0.7986 - dense_2_6_accuracy: 0.8994 - dense_2_7_accuracy: 0.9651\n",
            "Epoch 27/300\n",
            "10000/10000 [==============================] - 29s 3ms/sample - loss: 19.8255 - dense_2_loss: 3.9346 - dense_2_1_loss: 5.0881 - dense_2_2_loss: 4.9315 - dense_2_3_loss: 2.8770 - dense_2_4_loss: 1.6041 - dense_2_5_loss: 0.8268 - dense_2_6_loss: 0.4002 - dense_2_7_loss: 0.1675 - dense_2_accuracy: 0.2328 - dense_2_1_accuracy: 0.1176 - dense_2_2_accuracy: 0.2098 - dense_2_3_accuracy: 0.5047 - dense_2_4_accuracy: 0.6684 - dense_2_5_accuracy: 0.8014 - dense_2_6_accuracy: 0.8988 - dense_2_7_accuracy: 0.9645\n",
            "Epoch 28/300\n",
            "10000/10000 [==============================] - 29s 3ms/sample - loss: 19.7893 - dense_2_loss: 3.9248 - dense_2_1_loss: 5.0837 - dense_2_2_loss: 4.9249 - dense_2_3_loss: 2.8689 - dense_2_4_loss: 1.5997 - dense_2_5_loss: 0.8254 - dense_2_6_loss: 0.3989 - dense_2_7_loss: 0.1675 - dense_2_accuracy: 0.2334 - dense_2_1_accuracy: 0.1184 - dense_2_2_accuracy: 0.2109 - dense_2_3_accuracy: 0.5054 - dense_2_4_accuracy: 0.6695 - dense_2_5_accuracy: 0.8006 - dense_2_6_accuracy: 0.8996 - dense_2_7_accuracy: 0.9651\n",
            "Epoch 29/300\n",
            "10000/10000 [==============================] - 29s 3ms/sample - loss: 19.7603 - dense_2_loss: 3.9162 - dense_2_1_loss: 5.0776 - dense_2_2_loss: 4.9198 - dense_2_3_loss: 2.8640 - dense_2_4_loss: 1.5997 - dense_2_5_loss: 0.8239 - dense_2_6_loss: 0.3982 - dense_2_7_loss: 0.1667 - dense_2_accuracy: 0.2335 - dense_2_1_accuracy: 0.1178 - dense_2_2_accuracy: 0.2097 - dense_2_3_accuracy: 0.5058 - dense_2_4_accuracy: 0.6680 - dense_2_5_accuracy: 0.8013 - dense_2_6_accuracy: 0.9006 - dense_2_7_accuracy: 0.9650\n",
            "Epoch 30/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.7230 - dense_2_loss: 3.9073 - dense_2_1_loss: 5.0737 - dense_2_2_loss: 4.9106 - dense_2_3_loss: 2.8526 - dense_2_4_loss: 1.5935 - dense_2_5_loss: 0.8203 - dense_2_6_loss: 0.3966 - dense_2_7_loss: 0.1662 - dense_2_accuracy: 0.2341 - dense_2_1_accuracy: 0.1184 - dense_2_2_accuracy: 0.2116 - dense_2_3_accuracy: 0.5063 - dense_2_4_accuracy: 0.6701 - dense_2_5_accuracy: 0.8021 - dense_2_6_accuracy: 0.8998 - dense_2_7_accuracy: 0.9653\n",
            "Epoch 31/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.6921 - dense_2_loss: 3.8997 - dense_2_1_loss: 5.0717 - dense_2_2_loss: 4.9016 - dense_2_3_loss: 2.8490 - dense_2_4_loss: 1.5903 - dense_2_5_loss: 0.8192 - dense_2_6_loss: 0.3963 - dense_2_7_loss: 0.1663 - dense_2_accuracy: 0.2345 - dense_2_1_accuracy: 0.1180 - dense_2_2_accuracy: 0.2163 - dense_2_3_accuracy: 0.5061 - dense_2_4_accuracy: 0.6701 - dense_2_5_accuracy: 0.8022 - dense_2_6_accuracy: 0.8999 - dense_2_7_accuracy: 0.9653\n",
            "Epoch 32/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.6585 - dense_2_loss: 3.8955 - dense_2_1_loss: 5.0645 - dense_2_2_loss: 4.8953 - dense_2_3_loss: 2.8428 - dense_2_4_loss: 1.5878 - dense_2_5_loss: 0.8179 - dense_2_6_loss: 0.3957 - dense_2_7_loss: 0.1660 - dense_2_accuracy: 0.2354 - dense_2_1_accuracy: 0.1183 - dense_2_2_accuracy: 0.2295 - dense_2_3_accuracy: 0.5122 - dense_2_4_accuracy: 0.6683 - dense_2_5_accuracy: 0.8024 - dense_2_6_accuracy: 0.8997 - dense_2_7_accuracy: 0.9650\n",
            "Epoch 33/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.6292 - dense_2_loss: 3.8842 - dense_2_1_loss: 5.0587 - dense_2_2_loss: 4.8903 - dense_2_3_loss: 2.8352 - dense_2_4_loss: 1.5832 - dense_2_5_loss: 0.8153 - dense_2_6_loss: 0.3942 - dense_2_7_loss: 0.1652 - dense_2_accuracy: 0.2360 - dense_2_1_accuracy: 0.1186 - dense_2_2_accuracy: 0.2425 - dense_2_3_accuracy: 0.5143 - dense_2_4_accuracy: 0.6707 - dense_2_5_accuracy: 0.8038 - dense_2_6_accuracy: 0.9011 - dense_2_7_accuracy: 0.9656\n",
            "Epoch 34/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.6008 - dense_2_loss: 3.8799 - dense_2_1_loss: 5.0554 - dense_2_2_loss: 4.8861 - dense_2_3_loss: 2.8281 - dense_2_4_loss: 1.5818 - dense_2_5_loss: 0.8134 - dense_2_6_loss: 0.3935 - dense_2_7_loss: 0.1652 - dense_2_accuracy: 0.2361 - dense_2_1_accuracy: 0.1188 - dense_2_2_accuracy: 0.2546 - dense_2_3_accuracy: 0.5176 - dense_2_4_accuracy: 0.6690 - dense_2_5_accuracy: 0.8030 - dense_2_6_accuracy: 0.9005 - dense_2_7_accuracy: 0.9652\n",
            "Epoch 35/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.5711 - dense_2_loss: 3.8731 - dense_2_1_loss: 5.0525 - dense_2_2_loss: 4.8776 - dense_2_3_loss: 2.8247 - dense_2_4_loss: 1.5786 - dense_2_5_loss: 0.8123 - dense_2_6_loss: 0.3935 - dense_2_7_loss: 0.1654 - dense_2_accuracy: 0.2364 - dense_2_1_accuracy: 0.1187 - dense_2_2_accuracy: 0.2574 - dense_2_3_accuracy: 0.5205 - dense_2_4_accuracy: 0.6719 - dense_2_5_accuracy: 0.8045 - dense_2_6_accuracy: 0.8999 - dense_2_7_accuracy: 0.9654\n",
            "Epoch 36/300\n",
            "10000/10000 [==============================] - 29s 3ms/sample - loss: 19.5456 - dense_2_loss: 3.8650 - dense_2_1_loss: 5.0486 - dense_2_2_loss: 4.8739 - dense_2_3_loss: 2.8197 - dense_2_4_loss: 1.5740 - dense_2_5_loss: 0.8096 - dense_2_6_loss: 0.3923 - dense_2_7_loss: 0.1646 - dense_2_accuracy: 0.2368 - dense_2_1_accuracy: 0.1184 - dense_2_2_accuracy: 0.2572 - dense_2_3_accuracy: 0.5229 - dense_2_4_accuracy: 0.6710 - dense_2_5_accuracy: 0.8035 - dense_2_6_accuracy: 0.9009 - dense_2_7_accuracy: 0.9654\n",
            "Epoch 37/300\n",
            "10000/10000 [==============================] - 29s 3ms/sample - loss: 19.5196 - dense_2_loss: 3.8596 - dense_2_1_loss: 5.0425 - dense_2_2_loss: 4.8693 - dense_2_3_loss: 2.8122 - dense_2_4_loss: 1.5708 - dense_2_5_loss: 0.8093 - dense_2_6_loss: 0.3918 - dense_2_7_loss: 0.1649 - dense_2_accuracy: 0.2365 - dense_2_1_accuracy: 0.1197 - dense_2_2_accuracy: 0.2581 - dense_2_3_accuracy: 0.5238 - dense_2_4_accuracy: 0.6731 - dense_2_5_accuracy: 0.8042 - dense_2_6_accuracy: 0.9014 - dense_2_7_accuracy: 0.9655\n",
            "Epoch 38/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.4929 - dense_2_loss: 3.8554 - dense_2_1_loss: 5.0383 - dense_2_2_loss: 4.8608 - dense_2_3_loss: 2.8090 - dense_2_4_loss: 1.5684 - dense_2_5_loss: 0.8090 - dense_2_6_loss: 0.3921 - dense_2_7_loss: 0.1648 - dense_2_accuracy: 0.2367 - dense_2_1_accuracy: 0.1200 - dense_2_2_accuracy: 0.2587 - dense_2_3_accuracy: 0.5261 - dense_2_4_accuracy: 0.6737 - dense_2_5_accuracy: 0.8054 - dense_2_6_accuracy: 0.9026 - dense_2_7_accuracy: 0.9654\n",
            "Epoch 39/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.4707 - dense_2_loss: 3.8485 - dense_2_1_loss: 5.0367 - dense_2_2_loss: 4.8557 - dense_2_3_loss: 2.8067 - dense_2_4_loss: 1.5658 - dense_2_5_loss: 0.8067 - dense_2_6_loss: 0.3906 - dense_2_7_loss: 0.1641 - dense_2_accuracy: 0.2368 - dense_2_1_accuracy: 0.1211 - dense_2_2_accuracy: 0.2577 - dense_2_3_accuracy: 0.5266 - dense_2_4_accuracy: 0.6718 - dense_2_5_accuracy: 0.8040 - dense_2_6_accuracy: 0.9012 - dense_2_7_accuracy: 0.9655\n",
            "Epoch 40/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.4483 - dense_2_loss: 3.8458 - dense_2_1_loss: 5.0325 - dense_2_2_loss: 4.8470 - dense_2_3_loss: 2.7979 - dense_2_4_loss: 1.5617 - dense_2_5_loss: 0.8044 - dense_2_6_loss: 0.3895 - dense_2_7_loss: 0.1640 - dense_2_accuracy: 0.2369 - dense_2_1_accuracy: 0.1211 - dense_2_2_accuracy: 0.2590 - dense_2_3_accuracy: 0.5282 - dense_2_4_accuracy: 0.6738 - dense_2_5_accuracy: 0.8038 - dense_2_6_accuracy: 0.9019 - dense_2_7_accuracy: 0.9655\n",
            "Epoch 41/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.4256 - dense_2_loss: 3.8386 - dense_2_1_loss: 5.0264 - dense_2_2_loss: 4.8483 - dense_2_3_loss: 2.7961 - dense_2_4_loss: 1.5600 - dense_2_5_loss: 0.8043 - dense_2_6_loss: 0.3888 - dense_2_7_loss: 0.1636 - dense_2_accuracy: 0.2372 - dense_2_1_accuracy: 0.1226 - dense_2_2_accuracy: 0.2572 - dense_2_3_accuracy: 0.5287 - dense_2_4_accuracy: 0.6748 - dense_2_5_accuracy: 0.8049 - dense_2_6_accuracy: 0.9023 - dense_2_7_accuracy: 0.9654\n",
            "Epoch 42/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.4061 - dense_2_loss: 3.8341 - dense_2_1_loss: 5.0238 - dense_2_2_loss: 4.8420 - dense_2_3_loss: 2.7918 - dense_2_4_loss: 1.5576 - dense_2_5_loss: 0.8038 - dense_2_6_loss: 0.3881 - dense_2_7_loss: 0.1633 - dense_2_accuracy: 0.2375 - dense_2_1_accuracy: 0.1229 - dense_2_2_accuracy: 0.2585 - dense_2_3_accuracy: 0.5280 - dense_2_4_accuracy: 0.6746 - dense_2_5_accuracy: 0.8064 - dense_2_6_accuracy: 0.9014 - dense_2_7_accuracy: 0.9656\n",
            "Epoch 43/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.3837 - dense_2_loss: 3.8294 - dense_2_1_loss: 5.0202 - dense_2_2_loss: 4.8376 - dense_2_3_loss: 2.7861 - dense_2_4_loss: 1.5544 - dense_2_5_loss: 0.8019 - dense_2_6_loss: 0.3882 - dense_2_7_loss: 0.1633 - dense_2_accuracy: 0.2369 - dense_2_1_accuracy: 0.1244 - dense_2_2_accuracy: 0.2606 - dense_2_3_accuracy: 0.5309 - dense_2_4_accuracy: 0.6750 - dense_2_5_accuracy: 0.8053 - dense_2_6_accuracy: 0.9026 - dense_2_7_accuracy: 0.9655\n",
            "Epoch 44/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.3657 - dense_2_loss: 3.8255 - dense_2_1_loss: 5.0156 - dense_2_2_loss: 4.8324 - dense_2_3_loss: 2.7843 - dense_2_4_loss: 1.5535 - dense_2_5_loss: 0.8020 - dense_2_6_loss: 0.3879 - dense_2_7_loss: 0.1631 - dense_2_accuracy: 0.2378 - dense_2_1_accuracy: 0.1247 - dense_2_2_accuracy: 0.2591 - dense_2_3_accuracy: 0.5314 - dense_2_4_accuracy: 0.6777 - dense_2_5_accuracy: 0.8067 - dense_2_6_accuracy: 0.9016 - dense_2_7_accuracy: 0.9655\n",
            "Epoch 45/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.3469 - dense_2_loss: 3.8216 - dense_2_1_loss: 5.0144 - dense_2_2_loss: 4.8298 - dense_2_3_loss: 2.7799 - dense_2_4_loss: 1.5505 - dense_2_5_loss: 0.8012 - dense_2_6_loss: 0.3871 - dense_2_7_loss: 0.1631 - dense_2_accuracy: 0.2374 - dense_2_1_accuracy: 0.1261 - dense_2_2_accuracy: 0.2590 - dense_2_3_accuracy: 0.5311 - dense_2_4_accuracy: 0.6764 - dense_2_5_accuracy: 0.8055 - dense_2_6_accuracy: 0.9019 - dense_2_7_accuracy: 0.9658\n",
            "Epoch 46/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.3270 - dense_2_loss: 3.8191 - dense_2_1_loss: 5.0111 - dense_2_2_loss: 4.8233 - dense_2_3_loss: 2.7751 - dense_2_4_loss: 1.5485 - dense_2_5_loss: 0.8005 - dense_2_6_loss: 0.3868 - dense_2_7_loss: 0.1626 - dense_2_accuracy: 0.2371 - dense_2_1_accuracy: 0.1265 - dense_2_2_accuracy: 0.2604 - dense_2_3_accuracy: 0.5324 - dense_2_4_accuracy: 0.6760 - dense_2_5_accuracy: 0.8064 - dense_2_6_accuracy: 0.9025 - dense_2_7_accuracy: 0.9659\n",
            "Epoch 47/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.3079 - dense_2_loss: 3.8128 - dense_2_1_loss: 5.0073 - dense_2_2_loss: 4.8195 - dense_2_3_loss: 2.7699 - dense_2_4_loss: 1.5456 - dense_2_5_loss: 0.7988 - dense_2_6_loss: 0.3858 - dense_2_7_loss: 0.1624 - dense_2_accuracy: 0.2379 - dense_2_1_accuracy: 0.1274 - dense_2_2_accuracy: 0.2592 - dense_2_3_accuracy: 0.5317 - dense_2_4_accuracy: 0.6769 - dense_2_5_accuracy: 0.8053 - dense_2_6_accuracy: 0.9032 - dense_2_7_accuracy: 0.9658\n",
            "Epoch 48/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.2901 - dense_2_loss: 3.8068 - dense_2_1_loss: 5.0024 - dense_2_2_loss: 4.8177 - dense_2_3_loss: 2.7679 - dense_2_4_loss: 1.5457 - dense_2_5_loss: 0.7989 - dense_2_6_loss: 0.3862 - dense_2_7_loss: 0.1626 - dense_2_accuracy: 0.2372 - dense_2_1_accuracy: 0.1277 - dense_2_2_accuracy: 0.2592 - dense_2_3_accuracy: 0.5326 - dense_2_4_accuracy: 0.6788 - dense_2_5_accuracy: 0.8067 - dense_2_6_accuracy: 0.9022 - dense_2_7_accuracy: 0.9659\n",
            "Epoch 49/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.2753 - dense_2_loss: 3.8060 - dense_2_1_loss: 5.0001 - dense_2_2_loss: 4.8129 - dense_2_3_loss: 2.7657 - dense_2_4_loss: 1.5423 - dense_2_5_loss: 0.7979 - dense_2_6_loss: 0.3850 - dense_2_7_loss: 0.1622 - dense_2_accuracy: 0.2376 - dense_2_1_accuracy: 0.1279 - dense_2_2_accuracy: 0.2589 - dense_2_3_accuracy: 0.5324 - dense_2_4_accuracy: 0.6779 - dense_2_5_accuracy: 0.8061 - dense_2_6_accuracy: 0.9025 - dense_2_7_accuracy: 0.9656\n",
            "Epoch 50/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.2560 - dense_2_loss: 3.8026 - dense_2_1_loss: 4.9980 - dense_2_2_loss: 4.8102 - dense_2_3_loss: 2.7640 - dense_2_4_loss: 1.5415 - dense_2_5_loss: 0.7970 - dense_2_6_loss: 0.3855 - dense_2_7_loss: 0.1624 - dense_2_accuracy: 0.2387 - dense_2_1_accuracy: 0.1285 - dense_2_2_accuracy: 0.2597 - dense_2_3_accuracy: 0.5320 - dense_2_4_accuracy: 0.6795 - dense_2_5_accuracy: 0.8070 - dense_2_6_accuracy: 0.9046 - dense_2_7_accuracy: 0.9655\n",
            "Epoch 51/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.2410 - dense_2_loss: 3.7987 - dense_2_1_loss: 4.9934 - dense_2_2_loss: 4.8047 - dense_2_3_loss: 2.7586 - dense_2_4_loss: 1.5381 - dense_2_5_loss: 0.7958 - dense_2_6_loss: 0.3846 - dense_2_7_loss: 0.1620 - dense_2_accuracy: 0.2382 - dense_2_1_accuracy: 0.1294 - dense_2_2_accuracy: 0.2603 - dense_2_3_accuracy: 0.5344 - dense_2_4_accuracy: 0.6792 - dense_2_5_accuracy: 0.8060 - dense_2_6_accuracy: 0.9036 - dense_2_7_accuracy: 0.9659\n",
            "Epoch 52/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.2262 - dense_2_loss: 3.7931 - dense_2_1_loss: 4.9907 - dense_2_2_loss: 4.8009 - dense_2_3_loss: 2.7590 - dense_2_4_loss: 1.5384 - dense_2_5_loss: 0.7954 - dense_2_6_loss: 0.3840 - dense_2_7_loss: 0.1615 - dense_2_accuracy: 0.2386 - dense_2_1_accuracy: 0.1287 - dense_2_2_accuracy: 0.2631 - dense_2_3_accuracy: 0.5326 - dense_2_4_accuracy: 0.6788 - dense_2_5_accuracy: 0.8067 - dense_2_6_accuracy: 0.9032 - dense_2_7_accuracy: 0.9660\n",
            "Epoch 53/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.2108 - dense_2_loss: 3.7910 - dense_2_1_loss: 4.9871 - dense_2_2_loss: 4.7993 - dense_2_3_loss: 2.7549 - dense_2_4_loss: 1.5349 - dense_2_5_loss: 0.7952 - dense_2_6_loss: 0.3837 - dense_2_7_loss: 0.1616 - dense_2_accuracy: 0.2386 - dense_2_1_accuracy: 0.1293 - dense_2_2_accuracy: 0.2625 - dense_2_3_accuracy: 0.5329 - dense_2_4_accuracy: 0.6792 - dense_2_5_accuracy: 0.8052 - dense_2_6_accuracy: 0.9035 - dense_2_7_accuracy: 0.9658\n",
            "Epoch 54/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.1950 - dense_2_loss: 3.7881 - dense_2_1_loss: 4.9845 - dense_2_2_loss: 4.7963 - dense_2_3_loss: 2.7541 - dense_2_4_loss: 1.5358 - dense_2_5_loss: 0.7949 - dense_2_6_loss: 0.3836 - dense_2_7_loss: 0.1614 - dense_2_accuracy: 0.2387 - dense_2_1_accuracy: 0.1299 - dense_2_2_accuracy: 0.2633 - dense_2_3_accuracy: 0.5340 - dense_2_4_accuracy: 0.6822 - dense_2_5_accuracy: 0.8081 - dense_2_6_accuracy: 0.9032 - dense_2_7_accuracy: 0.9660\n",
            "Epoch 55/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.1810 - dense_2_loss: 3.7848 - dense_2_1_loss: 4.9830 - dense_2_2_loss: 4.7928 - dense_2_3_loss: 2.7491 - dense_2_4_loss: 1.5320 - dense_2_5_loss: 0.7931 - dense_2_6_loss: 0.3832 - dense_2_7_loss: 0.1613 - dense_2_accuracy: 0.2394 - dense_2_1_accuracy: 0.1304 - dense_2_2_accuracy: 0.2628 - dense_2_3_accuracy: 0.5341 - dense_2_4_accuracy: 0.6811 - dense_2_5_accuracy: 0.8084 - dense_2_6_accuracy: 0.9048 - dense_2_7_accuracy: 0.9659\n",
            "Epoch 56/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.1665 - dense_2_loss: 3.7796 - dense_2_1_loss: 4.9778 - dense_2_2_loss: 4.7890 - dense_2_3_loss: 2.7501 - dense_2_4_loss: 1.5326 - dense_2_5_loss: 0.7936 - dense_2_6_loss: 0.3829 - dense_2_7_loss: 0.1617 - dense_2_accuracy: 0.2395 - dense_2_1_accuracy: 0.1319 - dense_2_2_accuracy: 0.2644 - dense_2_3_accuracy: 0.5341 - dense_2_4_accuracy: 0.6799 - dense_2_5_accuracy: 0.8080 - dense_2_6_accuracy: 0.9037 - dense_2_7_accuracy: 0.9655\n",
            "Epoch 57/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.1524 - dense_2_loss: 3.7763 - dense_2_1_loss: 4.9755 - dense_2_2_loss: 4.7882 - dense_2_3_loss: 2.7462 - dense_2_4_loss: 1.5299 - dense_2_5_loss: 0.7926 - dense_2_6_loss: 0.3830 - dense_2_7_loss: 0.1615 - dense_2_accuracy: 0.2400 - dense_2_1_accuracy: 0.1319 - dense_2_2_accuracy: 0.2650 - dense_2_3_accuracy: 0.5356 - dense_2_4_accuracy: 0.6832 - dense_2_5_accuracy: 0.8092 - dense_2_6_accuracy: 0.9041 - dense_2_7_accuracy: 0.9653\n",
            "Epoch 58/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.1432 - dense_2_loss: 3.7725 - dense_2_1_loss: 4.9732 - dense_2_2_loss: 4.7849 - dense_2_3_loss: 2.7456 - dense_2_4_loss: 1.5309 - dense_2_5_loss: 0.7926 - dense_2_6_loss: 0.3828 - dense_2_7_loss: 0.1612 - dense_2_accuracy: 0.2401 - dense_2_1_accuracy: 0.1316 - dense_2_2_accuracy: 0.2662 - dense_2_3_accuracy: 0.5363 - dense_2_4_accuracy: 0.6826 - dense_2_5_accuracy: 0.8074 - dense_2_6_accuracy: 0.9040 - dense_2_7_accuracy: 0.9662\n",
            "Epoch 59/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.1273 - dense_2_loss: 3.7729 - dense_2_1_loss: 4.9707 - dense_2_2_loss: 4.7810 - dense_2_3_loss: 2.7429 - dense_2_4_loss: 1.5271 - dense_2_5_loss: 0.7921 - dense_2_6_loss: 0.3824 - dense_2_7_loss: 0.1614 - dense_2_accuracy: 0.2405 - dense_2_1_accuracy: 0.1321 - dense_2_2_accuracy: 0.2666 - dense_2_3_accuracy: 0.5356 - dense_2_4_accuracy: 0.6822 - dense_2_5_accuracy: 0.8082 - dense_2_6_accuracy: 0.9047 - dense_2_7_accuracy: 0.9659\n",
            "Epoch 60/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.1172 - dense_2_loss: 3.7680 - dense_2_1_loss: 4.9672 - dense_2_2_loss: 4.7783 - dense_2_3_loss: 2.7430 - dense_2_4_loss: 1.5276 - dense_2_5_loss: 0.7919 - dense_2_6_loss: 0.3822 - dense_2_7_loss: 0.1608 - dense_2_accuracy: 0.2404 - dense_2_1_accuracy: 0.1326 - dense_2_2_accuracy: 0.2673 - dense_2_3_accuracy: 0.5343 - dense_2_4_accuracy: 0.6815 - dense_2_5_accuracy: 0.8085 - dense_2_6_accuracy: 0.9040 - dense_2_7_accuracy: 0.9660\n",
            "Epoch 61/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.1030 - dense_2_loss: 3.7631 - dense_2_1_loss: 4.9641 - dense_2_2_loss: 4.7772 - dense_2_3_loss: 2.7411 - dense_2_4_loss: 1.5264 - dense_2_5_loss: 0.7915 - dense_2_6_loss: 0.3822 - dense_2_7_loss: 0.1613 - dense_2_accuracy: 0.2401 - dense_2_1_accuracy: 0.1321 - dense_2_2_accuracy: 0.2677 - dense_2_3_accuracy: 0.5361 - dense_2_4_accuracy: 0.6822 - dense_2_5_accuracy: 0.8085 - dense_2_6_accuracy: 0.9041 - dense_2_7_accuracy: 0.9654\n",
            "Epoch 62/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.0918 - dense_2_loss: 3.7608 - dense_2_1_loss: 4.9620 - dense_2_2_loss: 4.7736 - dense_2_3_loss: 2.7381 - dense_2_4_loss: 1.5249 - dense_2_5_loss: 0.7917 - dense_2_6_loss: 0.3823 - dense_2_7_loss: 0.1617 - dense_2_accuracy: 0.2408 - dense_2_1_accuracy: 0.1331 - dense_2_2_accuracy: 0.2682 - dense_2_3_accuracy: 0.5363 - dense_2_4_accuracy: 0.6829 - dense_2_5_accuracy: 0.8081 - dense_2_6_accuracy: 0.9045 - dense_2_7_accuracy: 0.9659\n",
            "Epoch 63/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.0793 - dense_2_loss: 3.7566 - dense_2_1_loss: 4.9579 - dense_2_2_loss: 4.7696 - dense_2_3_loss: 2.7349 - dense_2_4_loss: 1.5228 - dense_2_5_loss: 0.7896 - dense_2_6_loss: 0.3812 - dense_2_7_loss: 0.1607 - dense_2_accuracy: 0.2413 - dense_2_1_accuracy: 0.1337 - dense_2_2_accuracy: 0.2678 - dense_2_3_accuracy: 0.5371 - dense_2_4_accuracy: 0.6830 - dense_2_5_accuracy: 0.8090 - dense_2_6_accuracy: 0.9041 - dense_2_7_accuracy: 0.9659\n",
            "Epoch 64/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.0690 - dense_2_loss: 3.7554 - dense_2_1_loss: 4.9561 - dense_2_2_loss: 4.7690 - dense_2_3_loss: 2.7348 - dense_2_4_loss: 1.5216 - dense_2_5_loss: 0.7885 - dense_2_6_loss: 0.3807 - dense_2_7_loss: 0.1607 - dense_2_accuracy: 0.2419 - dense_2_1_accuracy: 0.1339 - dense_2_2_accuracy: 0.2685 - dense_2_3_accuracy: 0.5360 - dense_2_4_accuracy: 0.6833 - dense_2_5_accuracy: 0.8107 - dense_2_6_accuracy: 0.9051 - dense_2_7_accuracy: 0.9657\n",
            "Epoch 65/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.0565 - dense_2_loss: 3.7535 - dense_2_1_loss: 4.9532 - dense_2_2_loss: 4.7669 - dense_2_3_loss: 2.7331 - dense_2_4_loss: 1.5221 - dense_2_5_loss: 0.7903 - dense_2_6_loss: 0.3818 - dense_2_7_loss: 0.1610 - dense_2_accuracy: 0.2413 - dense_2_1_accuracy: 0.1340 - dense_2_2_accuracy: 0.2689 - dense_2_3_accuracy: 0.5378 - dense_2_4_accuracy: 0.6844 - dense_2_5_accuracy: 0.8108 - dense_2_6_accuracy: 0.9060 - dense_2_7_accuracy: 0.9657\n",
            "Epoch 66/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.0455 - dense_2_loss: 3.7498 - dense_2_1_loss: 4.9509 - dense_2_2_loss: 4.7626 - dense_2_3_loss: 2.7309 - dense_2_4_loss: 1.5218 - dense_2_5_loss: 0.7890 - dense_2_6_loss: 0.3809 - dense_2_7_loss: 0.1605 - dense_2_accuracy: 0.2424 - dense_2_1_accuracy: 0.1346 - dense_2_2_accuracy: 0.2700 - dense_2_3_accuracy: 0.5380 - dense_2_4_accuracy: 0.6847 - dense_2_5_accuracy: 0.8112 - dense_2_6_accuracy: 0.9056 - dense_2_7_accuracy: 0.9659\n",
            "Epoch 67/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.0359 - dense_2_loss: 3.7489 - dense_2_1_loss: 4.9476 - dense_2_2_loss: 4.7639 - dense_2_3_loss: 2.7295 - dense_2_4_loss: 1.5187 - dense_2_5_loss: 0.7881 - dense_2_6_loss: 0.3804 - dense_2_7_loss: 0.1604 - dense_2_accuracy: 0.2420 - dense_2_1_accuracy: 0.1352 - dense_2_2_accuracy: 0.2695 - dense_2_3_accuracy: 0.5380 - dense_2_4_accuracy: 0.6853 - dense_2_5_accuracy: 0.8106 - dense_2_6_accuracy: 0.9053 - dense_2_7_accuracy: 0.9658\n",
            "Epoch 68/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.0238 - dense_2_loss: 3.7421 - dense_2_1_loss: 4.9456 - dense_2_2_loss: 4.7598 - dense_2_3_loss: 2.7269 - dense_2_4_loss: 1.5169 - dense_2_5_loss: 0.7872 - dense_2_6_loss: 0.3800 - dense_2_7_loss: 0.1603 - dense_2_accuracy: 0.2440 - dense_2_1_accuracy: 0.1359 - dense_2_2_accuracy: 0.2710 - dense_2_3_accuracy: 0.5388 - dense_2_4_accuracy: 0.6862 - dense_2_5_accuracy: 0.8104 - dense_2_6_accuracy: 0.9058 - dense_2_7_accuracy: 0.9657\n",
            "Epoch 69/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.0135 - dense_2_loss: 3.7420 - dense_2_1_loss: 4.9425 - dense_2_2_loss: 4.7593 - dense_2_3_loss: 2.7269 - dense_2_4_loss: 1.5192 - dense_2_5_loss: 0.7883 - dense_2_6_loss: 0.3808 - dense_2_7_loss: 0.1614 - dense_2_accuracy: 0.2441 - dense_2_1_accuracy: 0.1356 - dense_2_2_accuracy: 0.2716 - dense_2_3_accuracy: 0.5380 - dense_2_4_accuracy: 0.6856 - dense_2_5_accuracy: 0.8111 - dense_2_6_accuracy: 0.9059 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 70/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 19.0031 - dense_2_loss: 3.7392 - dense_2_1_loss: 4.9410 - dense_2_2_loss: 4.7555 - dense_2_3_loss: 2.7250 - dense_2_4_loss: 1.5171 - dense_2_5_loss: 0.7868 - dense_2_6_loss: 0.3800 - dense_2_7_loss: 0.1600 - dense_2_accuracy: 0.2445 - dense_2_1_accuracy: 0.1365 - dense_2_2_accuracy: 0.2709 - dense_2_3_accuracy: 0.5393 - dense_2_4_accuracy: 0.6866 - dense_2_5_accuracy: 0.8109 - dense_2_6_accuracy: 0.9062 - dense_2_7_accuracy: 0.9661\n",
            "Epoch 71/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.9929 - dense_2_loss: 3.7376 - dense_2_1_loss: 4.9390 - dense_2_2_loss: 4.7518 - dense_2_3_loss: 2.7220 - dense_2_4_loss: 1.5160 - dense_2_5_loss: 0.7869 - dense_2_6_loss: 0.3799 - dense_2_7_loss: 0.1601 - dense_2_accuracy: 0.2437 - dense_2_1_accuracy: 0.1365 - dense_2_2_accuracy: 0.2731 - dense_2_3_accuracy: 0.5392 - dense_2_4_accuracy: 0.6848 - dense_2_5_accuracy: 0.8104 - dense_2_6_accuracy: 0.9060 - dense_2_7_accuracy: 0.9661\n",
            "Epoch 72/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 18.9832 - dense_2_loss: 3.7348 - dense_2_1_loss: 4.9356 - dense_2_2_loss: 4.7500 - dense_2_3_loss: 2.7207 - dense_2_4_loss: 1.5144 - dense_2_5_loss: 0.7872 - dense_2_6_loss: 0.3793 - dense_2_7_loss: 0.1601 - dense_2_accuracy: 0.2449 - dense_2_1_accuracy: 0.1374 - dense_2_2_accuracy: 0.2726 - dense_2_3_accuracy: 0.5391 - dense_2_4_accuracy: 0.6871 - dense_2_5_accuracy: 0.8114 - dense_2_6_accuracy: 0.9061 - dense_2_7_accuracy: 0.9661\n",
            "Epoch 73/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 18.9746 - dense_2_loss: 3.7327 - dense_2_1_loss: 4.9341 - dense_2_2_loss: 4.7496 - dense_2_3_loss: 2.7234 - dense_2_4_loss: 1.5149 - dense_2_5_loss: 0.7864 - dense_2_6_loss: 0.3802 - dense_2_7_loss: 0.1604 - dense_2_accuracy: 0.2453 - dense_2_1_accuracy: 0.1389 - dense_2_2_accuracy: 0.2722 - dense_2_3_accuracy: 0.5397 - dense_2_4_accuracy: 0.6866 - dense_2_5_accuracy: 0.8104 - dense_2_6_accuracy: 0.9063 - dense_2_7_accuracy: 0.9659\n",
            "Epoch 74/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 18.9639 - dense_2_loss: 3.7289 - dense_2_1_loss: 4.9321 - dense_2_2_loss: 4.7473 - dense_2_3_loss: 2.7183 - dense_2_4_loss: 1.5135 - dense_2_5_loss: 0.7858 - dense_2_6_loss: 0.3788 - dense_2_7_loss: 0.1600 - dense_2_accuracy: 0.2455 - dense_2_1_accuracy: 0.1386 - dense_2_2_accuracy: 0.2723 - dense_2_3_accuracy: 0.5405 - dense_2_4_accuracy: 0.6860 - dense_2_5_accuracy: 0.8109 - dense_2_6_accuracy: 0.9068 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 75/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 18.9542 - dense_2_loss: 3.7258 - dense_2_1_loss: 4.9293 - dense_2_2_loss: 4.7453 - dense_2_3_loss: 2.7176 - dense_2_4_loss: 1.5125 - dense_2_5_loss: 0.7844 - dense_2_6_loss: 0.3784 - dense_2_7_loss: 0.1596 - dense_2_accuracy: 0.2458 - dense_2_1_accuracy: 0.1391 - dense_2_2_accuracy: 0.2727 - dense_2_3_accuracy: 0.5401 - dense_2_4_accuracy: 0.6855 - dense_2_5_accuracy: 0.8121 - dense_2_6_accuracy: 0.9068 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 76/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 18.9441 - dense_2_loss: 3.7224 - dense_2_1_loss: 4.9267 - dense_2_2_loss: 4.7450 - dense_2_3_loss: 2.7160 - dense_2_4_loss: 1.5127 - dense_2_5_loss: 0.7856 - dense_2_6_loss: 0.3795 - dense_2_7_loss: 0.1602 - dense_2_accuracy: 0.2463 - dense_2_1_accuracy: 0.1396 - dense_2_2_accuracy: 0.2730 - dense_2_3_accuracy: 0.5417 - dense_2_4_accuracy: 0.6869 - dense_2_5_accuracy: 0.8113 - dense_2_6_accuracy: 0.9061 - dense_2_7_accuracy: 0.9662\n",
            "Epoch 77/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 18.9345 - dense_2_loss: 3.7199 - dense_2_1_loss: 4.9235 - dense_2_2_loss: 4.7404 - dense_2_3_loss: 2.7160 - dense_2_4_loss: 1.5103 - dense_2_5_loss: 0.7846 - dense_2_6_loss: 0.3788 - dense_2_7_loss: 0.1601 - dense_2_accuracy: 0.2468 - dense_2_1_accuracy: 0.1415 - dense_2_2_accuracy: 0.2746 - dense_2_3_accuracy: 0.5405 - dense_2_4_accuracy: 0.6873 - dense_2_5_accuracy: 0.8125 - dense_2_6_accuracy: 0.9071 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 78/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 18.9263 - dense_2_loss: 3.7182 - dense_2_1_loss: 4.9222 - dense_2_2_loss: 4.7406 - dense_2_3_loss: 2.7138 - dense_2_4_loss: 1.5118 - dense_2_5_loss: 0.7836 - dense_2_6_loss: 0.3786 - dense_2_7_loss: 0.1595 - dense_2_accuracy: 0.2470 - dense_2_1_accuracy: 0.1425 - dense_2_2_accuracy: 0.2747 - dense_2_3_accuracy: 0.5407 - dense_2_4_accuracy: 0.6873 - dense_2_5_accuracy: 0.8121 - dense_2_6_accuracy: 0.9060 - dense_2_7_accuracy: 0.9659\n",
            "Epoch 79/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.9174 - dense_2_loss: 3.7161 - dense_2_1_loss: 4.9191 - dense_2_2_loss: 4.7370 - dense_2_3_loss: 2.7133 - dense_2_4_loss: 1.5094 - dense_2_5_loss: 0.7836 - dense_2_6_loss: 0.3777 - dense_2_7_loss: 0.1594 - dense_2_accuracy: 0.2474 - dense_2_1_accuracy: 0.1414 - dense_2_2_accuracy: 0.2748 - dense_2_3_accuracy: 0.5424 - dense_2_4_accuracy: 0.6872 - dense_2_5_accuracy: 0.8113 - dense_2_6_accuracy: 0.9074 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 80/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 18.9067 - dense_2_loss: 3.7130 - dense_2_1_loss: 4.9174 - dense_2_2_loss: 4.7387 - dense_2_3_loss: 2.7105 - dense_2_4_loss: 1.5090 - dense_2_5_loss: 0.7836 - dense_2_6_loss: 0.3781 - dense_2_7_loss: 0.1598 - dense_2_accuracy: 0.2475 - dense_2_1_accuracy: 0.1433 - dense_2_2_accuracy: 0.2755 - dense_2_3_accuracy: 0.5432 - dense_2_4_accuracy: 0.6888 - dense_2_5_accuracy: 0.8129 - dense_2_6_accuracy: 0.9068 - dense_2_7_accuracy: 0.9659\n",
            "Epoch 81/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.8984 - dense_2_loss: 3.7088 - dense_2_1_loss: 4.9140 - dense_2_2_loss: 4.7346 - dense_2_3_loss: 2.7099 - dense_2_4_loss: 1.5088 - dense_2_5_loss: 0.7843 - dense_2_6_loss: 0.3786 - dense_2_7_loss: 0.1604 - dense_2_accuracy: 0.2472 - dense_2_1_accuracy: 0.1430 - dense_2_2_accuracy: 0.2764 - dense_2_3_accuracy: 0.5419 - dense_2_4_accuracy: 0.6879 - dense_2_5_accuracy: 0.8126 - dense_2_6_accuracy: 0.9069 - dense_2_7_accuracy: 0.9661\n",
            "Epoch 82/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.8907 - dense_2_loss: 3.7077 - dense_2_1_loss: 4.9104 - dense_2_2_loss: 4.7324 - dense_2_3_loss: 2.7081 - dense_2_4_loss: 1.5070 - dense_2_5_loss: 0.7824 - dense_2_6_loss: 0.3772 - dense_2_7_loss: 0.1593 - dense_2_accuracy: 0.2477 - dense_2_1_accuracy: 0.1438 - dense_2_2_accuracy: 0.2762 - dense_2_3_accuracy: 0.5417 - dense_2_4_accuracy: 0.6882 - dense_2_5_accuracy: 0.8122 - dense_2_6_accuracy: 0.9064 - dense_2_7_accuracy: 0.9661\n",
            "Epoch 83/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.8808 - dense_2_loss: 3.7048 - dense_2_1_loss: 4.9114 - dense_2_2_loss: 4.7307 - dense_2_3_loss: 2.7099 - dense_2_4_loss: 1.5074 - dense_2_5_loss: 0.7821 - dense_2_6_loss: 0.3769 - dense_2_7_loss: 0.1593 - dense_2_accuracy: 0.2475 - dense_2_1_accuracy: 0.1442 - dense_2_2_accuracy: 0.2767 - dense_2_3_accuracy: 0.5432 - dense_2_4_accuracy: 0.6882 - dense_2_5_accuracy: 0.8118 - dense_2_6_accuracy: 0.9066 - dense_2_7_accuracy: 0.9661\n",
            "Epoch 84/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.8753 - dense_2_loss: 3.7012 - dense_2_1_loss: 4.9071 - dense_2_2_loss: 4.7313 - dense_2_3_loss: 2.7055 - dense_2_4_loss: 1.5060 - dense_2_5_loss: 0.7823 - dense_2_6_loss: 0.3769 - dense_2_7_loss: 0.1592 - dense_2_accuracy: 0.2480 - dense_2_1_accuracy: 0.1453 - dense_2_2_accuracy: 0.2770 - dense_2_3_accuracy: 0.5420 - dense_2_4_accuracy: 0.6891 - dense_2_5_accuracy: 0.8119 - dense_2_6_accuracy: 0.9074 - dense_2_7_accuracy: 0.9660\n",
            "Epoch 85/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.8655 - dense_2_loss: 3.6999 - dense_2_1_loss: 4.9043 - dense_2_2_loss: 4.7279 - dense_2_3_loss: 2.7041 - dense_2_4_loss: 1.5056 - dense_2_5_loss: 0.7821 - dense_2_6_loss: 0.3766 - dense_2_7_loss: 0.1593 - dense_2_accuracy: 0.2486 - dense_2_1_accuracy: 0.1449 - dense_2_2_accuracy: 0.2775 - dense_2_3_accuracy: 0.5413 - dense_2_4_accuracy: 0.6881 - dense_2_5_accuracy: 0.8124 - dense_2_6_accuracy: 0.9076 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 86/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.8552 - dense_2_loss: 3.6970 - dense_2_1_loss: 4.9038 - dense_2_2_loss: 4.7265 - dense_2_3_loss: 2.7038 - dense_2_4_loss: 1.5070 - dense_2_5_loss: 0.7819 - dense_2_6_loss: 0.3771 - dense_2_7_loss: 0.1592 - dense_2_accuracy: 0.2487 - dense_2_1_accuracy: 0.1466 - dense_2_2_accuracy: 0.2771 - dense_2_3_accuracy: 0.5433 - dense_2_4_accuracy: 0.6895 - dense_2_5_accuracy: 0.8124 - dense_2_6_accuracy: 0.9072 - dense_2_7_accuracy: 0.9661\n",
            "Epoch 87/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.8454 - dense_2_loss: 3.6937 - dense_2_1_loss: 4.9017 - dense_2_2_loss: 4.7264 - dense_2_3_loss: 2.7034 - dense_2_4_loss: 1.5072 - dense_2_5_loss: 0.7805 - dense_2_6_loss: 0.3766 - dense_2_7_loss: 0.1592 - dense_2_accuracy: 0.2480 - dense_2_1_accuracy: 0.1468 - dense_2_2_accuracy: 0.2784 - dense_2_3_accuracy: 0.5435 - dense_2_4_accuracy: 0.6888 - dense_2_5_accuracy: 0.8135 - dense_2_6_accuracy: 0.9072 - dense_2_7_accuracy: 0.9660\n",
            "Epoch 88/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.8399 - dense_2_loss: 3.6930 - dense_2_1_loss: 4.9005 - dense_2_2_loss: 4.7236 - dense_2_3_loss: 2.7021 - dense_2_4_loss: 1.5038 - dense_2_5_loss: 0.7807 - dense_2_6_loss: 0.3762 - dense_2_7_loss: 0.1591 - dense_2_accuracy: 0.2497 - dense_2_1_accuracy: 0.1489 - dense_2_2_accuracy: 0.2772 - dense_2_3_accuracy: 0.5443 - dense_2_4_accuracy: 0.6908 - dense_2_5_accuracy: 0.8136 - dense_2_6_accuracy: 0.9073 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 89/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.8301 - dense_2_loss: 3.6890 - dense_2_1_loss: 4.8984 - dense_2_2_loss: 4.7208 - dense_2_3_loss: 2.7004 - dense_2_4_loss: 1.5035 - dense_2_5_loss: 0.7804 - dense_2_6_loss: 0.3764 - dense_2_7_loss: 0.1590 - dense_2_accuracy: 0.2492 - dense_2_1_accuracy: 0.1473 - dense_2_2_accuracy: 0.2779 - dense_2_3_accuracy: 0.5441 - dense_2_4_accuracy: 0.6893 - dense_2_5_accuracy: 0.8122 - dense_2_6_accuracy: 0.9069 - dense_2_7_accuracy: 0.9662\n",
            "Epoch 90/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.8210 - dense_2_loss: 3.6878 - dense_2_1_loss: 4.8953 - dense_2_2_loss: 4.7215 - dense_2_3_loss: 2.7021 - dense_2_4_loss: 1.5014 - dense_2_5_loss: 0.7796 - dense_2_6_loss: 0.3754 - dense_2_7_loss: 0.1591 - dense_2_accuracy: 0.2498 - dense_2_1_accuracy: 0.1486 - dense_2_2_accuracy: 0.2780 - dense_2_3_accuracy: 0.5430 - dense_2_4_accuracy: 0.6893 - dense_2_5_accuracy: 0.8134 - dense_2_6_accuracy: 0.9074 - dense_2_7_accuracy: 0.9659\n",
            "Epoch 91/300\n",
            "10000/10000 [==============================] - 30s 3ms/sample - loss: 18.8148 - dense_2_loss: 3.6846 - dense_2_1_loss: 4.8927 - dense_2_2_loss: 4.7191 - dense_2_3_loss: 2.6986 - dense_2_4_loss: 1.5021 - dense_2_5_loss: 0.7798 - dense_2_6_loss: 0.3762 - dense_2_7_loss: 0.1589 - dense_2_accuracy: 0.2497 - dense_2_1_accuracy: 0.1488 - dense_2_2_accuracy: 0.2789 - dense_2_3_accuracy: 0.5442 - dense_2_4_accuracy: 0.6897 - dense_2_5_accuracy: 0.8134 - dense_2_6_accuracy: 0.9078 - dense_2_7_accuracy: 0.9660\n",
            "Epoch 92/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.8065 - dense_2_loss: 3.6819 - dense_2_1_loss: 4.8908 - dense_2_2_loss: 4.7195 - dense_2_3_loss: 2.6972 - dense_2_4_loss: 1.5017 - dense_2_5_loss: 0.7803 - dense_2_6_loss: 0.3754 - dense_2_7_loss: 0.1589 - dense_2_accuracy: 0.2506 - dense_2_1_accuracy: 0.1494 - dense_2_2_accuracy: 0.2791 - dense_2_3_accuracy: 0.5449 - dense_2_4_accuracy: 0.6895 - dense_2_5_accuracy: 0.8125 - dense_2_6_accuracy: 0.9073 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 93/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.7980 - dense_2_loss: 3.6797 - dense_2_1_loss: 4.8898 - dense_2_2_loss: 4.7162 - dense_2_3_loss: 2.6989 - dense_2_4_loss: 1.5000 - dense_2_5_loss: 0.7792 - dense_2_6_loss: 0.3754 - dense_2_7_loss: 0.1590 - dense_2_accuracy: 0.2525 - dense_2_1_accuracy: 0.1499 - dense_2_2_accuracy: 0.2792 - dense_2_3_accuracy: 0.5437 - dense_2_4_accuracy: 0.6900 - dense_2_5_accuracy: 0.8141 - dense_2_6_accuracy: 0.9075 - dense_2_7_accuracy: 0.9659\n",
            "Epoch 94/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.7902 - dense_2_loss: 3.6780 - dense_2_1_loss: 4.8887 - dense_2_2_loss: 4.7161 - dense_2_3_loss: 2.6968 - dense_2_4_loss: 1.5022 - dense_2_5_loss: 0.7795 - dense_2_6_loss: 0.3761 - dense_2_7_loss: 0.1588 - dense_2_accuracy: 0.2528 - dense_2_1_accuracy: 0.1513 - dense_2_2_accuracy: 0.2796 - dense_2_3_accuracy: 0.5459 - dense_2_4_accuracy: 0.6923 - dense_2_5_accuracy: 0.8136 - dense_2_6_accuracy: 0.9077 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 95/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.7844 - dense_2_loss: 3.6757 - dense_2_1_loss: 4.8865 - dense_2_2_loss: 4.7134 - dense_2_3_loss: 2.6959 - dense_2_4_loss: 1.5026 - dense_2_5_loss: 0.7814 - dense_2_6_loss: 0.3762 - dense_2_7_loss: 0.1593 - dense_2_accuracy: 0.2538 - dense_2_1_accuracy: 0.1514 - dense_2_2_accuracy: 0.2794 - dense_2_3_accuracy: 0.5447 - dense_2_4_accuracy: 0.6909 - dense_2_5_accuracy: 0.8135 - dense_2_6_accuracy: 0.9069 - dense_2_7_accuracy: 0.9660\n",
            "Epoch 96/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.7762 - dense_2_loss: 3.6730 - dense_2_1_loss: 4.8836 - dense_2_2_loss: 4.7125 - dense_2_3_loss: 2.6940 - dense_2_4_loss: 1.5004 - dense_2_5_loss: 0.7783 - dense_2_6_loss: 0.3751 - dense_2_7_loss: 0.1589 - dense_2_accuracy: 0.2541 - dense_2_1_accuracy: 0.1530 - dense_2_2_accuracy: 0.2803 - dense_2_3_accuracy: 0.5453 - dense_2_4_accuracy: 0.6905 - dense_2_5_accuracy: 0.8140 - dense_2_6_accuracy: 0.9076 - dense_2_7_accuracy: 0.9659\n",
            "Epoch 97/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.7676 - dense_2_loss: 3.6687 - dense_2_1_loss: 4.8812 - dense_2_2_loss: 4.7107 - dense_2_3_loss: 2.6942 - dense_2_4_loss: 1.5007 - dense_2_5_loss: 0.7799 - dense_2_6_loss: 0.3759 - dense_2_7_loss: 0.1590 - dense_2_accuracy: 0.2548 - dense_2_1_accuracy: 0.1525 - dense_2_2_accuracy: 0.2799 - dense_2_3_accuracy: 0.5454 - dense_2_4_accuracy: 0.6908 - dense_2_5_accuracy: 0.8151 - dense_2_6_accuracy: 0.9081 - dense_2_7_accuracy: 0.9661\n",
            "Epoch 98/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.7600 - dense_2_loss: 3.6657 - dense_2_1_loss: 4.8791 - dense_2_2_loss: 4.7086 - dense_2_3_loss: 2.6929 - dense_2_4_loss: 1.4973 - dense_2_5_loss: 0.7774 - dense_2_6_loss: 0.3744 - dense_2_7_loss: 0.1586 - dense_2_accuracy: 0.2557 - dense_2_1_accuracy: 0.1539 - dense_2_2_accuracy: 0.2800 - dense_2_3_accuracy: 0.5451 - dense_2_4_accuracy: 0.6907 - dense_2_5_accuracy: 0.8145 - dense_2_6_accuracy: 0.9070 - dense_2_7_accuracy: 0.9660\n",
            "Epoch 99/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.7528 - dense_2_loss: 3.6653 - dense_2_1_loss: 4.8777 - dense_2_2_loss: 4.7080 - dense_2_3_loss: 2.6908 - dense_2_4_loss: 1.4977 - dense_2_5_loss: 0.7778 - dense_2_6_loss: 0.3751 - dense_2_7_loss: 0.1591 - dense_2_accuracy: 0.2565 - dense_2_1_accuracy: 0.1535 - dense_2_2_accuracy: 0.2799 - dense_2_3_accuracy: 0.5460 - dense_2_4_accuracy: 0.6899 - dense_2_5_accuracy: 0.8143 - dense_2_6_accuracy: 0.9077 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 100/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.7478 - dense_2_loss: 3.6625 - dense_2_1_loss: 4.8759 - dense_2_2_loss: 4.7079 - dense_2_3_loss: 2.6915 - dense_2_4_loss: 1.4983 - dense_2_5_loss: 0.7780 - dense_2_6_loss: 0.3749 - dense_2_7_loss: 0.1586 - dense_2_accuracy: 0.2566 - dense_2_1_accuracy: 0.1540 - dense_2_2_accuracy: 0.2804 - dense_2_3_accuracy: 0.5465 - dense_2_4_accuracy: 0.6909 - dense_2_5_accuracy: 0.8159 - dense_2_6_accuracy: 0.9079 - dense_2_7_accuracy: 0.9660\n",
            "Epoch 101/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.7392 - dense_2_loss: 3.6606 - dense_2_1_loss: 4.8739 - dense_2_2_loss: 4.7040 - dense_2_3_loss: 2.6883 - dense_2_4_loss: 1.4971 - dense_2_5_loss: 0.7775 - dense_2_6_loss: 0.3750 - dense_2_7_loss: 0.1587 - dense_2_accuracy: 0.2570 - dense_2_1_accuracy: 0.1553 - dense_2_2_accuracy: 0.2806 - dense_2_3_accuracy: 0.5466 - dense_2_4_accuracy: 0.6914 - dense_2_5_accuracy: 0.8131 - dense_2_6_accuracy: 0.9072 - dense_2_7_accuracy: 0.9657\n",
            "Epoch 102/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.7316 - dense_2_loss: 3.6588 - dense_2_1_loss: 4.8722 - dense_2_2_loss: 4.7035 - dense_2_3_loss: 2.6875 - dense_2_4_loss: 1.4977 - dense_2_5_loss: 0.7783 - dense_2_6_loss: 0.3755 - dense_2_7_loss: 0.1593 - dense_2_accuracy: 0.2571 - dense_2_1_accuracy: 0.1557 - dense_2_2_accuracy: 0.2808 - dense_2_3_accuracy: 0.5470 - dense_2_4_accuracy: 0.6916 - dense_2_5_accuracy: 0.8143 - dense_2_6_accuracy: 0.9084 - dense_2_7_accuracy: 0.9660\n",
            "Epoch 103/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.7243 - dense_2_loss: 3.6547 - dense_2_1_loss: 4.8700 - dense_2_2_loss: 4.7046 - dense_2_3_loss: 2.6891 - dense_2_4_loss: 1.4971 - dense_2_5_loss: 0.7773 - dense_2_6_loss: 0.3753 - dense_2_7_loss: 0.1590 - dense_2_accuracy: 0.2579 - dense_2_1_accuracy: 0.1555 - dense_2_2_accuracy: 0.2809 - dense_2_3_accuracy: 0.5474 - dense_2_4_accuracy: 0.6919 - dense_2_5_accuracy: 0.8142 - dense_2_6_accuracy: 0.9078 - dense_2_7_accuracy: 0.9661\n",
            "Epoch 104/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.7162 - dense_2_loss: 3.6549 - dense_2_1_loss: 4.8676 - dense_2_2_loss: 4.7022 - dense_2_3_loss: 2.6841 - dense_2_4_loss: 1.4947 - dense_2_5_loss: 0.7762 - dense_2_6_loss: 0.3741 - dense_2_7_loss: 0.1584 - dense_2_accuracy: 0.2584 - dense_2_1_accuracy: 0.1561 - dense_2_2_accuracy: 0.2811 - dense_2_3_accuracy: 0.5487 - dense_2_4_accuracy: 0.6923 - dense_2_5_accuracy: 0.8153 - dense_2_6_accuracy: 0.9083 - dense_2_7_accuracy: 0.9660\n",
            "Epoch 105/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.7095 - dense_2_loss: 3.6511 - dense_2_1_loss: 4.8655 - dense_2_2_loss: 4.7000 - dense_2_3_loss: 2.6864 - dense_2_4_loss: 1.4946 - dense_2_5_loss: 0.7764 - dense_2_6_loss: 0.3736 - dense_2_7_loss: 0.1584 - dense_2_accuracy: 0.2576 - dense_2_1_accuracy: 0.1563 - dense_2_2_accuracy: 0.2807 - dense_2_3_accuracy: 0.5478 - dense_2_4_accuracy: 0.6911 - dense_2_5_accuracy: 0.8148 - dense_2_6_accuracy: 0.9081 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 106/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.7037 - dense_2_loss: 3.6499 - dense_2_1_loss: 4.8660 - dense_2_2_loss: 4.6985 - dense_2_3_loss: 2.6842 - dense_2_4_loss: 1.4936 - dense_2_5_loss: 0.7758 - dense_2_6_loss: 0.3738 - dense_2_7_loss: 0.1585 - dense_2_accuracy: 0.2587 - dense_2_1_accuracy: 0.1570 - dense_2_2_accuracy: 0.2815 - dense_2_3_accuracy: 0.5476 - dense_2_4_accuracy: 0.6921 - dense_2_5_accuracy: 0.8143 - dense_2_6_accuracy: 0.9078 - dense_2_7_accuracy: 0.9660\n",
            "Epoch 107/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.6963 - dense_2_loss: 3.6479 - dense_2_1_loss: 4.8623 - dense_2_2_loss: 4.6962 - dense_2_3_loss: 2.6819 - dense_2_4_loss: 1.4936 - dense_2_5_loss: 0.7759 - dense_2_6_loss: 0.3741 - dense_2_7_loss: 0.1584 - dense_2_accuracy: 0.2583 - dense_2_1_accuracy: 0.1566 - dense_2_2_accuracy: 0.2814 - dense_2_3_accuracy: 0.5495 - dense_2_4_accuracy: 0.6926 - dense_2_5_accuracy: 0.8151 - dense_2_6_accuracy: 0.9077 - dense_2_7_accuracy: 0.9659\n",
            "Epoch 108/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.6897 - dense_2_loss: 3.6455 - dense_2_1_loss: 4.8614 - dense_2_2_loss: 4.6971 - dense_2_3_loss: 2.6841 - dense_2_4_loss: 1.4945 - dense_2_5_loss: 0.7768 - dense_2_6_loss: 0.3738 - dense_2_7_loss: 0.1585 - dense_2_accuracy: 0.2589 - dense_2_1_accuracy: 0.1573 - dense_2_2_accuracy: 0.2817 - dense_2_3_accuracy: 0.5484 - dense_2_4_accuracy: 0.6922 - dense_2_5_accuracy: 0.8145 - dense_2_6_accuracy: 0.9083 - dense_2_7_accuracy: 0.9657\n",
            "Epoch 109/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.6815 - dense_2_loss: 3.6443 - dense_2_1_loss: 4.8607 - dense_2_2_loss: 4.6932 - dense_2_3_loss: 2.6822 - dense_2_4_loss: 1.4941 - dense_2_5_loss: 0.7767 - dense_2_6_loss: 0.3744 - dense_2_7_loss: 0.1586 - dense_2_accuracy: 0.2597 - dense_2_1_accuracy: 0.1579 - dense_2_2_accuracy: 0.2820 - dense_2_3_accuracy: 0.5491 - dense_2_4_accuracy: 0.6940 - dense_2_5_accuracy: 0.8153 - dense_2_6_accuracy: 0.9082 - dense_2_7_accuracy: 0.9661\n",
            "Epoch 110/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.6754 - dense_2_loss: 3.6412 - dense_2_1_loss: 4.8585 - dense_2_2_loss: 4.6931 - dense_2_3_loss: 2.6812 - dense_2_4_loss: 1.4948 - dense_2_5_loss: 0.7785 - dense_2_6_loss: 0.3747 - dense_2_7_loss: 0.1592 - dense_2_accuracy: 0.2590 - dense_2_1_accuracy: 0.1578 - dense_2_2_accuracy: 0.2820 - dense_2_3_accuracy: 0.5488 - dense_2_4_accuracy: 0.6916 - dense_2_5_accuracy: 0.8141 - dense_2_6_accuracy: 0.9077 - dense_2_7_accuracy: 0.9658\n",
            "Epoch 111/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.6684 - dense_2_loss: 3.6375 - dense_2_1_loss: 4.8557 - dense_2_2_loss: 4.6910 - dense_2_3_loss: 2.6792 - dense_2_4_loss: 1.4935 - dense_2_5_loss: 0.7750 - dense_2_6_loss: 0.3734 - dense_2_7_loss: 0.1583 - dense_2_accuracy: 0.2604 - dense_2_1_accuracy: 0.1580 - dense_2_2_accuracy: 0.2825 - dense_2_3_accuracy: 0.5490 - dense_2_4_accuracy: 0.6934 - dense_2_5_accuracy: 0.8143 - dense_2_6_accuracy: 0.9079 - dense_2_7_accuracy: 0.9658\n",
            "Epoch 112/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.6622 - dense_2_loss: 3.6367 - dense_2_1_loss: 4.8538 - dense_2_2_loss: 4.6919 - dense_2_3_loss: 2.6813 - dense_2_4_loss: 1.4932 - dense_2_5_loss: 0.7749 - dense_2_6_loss: 0.3733 - dense_2_7_loss: 0.1582 - dense_2_accuracy: 0.2605 - dense_2_1_accuracy: 0.1590 - dense_2_2_accuracy: 0.2814 - dense_2_3_accuracy: 0.5489 - dense_2_4_accuracy: 0.6929 - dense_2_5_accuracy: 0.8143 - dense_2_6_accuracy: 0.9076 - dense_2_7_accuracy: 0.9661\n",
            "Epoch 113/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.6563 - dense_2_loss: 3.6340 - dense_2_1_loss: 4.8522 - dense_2_2_loss: 4.6893 - dense_2_3_loss: 2.6783 - dense_2_4_loss: 1.4923 - dense_2_5_loss: 0.7757 - dense_2_6_loss: 0.3734 - dense_2_7_loss: 0.1584 - dense_2_accuracy: 0.2618 - dense_2_1_accuracy: 0.1590 - dense_2_2_accuracy: 0.2823 - dense_2_3_accuracy: 0.5494 - dense_2_4_accuracy: 0.6940 - dense_2_5_accuracy: 0.8151 - dense_2_6_accuracy: 0.9083 - dense_2_7_accuracy: 0.9659\n",
            "Epoch 114/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.6495 - dense_2_loss: 3.6316 - dense_2_1_loss: 4.8499 - dense_2_2_loss: 4.6903 - dense_2_3_loss: 2.6792 - dense_2_4_loss: 1.4913 - dense_2_5_loss: 0.7747 - dense_2_6_loss: 0.3729 - dense_2_7_loss: 0.1581 - dense_2_accuracy: 0.2625 - dense_2_1_accuracy: 0.1591 - dense_2_2_accuracy: 0.2823 - dense_2_3_accuracy: 0.5505 - dense_2_4_accuracy: 0.6929 - dense_2_5_accuracy: 0.8146 - dense_2_6_accuracy: 0.9080 - dense_2_7_accuracy: 0.9662\n",
            "Epoch 115/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.6421 - dense_2_loss: 3.6307 - dense_2_1_loss: 4.8494 - dense_2_2_loss: 4.6851 - dense_2_3_loss: 2.6762 - dense_2_4_loss: 1.4905 - dense_2_5_loss: 0.7737 - dense_2_6_loss: 0.3726 - dense_2_7_loss: 0.1581 - dense_2_accuracy: 0.2632 - dense_2_1_accuracy: 0.1591 - dense_2_2_accuracy: 0.2816 - dense_2_3_accuracy: 0.5489 - dense_2_4_accuracy: 0.6950 - dense_2_5_accuracy: 0.8157 - dense_2_6_accuracy: 0.9077 - dense_2_7_accuracy: 0.9659\n",
            "Epoch 116/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.6359 - dense_2_loss: 3.6272 - dense_2_1_loss: 4.8478 - dense_2_2_loss: 4.6876 - dense_2_3_loss: 2.6758 - dense_2_4_loss: 1.4903 - dense_2_5_loss: 0.7741 - dense_2_6_loss: 0.3723 - dense_2_7_loss: 0.1580 - dense_2_accuracy: 0.2625 - dense_2_1_accuracy: 0.1592 - dense_2_2_accuracy: 0.2830 - dense_2_3_accuracy: 0.5499 - dense_2_4_accuracy: 0.6938 - dense_2_5_accuracy: 0.8157 - dense_2_6_accuracy: 0.9078 - dense_2_7_accuracy: 0.9659\n",
            "Epoch 117/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.6304 - dense_2_loss: 3.6262 - dense_2_1_loss: 4.8467 - dense_2_2_loss: 4.6860 - dense_2_3_loss: 2.6767 - dense_2_4_loss: 1.4901 - dense_2_5_loss: 0.7745 - dense_2_6_loss: 0.3729 - dense_2_7_loss: 0.1579 - dense_2_accuracy: 0.2641 - dense_2_1_accuracy: 0.1596 - dense_2_2_accuracy: 0.2822 - dense_2_3_accuracy: 0.5503 - dense_2_4_accuracy: 0.6945 - dense_2_5_accuracy: 0.8157 - dense_2_6_accuracy: 0.9084 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 118/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.6223 - dense_2_loss: 3.6239 - dense_2_1_loss: 4.8444 - dense_2_2_loss: 4.6819 - dense_2_3_loss: 2.6761 - dense_2_4_loss: 1.4912 - dense_2_5_loss: 0.7743 - dense_2_6_loss: 0.3733 - dense_2_7_loss: 0.1581 - dense_2_accuracy: 0.2643 - dense_2_1_accuracy: 0.1601 - dense_2_2_accuracy: 0.2821 - dense_2_3_accuracy: 0.5492 - dense_2_4_accuracy: 0.6933 - dense_2_5_accuracy: 0.8153 - dense_2_6_accuracy: 0.9083 - dense_2_7_accuracy: 0.9659\n",
            "Epoch 119/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.6166 - dense_2_loss: 3.6208 - dense_2_1_loss: 4.8421 - dense_2_2_loss: 4.6841 - dense_2_3_loss: 2.6756 - dense_2_4_loss: 1.4903 - dense_2_5_loss: 0.7741 - dense_2_6_loss: 0.3734 - dense_2_7_loss: 0.1584 - dense_2_accuracy: 0.2650 - dense_2_1_accuracy: 0.1598 - dense_2_2_accuracy: 0.2833 - dense_2_3_accuracy: 0.5498 - dense_2_4_accuracy: 0.6929 - dense_2_5_accuracy: 0.8140 - dense_2_6_accuracy: 0.9084 - dense_2_7_accuracy: 0.9660\n",
            "Epoch 120/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.6103 - dense_2_loss: 3.6200 - dense_2_1_loss: 4.8407 - dense_2_2_loss: 4.6816 - dense_2_3_loss: 2.6720 - dense_2_4_loss: 1.4888 - dense_2_5_loss: 0.7739 - dense_2_6_loss: 0.3734 - dense_2_7_loss: 0.1593 - dense_2_accuracy: 0.2650 - dense_2_1_accuracy: 0.1601 - dense_2_2_accuracy: 0.2836 - dense_2_3_accuracy: 0.5509 - dense_2_4_accuracy: 0.6944 - dense_2_5_accuracy: 0.8158 - dense_2_6_accuracy: 0.9089 - dense_2_7_accuracy: 0.9660\n",
            "Epoch 121/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.6049 - dense_2_loss: 3.6176 - dense_2_1_loss: 4.8384 - dense_2_2_loss: 4.6822 - dense_2_3_loss: 2.6737 - dense_2_4_loss: 1.4900 - dense_2_5_loss: 0.7738 - dense_2_6_loss: 0.3725 - dense_2_7_loss: 0.1579 - dense_2_accuracy: 0.2654 - dense_2_1_accuracy: 0.1605 - dense_2_2_accuracy: 0.2838 - dense_2_3_accuracy: 0.5496 - dense_2_4_accuracy: 0.6937 - dense_2_5_accuracy: 0.8146 - dense_2_6_accuracy: 0.9082 - dense_2_7_accuracy: 0.9661\n",
            "Epoch 122/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.5997 - dense_2_loss: 3.6142 - dense_2_1_loss: 4.8364 - dense_2_2_loss: 4.6797 - dense_2_3_loss: 2.6746 - dense_2_4_loss: 1.4895 - dense_2_5_loss: 0.7742 - dense_2_6_loss: 0.3731 - dense_2_7_loss: 0.1584 - dense_2_accuracy: 0.2655 - dense_2_1_accuracy: 0.1603 - dense_2_2_accuracy: 0.2841 - dense_2_3_accuracy: 0.5496 - dense_2_4_accuracy: 0.6937 - dense_2_5_accuracy: 0.8140 - dense_2_6_accuracy: 0.9086 - dense_2_7_accuracy: 0.9662\n",
            "Epoch 123/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.5922 - dense_2_loss: 3.6135 - dense_2_1_loss: 4.8365 - dense_2_2_loss: 4.6798 - dense_2_3_loss: 2.6726 - dense_2_4_loss: 1.4908 - dense_2_5_loss: 0.7730 - dense_2_6_loss: 0.3724 - dense_2_7_loss: 0.1579 - dense_2_accuracy: 0.2656 - dense_2_1_accuracy: 0.1609 - dense_2_2_accuracy: 0.2839 - dense_2_3_accuracy: 0.5500 - dense_2_4_accuracy: 0.6925 - dense_2_5_accuracy: 0.8148 - dense_2_6_accuracy: 0.9088 - dense_2_7_accuracy: 0.9660\n",
            "Epoch 124/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.5859 - dense_2_loss: 3.6103 - dense_2_1_loss: 4.8352 - dense_2_2_loss: 4.6771 - dense_2_3_loss: 2.6705 - dense_2_4_loss: 1.4867 - dense_2_5_loss: 0.7724 - dense_2_6_loss: 0.3720 - dense_2_7_loss: 0.1578 - dense_2_accuracy: 0.2659 - dense_2_1_accuracy: 0.1605 - dense_2_2_accuracy: 0.2832 - dense_2_3_accuracy: 0.5508 - dense_2_4_accuracy: 0.6945 - dense_2_5_accuracy: 0.8157 - dense_2_6_accuracy: 0.9082 - dense_2_7_accuracy: 0.9658\n",
            "Epoch 125/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.5792 - dense_2_loss: 3.6109 - dense_2_1_loss: 4.8324 - dense_2_2_loss: 4.6753 - dense_2_3_loss: 2.6700 - dense_2_4_loss: 1.4873 - dense_2_5_loss: 0.7728 - dense_2_6_loss: 0.3726 - dense_2_7_loss: 0.1582 - dense_2_accuracy: 0.2659 - dense_2_1_accuracy: 0.1614 - dense_2_2_accuracy: 0.2844 - dense_2_3_accuracy: 0.5500 - dense_2_4_accuracy: 0.6949 - dense_2_5_accuracy: 0.8150 - dense_2_6_accuracy: 0.9083 - dense_2_7_accuracy: 0.9660\n",
            "Epoch 126/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.5741 - dense_2_loss: 3.6085 - dense_2_1_loss: 4.8327 - dense_2_2_loss: 4.6751 - dense_2_3_loss: 2.6695 - dense_2_4_loss: 1.4883 - dense_2_5_loss: 0.7726 - dense_2_6_loss: 0.3723 - dense_2_7_loss: 0.1578 - dense_2_accuracy: 0.2662 - dense_2_1_accuracy: 0.1616 - dense_2_2_accuracy: 0.2838 - dense_2_3_accuracy: 0.5513 - dense_2_4_accuracy: 0.6944 - dense_2_5_accuracy: 0.8163 - dense_2_6_accuracy: 0.9088 - dense_2_7_accuracy: 0.9658\n",
            "Epoch 127/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.5684 - dense_2_loss: 3.6050 - dense_2_1_loss: 4.8283 - dense_2_2_loss: 4.6743 - dense_2_3_loss: 2.6686 - dense_2_4_loss: 1.4854 - dense_2_5_loss: 0.7721 - dense_2_6_loss: 0.3720 - dense_2_7_loss: 0.1579 - dense_2_accuracy: 0.2670 - dense_2_1_accuracy: 0.1615 - dense_2_2_accuracy: 0.2844 - dense_2_3_accuracy: 0.5510 - dense_2_4_accuracy: 0.6954 - dense_2_5_accuracy: 0.8163 - dense_2_6_accuracy: 0.9090 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 128/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.5632 - dense_2_loss: 3.6039 - dense_2_1_loss: 4.8292 - dense_2_2_loss: 4.6742 - dense_2_3_loss: 2.6701 - dense_2_4_loss: 1.4873 - dense_2_5_loss: 0.7723 - dense_2_6_loss: 0.3721 - dense_2_7_loss: 0.1576 - dense_2_accuracy: 0.2669 - dense_2_1_accuracy: 0.1621 - dense_2_2_accuracy: 0.2845 - dense_2_3_accuracy: 0.5499 - dense_2_4_accuracy: 0.6944 - dense_2_5_accuracy: 0.8158 - dense_2_6_accuracy: 0.9084 - dense_2_7_accuracy: 0.9661\n",
            "Epoch 129/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.5574 - dense_2_loss: 3.6010 - dense_2_1_loss: 4.8262 - dense_2_2_loss: 4.6723 - dense_2_3_loss: 2.6658 - dense_2_4_loss: 1.4870 - dense_2_5_loss: 0.7720 - dense_2_6_loss: 0.3716 - dense_2_7_loss: 0.1577 - dense_2_accuracy: 0.2677 - dense_2_1_accuracy: 0.1619 - dense_2_2_accuracy: 0.2844 - dense_2_3_accuracy: 0.5508 - dense_2_4_accuracy: 0.6941 - dense_2_5_accuracy: 0.8154 - dense_2_6_accuracy: 0.9090 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 130/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.5532 - dense_2_loss: 3.5994 - dense_2_1_loss: 4.8244 - dense_2_2_loss: 4.6720 - dense_2_3_loss: 2.6701 - dense_2_4_loss: 1.4867 - dense_2_5_loss: 0.7725 - dense_2_6_loss: 0.3728 - dense_2_7_loss: 0.1582 - dense_2_accuracy: 0.2681 - dense_2_1_accuracy: 0.1616 - dense_2_2_accuracy: 0.2840 - dense_2_3_accuracy: 0.5511 - dense_2_4_accuracy: 0.6951 - dense_2_5_accuracy: 0.8156 - dense_2_6_accuracy: 0.9092 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 131/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.5449 - dense_2_loss: 3.5988 - dense_2_1_loss: 4.8225 - dense_2_2_loss: 4.6703 - dense_2_3_loss: 2.6665 - dense_2_4_loss: 1.4844 - dense_2_5_loss: 0.7713 - dense_2_6_loss: 0.3712 - dense_2_7_loss: 0.1578 - dense_2_accuracy: 0.2683 - dense_2_1_accuracy: 0.1621 - dense_2_2_accuracy: 0.2853 - dense_2_3_accuracy: 0.5506 - dense_2_4_accuracy: 0.6951 - dense_2_5_accuracy: 0.8158 - dense_2_6_accuracy: 0.9088 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 132/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.5405 - dense_2_loss: 3.5988 - dense_2_1_loss: 4.8217 - dense_2_2_loss: 4.6695 - dense_2_3_loss: 2.6664 - dense_2_4_loss: 1.4848 - dense_2_5_loss: 0.7710 - dense_2_6_loss: 0.3717 - dense_2_7_loss: 0.1574 - dense_2_accuracy: 0.2682 - dense_2_1_accuracy: 0.1617 - dense_2_2_accuracy: 0.2853 - dense_2_3_accuracy: 0.5517 - dense_2_4_accuracy: 0.6947 - dense_2_5_accuracy: 0.8158 - dense_2_6_accuracy: 0.9088 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 133/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.5348 - dense_2_loss: 3.5950 - dense_2_1_loss: 4.8201 - dense_2_2_loss: 4.6718 - dense_2_3_loss: 2.6659 - dense_2_4_loss: 1.4844 - dense_2_5_loss: 0.7712 - dense_2_6_loss: 0.3713 - dense_2_7_loss: 0.1576 - dense_2_accuracy: 0.2685 - dense_2_1_accuracy: 0.1625 - dense_2_2_accuracy: 0.2848 - dense_2_3_accuracy: 0.5510 - dense_2_4_accuracy: 0.6945 - dense_2_5_accuracy: 0.8161 - dense_2_6_accuracy: 0.9089 - dense_2_7_accuracy: 0.9660\n",
            "Epoch 134/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.5291 - dense_2_loss: 3.5940 - dense_2_1_loss: 4.8199 - dense_2_2_loss: 4.6663 - dense_2_3_loss: 2.6637 - dense_2_4_loss: 1.4839 - dense_2_5_loss: 0.7712 - dense_2_6_loss: 0.3718 - dense_2_7_loss: 0.1577 - dense_2_accuracy: 0.2687 - dense_2_1_accuracy: 0.1629 - dense_2_2_accuracy: 0.2851 - dense_2_3_accuracy: 0.5515 - dense_2_4_accuracy: 0.6942 - dense_2_5_accuracy: 0.8161 - dense_2_6_accuracy: 0.9097 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 135/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.5248 - dense_2_loss: 3.5901 - dense_2_1_loss: 4.8196 - dense_2_2_loss: 4.6662 - dense_2_3_loss: 2.6630 - dense_2_4_loss: 1.4839 - dense_2_5_loss: 0.7709 - dense_2_6_loss: 0.3716 - dense_2_7_loss: 0.1575 - dense_2_accuracy: 0.2692 - dense_2_1_accuracy: 0.1618 - dense_2_2_accuracy: 0.2854 - dense_2_3_accuracy: 0.5518 - dense_2_4_accuracy: 0.6947 - dense_2_5_accuracy: 0.8164 - dense_2_6_accuracy: 0.9089 - dense_2_7_accuracy: 0.9662\n",
            "Epoch 136/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.5185 - dense_2_loss: 3.5902 - dense_2_1_loss: 4.8183 - dense_2_2_loss: 4.6662 - dense_2_3_loss: 2.6617 - dense_2_4_loss: 1.4833 - dense_2_5_loss: 0.7708 - dense_2_6_loss: 0.3720 - dense_2_7_loss: 0.1579 - dense_2_accuracy: 0.2689 - dense_2_1_accuracy: 0.1628 - dense_2_2_accuracy: 0.2858 - dense_2_3_accuracy: 0.5522 - dense_2_4_accuracy: 0.6957 - dense_2_5_accuracy: 0.8163 - dense_2_6_accuracy: 0.9092 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 137/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.5132 - dense_2_loss: 3.5876 - dense_2_1_loss: 4.8167 - dense_2_2_loss: 4.6634 - dense_2_3_loss: 2.6633 - dense_2_4_loss: 1.4836 - dense_2_5_loss: 0.7700 - dense_2_6_loss: 0.3710 - dense_2_7_loss: 0.1574 - dense_2_accuracy: 0.2687 - dense_2_1_accuracy: 0.1631 - dense_2_2_accuracy: 0.2854 - dense_2_3_accuracy: 0.5525 - dense_2_4_accuracy: 0.6947 - dense_2_5_accuracy: 0.8159 - dense_2_6_accuracy: 0.9090 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 138/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.5077 - dense_2_loss: 3.5853 - dense_2_1_loss: 4.8154 - dense_2_2_loss: 4.6644 - dense_2_3_loss: 2.6629 - dense_2_4_loss: 1.4831 - dense_2_5_loss: 0.7704 - dense_2_6_loss: 0.3713 - dense_2_7_loss: 0.1577 - dense_2_accuracy: 0.2698 - dense_2_1_accuracy: 0.1639 - dense_2_2_accuracy: 0.2851 - dense_2_3_accuracy: 0.5521 - dense_2_4_accuracy: 0.6962 - dense_2_5_accuracy: 0.8161 - dense_2_6_accuracy: 0.9095 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 139/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.5027 - dense_2_loss: 3.5838 - dense_2_1_loss: 4.8141 - dense_2_2_loss: 4.6612 - dense_2_3_loss: 2.6622 - dense_2_4_loss: 1.4814 - dense_2_5_loss: 0.7694 - dense_2_6_loss: 0.3707 - dense_2_7_loss: 0.1573 - dense_2_accuracy: 0.2695 - dense_2_1_accuracy: 0.1632 - dense_2_2_accuracy: 0.2857 - dense_2_3_accuracy: 0.5531 - dense_2_4_accuracy: 0.6952 - dense_2_5_accuracy: 0.8163 - dense_2_6_accuracy: 0.9092 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 140/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.4981 - dense_2_loss: 3.5830 - dense_2_1_loss: 4.8111 - dense_2_2_loss: 4.6634 - dense_2_3_loss: 2.6613 - dense_2_4_loss: 1.4836 - dense_2_5_loss: 0.7704 - dense_2_6_loss: 0.3713 - dense_2_7_loss: 0.1572 - dense_2_accuracy: 0.2699 - dense_2_1_accuracy: 0.1631 - dense_2_2_accuracy: 0.2857 - dense_2_3_accuracy: 0.5520 - dense_2_4_accuracy: 0.6952 - dense_2_5_accuracy: 0.8164 - dense_2_6_accuracy: 0.9095 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 141/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.4936 - dense_2_loss: 3.5818 - dense_2_1_loss: 4.8101 - dense_2_2_loss: 4.6618 - dense_2_3_loss: 2.6623 - dense_2_4_loss: 1.4836 - dense_2_5_loss: 0.7708 - dense_2_6_loss: 0.3710 - dense_2_7_loss: 0.1576 - dense_2_accuracy: 0.2703 - dense_2_1_accuracy: 0.1636 - dense_2_2_accuracy: 0.2859 - dense_2_3_accuracy: 0.5530 - dense_2_4_accuracy: 0.6960 - dense_2_5_accuracy: 0.8166 - dense_2_6_accuracy: 0.9089 - dense_2_7_accuracy: 0.9660\n",
            "Epoch 142/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.4873 - dense_2_loss: 3.5795 - dense_2_1_loss: 4.8093 - dense_2_2_loss: 4.6602 - dense_2_3_loss: 2.6579 - dense_2_4_loss: 1.4806 - dense_2_5_loss: 0.7693 - dense_2_6_loss: 0.3713 - dense_2_7_loss: 0.1577 - dense_2_accuracy: 0.2700 - dense_2_1_accuracy: 0.1642 - dense_2_2_accuracy: 0.2866 - dense_2_3_accuracy: 0.5530 - dense_2_4_accuracy: 0.6973 - dense_2_5_accuracy: 0.8164 - dense_2_6_accuracy: 0.9088 - dense_2_7_accuracy: 0.9662\n",
            "Epoch 143/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.4832 - dense_2_loss: 3.5786 - dense_2_1_loss: 4.8095 - dense_2_2_loss: 4.6602 - dense_2_3_loss: 2.6570 - dense_2_4_loss: 1.4813 - dense_2_5_loss: 0.7692 - dense_2_6_loss: 0.3705 - dense_2_7_loss: 0.1571 - dense_2_accuracy: 0.2701 - dense_2_1_accuracy: 0.1638 - dense_2_2_accuracy: 0.2862 - dense_2_3_accuracy: 0.5531 - dense_2_4_accuracy: 0.6962 - dense_2_5_accuracy: 0.8168 - dense_2_6_accuracy: 0.9094 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 144/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.4770 - dense_2_loss: 3.5762 - dense_2_1_loss: 4.8084 - dense_2_2_loss: 4.6581 - dense_2_3_loss: 2.6596 - dense_2_4_loss: 1.4822 - dense_2_5_loss: 0.7694 - dense_2_6_loss: 0.3706 - dense_2_7_loss: 0.1572 - dense_2_accuracy: 0.2705 - dense_2_1_accuracy: 0.1641 - dense_2_2_accuracy: 0.2864 - dense_2_3_accuracy: 0.5526 - dense_2_4_accuracy: 0.6959 - dense_2_5_accuracy: 0.8169 - dense_2_6_accuracy: 0.9099 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 145/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.4736 - dense_2_loss: 3.5748 - dense_2_1_loss: 4.8029 - dense_2_2_loss: 4.6568 - dense_2_3_loss: 2.6572 - dense_2_4_loss: 1.4822 - dense_2_5_loss: 0.7691 - dense_2_6_loss: 0.3711 - dense_2_7_loss: 0.1572 - dense_2_accuracy: 0.2707 - dense_2_1_accuracy: 0.1647 - dense_2_2_accuracy: 0.2859 - dense_2_3_accuracy: 0.5515 - dense_2_4_accuracy: 0.6951 - dense_2_5_accuracy: 0.8172 - dense_2_6_accuracy: 0.9084 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 146/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.4673 - dense_2_loss: 3.5752 - dense_2_1_loss: 4.8037 - dense_2_2_loss: 4.6549 - dense_2_3_loss: 2.6557 - dense_2_4_loss: 1.4808 - dense_2_5_loss: 0.7689 - dense_2_6_loss: 0.3702 - dense_2_7_loss: 0.1575 - dense_2_accuracy: 0.2710 - dense_2_1_accuracy: 0.1653 - dense_2_2_accuracy: 0.2866 - dense_2_3_accuracy: 0.5535 - dense_2_4_accuracy: 0.6951 - dense_2_5_accuracy: 0.8169 - dense_2_6_accuracy: 0.9094 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 147/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.4630 - dense_2_loss: 3.5735 - dense_2_1_loss: 4.8029 - dense_2_2_loss: 4.6561 - dense_2_3_loss: 2.6560 - dense_2_4_loss: 1.4804 - dense_2_5_loss: 0.7689 - dense_2_6_loss: 0.3704 - dense_2_7_loss: 0.1573 - dense_2_accuracy: 0.2715 - dense_2_1_accuracy: 0.1639 - dense_2_2_accuracy: 0.2868 - dense_2_3_accuracy: 0.5538 - dense_2_4_accuracy: 0.6968 - dense_2_5_accuracy: 0.8170 - dense_2_6_accuracy: 0.9101 - dense_2_7_accuracy: 0.9662\n",
            "Epoch 148/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.4574 - dense_2_loss: 3.5701 - dense_2_1_loss: 4.8010 - dense_2_2_loss: 4.6540 - dense_2_3_loss: 2.6528 - dense_2_4_loss: 1.4788 - dense_2_5_loss: 0.7678 - dense_2_6_loss: 0.3701 - dense_2_7_loss: 0.1571 - dense_2_accuracy: 0.2712 - dense_2_1_accuracy: 0.1648 - dense_2_2_accuracy: 0.2859 - dense_2_3_accuracy: 0.5532 - dense_2_4_accuracy: 0.6961 - dense_2_5_accuracy: 0.8176 - dense_2_6_accuracy: 0.9096 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 149/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.4534 - dense_2_loss: 3.5685 - dense_2_1_loss: 4.7995 - dense_2_2_loss: 4.6544 - dense_2_3_loss: 2.6542 - dense_2_4_loss: 1.4788 - dense_2_5_loss: 0.7683 - dense_2_6_loss: 0.3700 - dense_2_7_loss: 0.1570 - dense_2_accuracy: 0.2710 - dense_2_1_accuracy: 0.1657 - dense_2_2_accuracy: 0.2866 - dense_2_3_accuracy: 0.5542 - dense_2_4_accuracy: 0.6949 - dense_2_5_accuracy: 0.8176 - dense_2_6_accuracy: 0.9105 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 150/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.4475 - dense_2_loss: 3.5676 - dense_2_1_loss: 4.7997 - dense_2_2_loss: 4.6540 - dense_2_3_loss: 2.6550 - dense_2_4_loss: 1.4809 - dense_2_5_loss: 0.7685 - dense_2_6_loss: 0.3706 - dense_2_7_loss: 0.1569 - dense_2_accuracy: 0.2709 - dense_2_1_accuracy: 0.1652 - dense_2_2_accuracy: 0.2867 - dense_2_3_accuracy: 0.5540 - dense_2_4_accuracy: 0.6956 - dense_2_5_accuracy: 0.8156 - dense_2_6_accuracy: 0.9089 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 151/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.4436 - dense_2_loss: 3.5648 - dense_2_1_loss: 4.7977 - dense_2_2_loss: 4.6519 - dense_2_3_loss: 2.6547 - dense_2_4_loss: 1.4801 - dense_2_5_loss: 0.7683 - dense_2_6_loss: 0.3700 - dense_2_7_loss: 0.1572 - dense_2_accuracy: 0.2705 - dense_2_1_accuracy: 0.1654 - dense_2_2_accuracy: 0.2867 - dense_2_3_accuracy: 0.5528 - dense_2_4_accuracy: 0.6965 - dense_2_5_accuracy: 0.8182 - dense_2_6_accuracy: 0.9098 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 152/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.4388 - dense_2_loss: 3.5637 - dense_2_1_loss: 4.7967 - dense_2_2_loss: 4.6524 - dense_2_3_loss: 2.6529 - dense_2_4_loss: 1.4790 - dense_2_5_loss: 0.7681 - dense_2_6_loss: 0.3704 - dense_2_7_loss: 0.1574 - dense_2_accuracy: 0.2717 - dense_2_1_accuracy: 0.1661 - dense_2_2_accuracy: 0.2858 - dense_2_3_accuracy: 0.5545 - dense_2_4_accuracy: 0.6960 - dense_2_5_accuracy: 0.8176 - dense_2_6_accuracy: 0.9097 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 153/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.4333 - dense_2_loss: 3.5634 - dense_2_1_loss: 4.7950 - dense_2_2_loss: 4.6478 - dense_2_3_loss: 2.6507 - dense_2_4_loss: 1.4775 - dense_2_5_loss: 0.7667 - dense_2_6_loss: 0.3696 - dense_2_7_loss: 0.1570 - dense_2_accuracy: 0.2718 - dense_2_1_accuracy: 0.1663 - dense_2_2_accuracy: 0.2859 - dense_2_3_accuracy: 0.5556 - dense_2_4_accuracy: 0.6972 - dense_2_5_accuracy: 0.8182 - dense_2_6_accuracy: 0.9097 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 154/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.4288 - dense_2_loss: 3.5619 - dense_2_1_loss: 4.7947 - dense_2_2_loss: 4.6502 - dense_2_3_loss: 2.6538 - dense_2_4_loss: 1.4788 - dense_2_5_loss: 0.7678 - dense_2_6_loss: 0.3711 - dense_2_7_loss: 0.1574 - dense_2_accuracy: 0.2723 - dense_2_1_accuracy: 0.1653 - dense_2_2_accuracy: 0.2861 - dense_2_3_accuracy: 0.5546 - dense_2_4_accuracy: 0.6966 - dense_2_5_accuracy: 0.8176 - dense_2_6_accuracy: 0.9091 - dense_2_7_accuracy: 0.9660\n",
            "Epoch 155/300\n",
            "10000/10000 [==============================] - 31s 3ms/sample - loss: 18.4243 - dense_2_loss: 3.5595 - dense_2_1_loss: 4.7932 - dense_2_2_loss: 4.6488 - dense_2_3_loss: 2.6502 - dense_2_4_loss: 1.4763 - dense_2_5_loss: 0.7668 - dense_2_6_loss: 0.3694 - dense_2_7_loss: 0.1567 - dense_2_accuracy: 0.2728 - dense_2_1_accuracy: 0.1663 - dense_2_2_accuracy: 0.2855 - dense_2_3_accuracy: 0.5535 - dense_2_4_accuracy: 0.6960 - dense_2_5_accuracy: 0.8178 - dense_2_6_accuracy: 0.9097 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 156/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.4201 - dense_2_loss: 3.5577 - dense_2_1_loss: 4.7907 - dense_2_2_loss: 4.6476 - dense_2_3_loss: 2.6517 - dense_2_4_loss: 1.4773 - dense_2_5_loss: 0.7679 - dense_2_6_loss: 0.3700 - dense_2_7_loss: 0.1573 - dense_2_accuracy: 0.2725 - dense_2_1_accuracy: 0.1668 - dense_2_2_accuracy: 0.2856 - dense_2_3_accuracy: 0.5553 - dense_2_4_accuracy: 0.6969 - dense_2_5_accuracy: 0.8181 - dense_2_6_accuracy: 0.9090 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 157/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.4154 - dense_2_loss: 3.5577 - dense_2_1_loss: 4.7898 - dense_2_2_loss: 4.6470 - dense_2_3_loss: 2.6519 - dense_2_4_loss: 1.4771 - dense_2_5_loss: 0.7674 - dense_2_6_loss: 0.3699 - dense_2_7_loss: 0.1568 - dense_2_accuracy: 0.2730 - dense_2_1_accuracy: 0.1670 - dense_2_2_accuracy: 0.2867 - dense_2_3_accuracy: 0.5554 - dense_2_4_accuracy: 0.6961 - dense_2_5_accuracy: 0.8171 - dense_2_6_accuracy: 0.9099 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 158/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.4113 - dense_2_loss: 3.5550 - dense_2_1_loss: 4.7877 - dense_2_2_loss: 4.6485 - dense_2_3_loss: 2.6528 - dense_2_4_loss: 1.4776 - dense_2_5_loss: 0.7676 - dense_2_6_loss: 0.3702 - dense_2_7_loss: 0.1570 - dense_2_accuracy: 0.2727 - dense_2_1_accuracy: 0.1671 - dense_2_2_accuracy: 0.2858 - dense_2_3_accuracy: 0.5545 - dense_2_4_accuracy: 0.6973 - dense_2_5_accuracy: 0.8176 - dense_2_6_accuracy: 0.9093 - dense_2_7_accuracy: 0.9662\n",
            "Epoch 159/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.4058 - dense_2_loss: 3.5546 - dense_2_1_loss: 4.7885 - dense_2_2_loss: 4.6448 - dense_2_3_loss: 2.6501 - dense_2_4_loss: 1.4756 - dense_2_5_loss: 0.7660 - dense_2_6_loss: 0.3696 - dense_2_7_loss: 0.1570 - dense_2_accuracy: 0.2734 - dense_2_1_accuracy: 0.1668 - dense_2_2_accuracy: 0.2862 - dense_2_3_accuracy: 0.5545 - dense_2_4_accuracy: 0.6971 - dense_2_5_accuracy: 0.8173 - dense_2_6_accuracy: 0.9093 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 160/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.4014 - dense_2_loss: 3.5545 - dense_2_1_loss: 4.7879 - dense_2_2_loss: 4.6425 - dense_2_3_loss: 2.6485 - dense_2_4_loss: 1.4764 - dense_2_5_loss: 0.7662 - dense_2_6_loss: 0.3698 - dense_2_7_loss: 0.1569 - dense_2_accuracy: 0.2731 - dense_2_1_accuracy: 0.1679 - dense_2_2_accuracy: 0.2862 - dense_2_3_accuracy: 0.5554 - dense_2_4_accuracy: 0.6957 - dense_2_5_accuracy: 0.8176 - dense_2_6_accuracy: 0.9097 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 161/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.3967 - dense_2_loss: 3.5520 - dense_2_1_loss: 4.7860 - dense_2_2_loss: 4.6457 - dense_2_3_loss: 2.6494 - dense_2_4_loss: 1.4759 - dense_2_5_loss: 0.7668 - dense_2_6_loss: 0.3704 - dense_2_7_loss: 0.1572 - dense_2_accuracy: 0.2739 - dense_2_1_accuracy: 0.1669 - dense_2_2_accuracy: 0.2867 - dense_2_3_accuracy: 0.5555 - dense_2_4_accuracy: 0.6966 - dense_2_5_accuracy: 0.8177 - dense_2_6_accuracy: 0.9101 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 162/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.3922 - dense_2_loss: 3.5490 - dense_2_1_loss: 4.7839 - dense_2_2_loss: 4.6432 - dense_2_3_loss: 2.6482 - dense_2_4_loss: 1.4754 - dense_2_5_loss: 0.7657 - dense_2_6_loss: 0.3690 - dense_2_7_loss: 0.1567 - dense_2_accuracy: 0.2741 - dense_2_1_accuracy: 0.1672 - dense_2_2_accuracy: 0.2869 - dense_2_3_accuracy: 0.5550 - dense_2_4_accuracy: 0.6966 - dense_2_5_accuracy: 0.8179 - dense_2_6_accuracy: 0.9093 - dense_2_7_accuracy: 0.9661\n",
            "Epoch 163/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.3885 - dense_2_loss: 3.5490 - dense_2_1_loss: 4.7832 - dense_2_2_loss: 4.6403 - dense_2_3_loss: 2.6477 - dense_2_4_loss: 1.4743 - dense_2_5_loss: 0.7648 - dense_2_6_loss: 0.3690 - dense_2_7_loss: 0.1568 - dense_2_accuracy: 0.2742 - dense_2_1_accuracy: 0.1677 - dense_2_2_accuracy: 0.2862 - dense_2_3_accuracy: 0.5557 - dense_2_4_accuracy: 0.6966 - dense_2_5_accuracy: 0.8181 - dense_2_6_accuracy: 0.9092 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 164/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.3846 - dense_2_loss: 3.5476 - dense_2_1_loss: 4.7819 - dense_2_2_loss: 4.6421 - dense_2_3_loss: 2.6482 - dense_2_4_loss: 1.4758 - dense_2_5_loss: 0.7656 - dense_2_6_loss: 0.3703 - dense_2_7_loss: 0.1573 - dense_2_accuracy: 0.2752 - dense_2_1_accuracy: 0.1674 - dense_2_2_accuracy: 0.2868 - dense_2_3_accuracy: 0.5551 - dense_2_4_accuracy: 0.6966 - dense_2_5_accuracy: 0.8185 - dense_2_6_accuracy: 0.9093 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 165/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.3793 - dense_2_loss: 3.5447 - dense_2_1_loss: 4.7810 - dense_2_2_loss: 4.6416 - dense_2_3_loss: 2.6465 - dense_2_4_loss: 1.4741 - dense_2_5_loss: 0.7655 - dense_2_6_loss: 0.3698 - dense_2_7_loss: 0.1570 - dense_2_accuracy: 0.2756 - dense_2_1_accuracy: 0.1674 - dense_2_2_accuracy: 0.2870 - dense_2_3_accuracy: 0.5559 - dense_2_4_accuracy: 0.6978 - dense_2_5_accuracy: 0.8180 - dense_2_6_accuracy: 0.9098 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 166/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.3760 - dense_2_loss: 3.5447 - dense_2_1_loss: 4.7789 - dense_2_2_loss: 4.6401 - dense_2_3_loss: 2.6457 - dense_2_4_loss: 1.4751 - dense_2_5_loss: 0.7654 - dense_2_6_loss: 0.3696 - dense_2_7_loss: 0.1572 - dense_2_accuracy: 0.2748 - dense_2_1_accuracy: 0.1683 - dense_2_2_accuracy: 0.2865 - dense_2_3_accuracy: 0.5560 - dense_2_4_accuracy: 0.6959 - dense_2_5_accuracy: 0.8178 - dense_2_6_accuracy: 0.9095 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 167/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.3712 - dense_2_loss: 3.5438 - dense_2_1_loss: 4.7778 - dense_2_2_loss: 4.6383 - dense_2_3_loss: 2.6444 - dense_2_4_loss: 1.4721 - dense_2_5_loss: 0.7641 - dense_2_6_loss: 0.3688 - dense_2_7_loss: 0.1565 - dense_2_accuracy: 0.2755 - dense_2_1_accuracy: 0.1684 - dense_2_2_accuracy: 0.2866 - dense_2_3_accuracy: 0.5559 - dense_2_4_accuracy: 0.6966 - dense_2_5_accuracy: 0.8189 - dense_2_6_accuracy: 0.9100 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 168/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.3670 - dense_2_loss: 3.5422 - dense_2_1_loss: 4.7771 - dense_2_2_loss: 4.6375 - dense_2_3_loss: 2.6445 - dense_2_4_loss: 1.4737 - dense_2_5_loss: 0.7648 - dense_2_6_loss: 0.3692 - dense_2_7_loss: 0.1565 - dense_2_accuracy: 0.2758 - dense_2_1_accuracy: 0.1681 - dense_2_2_accuracy: 0.2872 - dense_2_3_accuracy: 0.5565 - dense_2_4_accuracy: 0.6970 - dense_2_5_accuracy: 0.8179 - dense_2_6_accuracy: 0.9097 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 169/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.3629 - dense_2_loss: 3.5409 - dense_2_1_loss: 4.7768 - dense_2_2_loss: 4.6381 - dense_2_3_loss: 2.6436 - dense_2_4_loss: 1.4724 - dense_2_5_loss: 0.7638 - dense_2_6_loss: 0.3687 - dense_2_7_loss: 0.1567 - dense_2_accuracy: 0.2754 - dense_2_1_accuracy: 0.1684 - dense_2_2_accuracy: 0.2864 - dense_2_3_accuracy: 0.5563 - dense_2_4_accuracy: 0.6963 - dense_2_5_accuracy: 0.8182 - dense_2_6_accuracy: 0.9106 - dense_2_7_accuracy: 0.9662\n",
            "Epoch 170/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.3593 - dense_2_loss: 3.5399 - dense_2_1_loss: 4.7763 - dense_2_2_loss: 4.6370 - dense_2_3_loss: 2.6456 - dense_2_4_loss: 1.4733 - dense_2_5_loss: 0.7644 - dense_2_6_loss: 0.3693 - dense_2_7_loss: 0.1565 - dense_2_accuracy: 0.2763 - dense_2_1_accuracy: 0.1689 - dense_2_2_accuracy: 0.2869 - dense_2_3_accuracy: 0.5563 - dense_2_4_accuracy: 0.6962 - dense_2_5_accuracy: 0.8185 - dense_2_6_accuracy: 0.9094 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 171/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.3544 - dense_2_loss: 3.5395 - dense_2_1_loss: 4.7756 - dense_2_2_loss: 4.6355 - dense_2_3_loss: 2.6450 - dense_2_4_loss: 1.4732 - dense_2_5_loss: 0.7647 - dense_2_6_loss: 0.3702 - dense_2_7_loss: 0.1569 - dense_2_accuracy: 0.2757 - dense_2_1_accuracy: 0.1684 - dense_2_2_accuracy: 0.2870 - dense_2_3_accuracy: 0.5559 - dense_2_4_accuracy: 0.6961 - dense_2_5_accuracy: 0.8186 - dense_2_6_accuracy: 0.9100 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 172/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.3503 - dense_2_loss: 3.5386 - dense_2_1_loss: 4.7746 - dense_2_2_loss: 4.6351 - dense_2_3_loss: 2.6409 - dense_2_4_loss: 1.4728 - dense_2_5_loss: 0.7631 - dense_2_6_loss: 0.3688 - dense_2_7_loss: 0.1566 - dense_2_accuracy: 0.2763 - dense_2_1_accuracy: 0.1681 - dense_2_2_accuracy: 0.2874 - dense_2_3_accuracy: 0.5572 - dense_2_4_accuracy: 0.6971 - dense_2_5_accuracy: 0.8179 - dense_2_6_accuracy: 0.9099 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 173/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.3466 - dense_2_loss: 3.5379 - dense_2_1_loss: 4.7731 - dense_2_2_loss: 4.6333 - dense_2_3_loss: 2.6420 - dense_2_4_loss: 1.4718 - dense_2_5_loss: 0.7649 - dense_2_6_loss: 0.3693 - dense_2_7_loss: 0.1569 - dense_2_accuracy: 0.2771 - dense_2_1_accuracy: 0.1685 - dense_2_2_accuracy: 0.2869 - dense_2_3_accuracy: 0.5563 - dense_2_4_accuracy: 0.6974 - dense_2_5_accuracy: 0.8181 - dense_2_6_accuracy: 0.9098 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 174/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.3423 - dense_2_loss: 3.5355 - dense_2_1_loss: 4.7700 - dense_2_2_loss: 4.6328 - dense_2_3_loss: 2.6399 - dense_2_4_loss: 1.4711 - dense_2_5_loss: 0.7638 - dense_2_6_loss: 0.3690 - dense_2_7_loss: 0.1568 - dense_2_accuracy: 0.2765 - dense_2_1_accuracy: 0.1689 - dense_2_2_accuracy: 0.2874 - dense_2_3_accuracy: 0.5558 - dense_2_4_accuracy: 0.6963 - dense_2_5_accuracy: 0.8185 - dense_2_6_accuracy: 0.9102 - dense_2_7_accuracy: 0.9667\n",
            "Epoch 175/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.3382 - dense_2_loss: 3.5344 - dense_2_1_loss: 4.7719 - dense_2_2_loss: 4.6330 - dense_2_3_loss: 2.6422 - dense_2_4_loss: 1.4722 - dense_2_5_loss: 0.7646 - dense_2_6_loss: 0.3695 - dense_2_7_loss: 0.1573 - dense_2_accuracy: 0.2766 - dense_2_1_accuracy: 0.1691 - dense_2_2_accuracy: 0.2873 - dense_2_3_accuracy: 0.5568 - dense_2_4_accuracy: 0.6969 - dense_2_5_accuracy: 0.8192 - dense_2_6_accuracy: 0.9105 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 176/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.3344 - dense_2_loss: 3.5338 - dense_2_1_loss: 4.7695 - dense_2_2_loss: 4.6317 - dense_2_3_loss: 2.6398 - dense_2_4_loss: 1.4702 - dense_2_5_loss: 0.7626 - dense_2_6_loss: 0.3681 - dense_2_7_loss: 0.1564 - dense_2_accuracy: 0.2771 - dense_2_1_accuracy: 0.1692 - dense_2_2_accuracy: 0.2874 - dense_2_3_accuracy: 0.5573 - dense_2_4_accuracy: 0.6967 - dense_2_5_accuracy: 0.8183 - dense_2_6_accuracy: 0.9099 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 177/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.3304 - dense_2_loss: 3.5316 - dense_2_1_loss: 4.7678 - dense_2_2_loss: 4.6298 - dense_2_3_loss: 2.6419 - dense_2_4_loss: 1.4711 - dense_2_5_loss: 0.7634 - dense_2_6_loss: 0.3687 - dense_2_7_loss: 0.1567 - dense_2_accuracy: 0.2769 - dense_2_1_accuracy: 0.1692 - dense_2_2_accuracy: 0.2873 - dense_2_3_accuracy: 0.5566 - dense_2_4_accuracy: 0.6974 - dense_2_5_accuracy: 0.8194 - dense_2_6_accuracy: 0.9100 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 178/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.3263 - dense_2_loss: 3.5276 - dense_2_1_loss: 4.7667 - dense_2_2_loss: 4.6306 - dense_2_3_loss: 2.6373 - dense_2_4_loss: 1.4694 - dense_2_5_loss: 0.7619 - dense_2_6_loss: 0.3682 - dense_2_7_loss: 0.1564 - dense_2_accuracy: 0.2767 - dense_2_1_accuracy: 0.1693 - dense_2_2_accuracy: 0.2869 - dense_2_3_accuracy: 0.5576 - dense_2_4_accuracy: 0.6972 - dense_2_5_accuracy: 0.8183 - dense_2_6_accuracy: 0.9101 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 179/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.3224 - dense_2_loss: 3.5293 - dense_2_1_loss: 4.7663 - dense_2_2_loss: 4.6283 - dense_2_3_loss: 2.6379 - dense_2_4_loss: 1.4694 - dense_2_5_loss: 0.7627 - dense_2_6_loss: 0.3685 - dense_2_7_loss: 0.1568 - dense_2_accuracy: 0.2771 - dense_2_1_accuracy: 0.1694 - dense_2_2_accuracy: 0.2876 - dense_2_3_accuracy: 0.5568 - dense_2_4_accuracy: 0.6966 - dense_2_5_accuracy: 0.8192 - dense_2_6_accuracy: 0.9094 - dense_2_7_accuracy: 0.9662\n",
            "Epoch 180/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.3182 - dense_2_loss: 3.5285 - dense_2_1_loss: 4.7652 - dense_2_2_loss: 4.6316 - dense_2_3_loss: 2.6369 - dense_2_4_loss: 1.4706 - dense_2_5_loss: 0.7622 - dense_2_6_loss: 0.3682 - dense_2_7_loss: 0.1562 - dense_2_accuracy: 0.2775 - dense_2_1_accuracy: 0.1690 - dense_2_2_accuracy: 0.2874 - dense_2_3_accuracy: 0.5555 - dense_2_4_accuracy: 0.6979 - dense_2_5_accuracy: 0.8193 - dense_2_6_accuracy: 0.9108 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 181/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.3154 - dense_2_loss: 3.5274 - dense_2_1_loss: 4.7636 - dense_2_2_loss: 4.6274 - dense_2_3_loss: 2.6374 - dense_2_4_loss: 1.4704 - dense_2_5_loss: 0.7632 - dense_2_6_loss: 0.3691 - dense_2_7_loss: 0.1571 - dense_2_accuracy: 0.2778 - dense_2_1_accuracy: 0.1698 - dense_2_2_accuracy: 0.2875 - dense_2_3_accuracy: 0.5577 - dense_2_4_accuracy: 0.6974 - dense_2_5_accuracy: 0.8193 - dense_2_6_accuracy: 0.9104 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 182/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.3102 - dense_2_loss: 3.5248 - dense_2_1_loss: 4.7623 - dense_2_2_loss: 4.6275 - dense_2_3_loss: 2.6377 - dense_2_4_loss: 1.4684 - dense_2_5_loss: 0.7624 - dense_2_6_loss: 0.3681 - dense_2_7_loss: 0.1565 - dense_2_accuracy: 0.2776 - dense_2_1_accuracy: 0.1698 - dense_2_2_accuracy: 0.2878 - dense_2_3_accuracy: 0.5575 - dense_2_4_accuracy: 0.6971 - dense_2_5_accuracy: 0.8192 - dense_2_6_accuracy: 0.9104 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 183/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.3063 - dense_2_loss: 3.5251 - dense_2_1_loss: 4.7629 - dense_2_2_loss: 4.6260 - dense_2_3_loss: 2.6369 - dense_2_4_loss: 1.4687 - dense_2_5_loss: 0.7617 - dense_2_6_loss: 0.3681 - dense_2_7_loss: 0.1561 - dense_2_accuracy: 0.2779 - dense_2_1_accuracy: 0.1696 - dense_2_2_accuracy: 0.2886 - dense_2_3_accuracy: 0.5567 - dense_2_4_accuracy: 0.6984 - dense_2_5_accuracy: 0.8188 - dense_2_6_accuracy: 0.9097 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 184/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.3040 - dense_2_loss: 3.5225 - dense_2_1_loss: 4.7598 - dense_2_2_loss: 4.6274 - dense_2_3_loss: 2.6350 - dense_2_4_loss: 1.4694 - dense_2_5_loss: 0.7619 - dense_2_6_loss: 0.3682 - dense_2_7_loss: 0.1565 - dense_2_accuracy: 0.2782 - dense_2_1_accuracy: 0.1701 - dense_2_2_accuracy: 0.2879 - dense_2_3_accuracy: 0.5553 - dense_2_4_accuracy: 0.6971 - dense_2_5_accuracy: 0.8176 - dense_2_6_accuracy: 0.9105 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 185/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.2991 - dense_2_loss: 3.5217 - dense_2_1_loss: 4.7615 - dense_2_2_loss: 4.6247 - dense_2_3_loss: 2.6365 - dense_2_4_loss: 1.4720 - dense_2_5_loss: 0.7628 - dense_2_6_loss: 0.3687 - dense_2_7_loss: 0.1565 - dense_2_accuracy: 0.2782 - dense_2_1_accuracy: 0.1697 - dense_2_2_accuracy: 0.2877 - dense_2_3_accuracy: 0.5568 - dense_2_4_accuracy: 0.6983 - dense_2_5_accuracy: 0.8181 - dense_2_6_accuracy: 0.9108 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 186/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.2964 - dense_2_loss: 3.5211 - dense_2_1_loss: 4.7595 - dense_2_2_loss: 4.6247 - dense_2_3_loss: 2.6352 - dense_2_4_loss: 1.4681 - dense_2_5_loss: 0.7612 - dense_2_6_loss: 0.3677 - dense_2_7_loss: 0.1562 - dense_2_accuracy: 0.2784 - dense_2_1_accuracy: 0.1696 - dense_2_2_accuracy: 0.2881 - dense_2_3_accuracy: 0.5573 - dense_2_4_accuracy: 0.6963 - dense_2_5_accuracy: 0.8195 - dense_2_6_accuracy: 0.9100 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 187/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.2920 - dense_2_loss: 3.5197 - dense_2_1_loss: 4.7581 - dense_2_2_loss: 4.6258 - dense_2_3_loss: 2.6351 - dense_2_4_loss: 1.4682 - dense_2_5_loss: 0.7615 - dense_2_6_loss: 0.3685 - dense_2_7_loss: 0.1564 - dense_2_accuracy: 0.2788 - dense_2_1_accuracy: 0.1701 - dense_2_2_accuracy: 0.2877 - dense_2_3_accuracy: 0.5575 - dense_2_4_accuracy: 0.6976 - dense_2_5_accuracy: 0.8192 - dense_2_6_accuracy: 0.9110 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 188/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.2891 - dense_2_loss: 3.5184 - dense_2_1_loss: 4.7570 - dense_2_2_loss: 4.6255 - dense_2_3_loss: 2.6357 - dense_2_4_loss: 1.4690 - dense_2_5_loss: 0.7613 - dense_2_6_loss: 0.3678 - dense_2_7_loss: 0.1562 - dense_2_accuracy: 0.2789 - dense_2_1_accuracy: 0.1706 - dense_2_2_accuracy: 0.2880 - dense_2_3_accuracy: 0.5578 - dense_2_4_accuracy: 0.6987 - dense_2_5_accuracy: 0.8182 - dense_2_6_accuracy: 0.9101 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 189/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.2841 - dense_2_loss: 3.5178 - dense_2_1_loss: 4.7560 - dense_2_2_loss: 4.6219 - dense_2_3_loss: 2.6356 - dense_2_4_loss: 1.4678 - dense_2_5_loss: 0.7610 - dense_2_6_loss: 0.3681 - dense_2_7_loss: 0.1563 - dense_2_accuracy: 0.2794 - dense_2_1_accuracy: 0.1708 - dense_2_2_accuracy: 0.2881 - dense_2_3_accuracy: 0.5577 - dense_2_4_accuracy: 0.6987 - dense_2_5_accuracy: 0.8197 - dense_2_6_accuracy: 0.9106 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 190/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.2812 - dense_2_loss: 3.5163 - dense_2_1_loss: 4.7546 - dense_2_2_loss: 4.6221 - dense_2_3_loss: 2.6353 - dense_2_4_loss: 1.4685 - dense_2_5_loss: 0.7609 - dense_2_6_loss: 0.3681 - dense_2_7_loss: 0.1560 - dense_2_accuracy: 0.2792 - dense_2_1_accuracy: 0.1705 - dense_2_2_accuracy: 0.2886 - dense_2_3_accuracy: 0.5574 - dense_2_4_accuracy: 0.6979 - dense_2_5_accuracy: 0.8200 - dense_2_6_accuracy: 0.9108 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 191/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.2786 - dense_2_loss: 3.5157 - dense_2_1_loss: 4.7548 - dense_2_2_loss: 4.6190 - dense_2_3_loss: 2.6335 - dense_2_4_loss: 1.4680 - dense_2_5_loss: 0.7611 - dense_2_6_loss: 0.3679 - dense_2_7_loss: 0.1564 - dense_2_accuracy: 0.2795 - dense_2_1_accuracy: 0.1714 - dense_2_2_accuracy: 0.2880 - dense_2_3_accuracy: 0.5572 - dense_2_4_accuracy: 0.6973 - dense_2_5_accuracy: 0.8186 - dense_2_6_accuracy: 0.9110 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 192/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.2741 - dense_2_loss: 3.5144 - dense_2_1_loss: 4.7535 - dense_2_2_loss: 4.6216 - dense_2_3_loss: 2.6334 - dense_2_4_loss: 1.4664 - dense_2_5_loss: 0.7600 - dense_2_6_loss: 0.3672 - dense_2_7_loss: 0.1561 - dense_2_accuracy: 0.2795 - dense_2_1_accuracy: 0.1712 - dense_2_2_accuracy: 0.2884 - dense_2_3_accuracy: 0.5579 - dense_2_4_accuracy: 0.6978 - dense_2_5_accuracy: 0.8193 - dense_2_6_accuracy: 0.9109 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 193/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.2702 - dense_2_loss: 3.5135 - dense_2_1_loss: 4.7530 - dense_2_2_loss: 4.6192 - dense_2_3_loss: 2.6323 - dense_2_4_loss: 1.4661 - dense_2_5_loss: 0.7604 - dense_2_6_loss: 0.3682 - dense_2_7_loss: 0.1565 - dense_2_accuracy: 0.2797 - dense_2_1_accuracy: 0.1707 - dense_2_2_accuracy: 0.2884 - dense_2_3_accuracy: 0.5586 - dense_2_4_accuracy: 0.6988 - dense_2_5_accuracy: 0.8194 - dense_2_6_accuracy: 0.9110 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 194/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.2676 - dense_2_loss: 3.5113 - dense_2_1_loss: 4.7520 - dense_2_2_loss: 4.6207 - dense_2_3_loss: 2.6360 - dense_2_4_loss: 1.4675 - dense_2_5_loss: 0.7606 - dense_2_6_loss: 0.3678 - dense_2_7_loss: 0.1560 - dense_2_accuracy: 0.2797 - dense_2_1_accuracy: 0.1712 - dense_2_2_accuracy: 0.2886 - dense_2_3_accuracy: 0.5575 - dense_2_4_accuracy: 0.6993 - dense_2_5_accuracy: 0.8200 - dense_2_6_accuracy: 0.9110 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 195/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.2634 - dense_2_loss: 3.5131 - dense_2_1_loss: 4.7499 - dense_2_2_loss: 4.6188 - dense_2_3_loss: 2.6324 - dense_2_4_loss: 1.4669 - dense_2_5_loss: 0.7603 - dense_2_6_loss: 0.3681 - dense_2_7_loss: 0.1563 - dense_2_accuracy: 0.2800 - dense_2_1_accuracy: 0.1712 - dense_2_2_accuracy: 0.2893 - dense_2_3_accuracy: 0.5571 - dense_2_4_accuracy: 0.6967 - dense_2_5_accuracy: 0.8197 - dense_2_6_accuracy: 0.9103 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 196/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.2603 - dense_2_loss: 3.5104 - dense_2_1_loss: 4.7499 - dense_2_2_loss: 4.6178 - dense_2_3_loss: 2.6324 - dense_2_4_loss: 1.4675 - dense_2_5_loss: 0.7600 - dense_2_6_loss: 0.3670 - dense_2_7_loss: 0.1560 - dense_2_accuracy: 0.2800 - dense_2_1_accuracy: 0.1717 - dense_2_2_accuracy: 0.2883 - dense_2_3_accuracy: 0.5573 - dense_2_4_accuracy: 0.6981 - dense_2_5_accuracy: 0.8207 - dense_2_6_accuracy: 0.9107 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 197/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.2570 - dense_2_loss: 3.5083 - dense_2_1_loss: 4.7458 - dense_2_2_loss: 4.6166 - dense_2_3_loss: 2.6284 - dense_2_4_loss: 1.4655 - dense_2_5_loss: 0.7599 - dense_2_6_loss: 0.3677 - dense_2_7_loss: 0.1564 - dense_2_accuracy: 0.2799 - dense_2_1_accuracy: 0.1716 - dense_2_2_accuracy: 0.2890 - dense_2_3_accuracy: 0.5584 - dense_2_4_accuracy: 0.6979 - dense_2_5_accuracy: 0.8203 - dense_2_6_accuracy: 0.9108 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 198/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.2538 - dense_2_loss: 3.5079 - dense_2_1_loss: 4.7483 - dense_2_2_loss: 4.6191 - dense_2_3_loss: 2.6310 - dense_2_4_loss: 1.4677 - dense_2_5_loss: 0.7606 - dense_2_6_loss: 0.3676 - dense_2_7_loss: 0.1561 - dense_2_accuracy: 0.2800 - dense_2_1_accuracy: 0.1716 - dense_2_2_accuracy: 0.2887 - dense_2_3_accuracy: 0.5576 - dense_2_4_accuracy: 0.6974 - dense_2_5_accuracy: 0.8197 - dense_2_6_accuracy: 0.9107 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 199/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.2497 - dense_2_loss: 3.5069 - dense_2_1_loss: 4.7468 - dense_2_2_loss: 4.6156 - dense_2_3_loss: 2.6299 - dense_2_4_loss: 1.4645 - dense_2_5_loss: 0.7592 - dense_2_6_loss: 0.3671 - dense_2_7_loss: 0.1558 - dense_2_accuracy: 0.2807 - dense_2_1_accuracy: 0.1718 - dense_2_2_accuracy: 0.2891 - dense_2_3_accuracy: 0.5579 - dense_2_4_accuracy: 0.6984 - dense_2_5_accuracy: 0.8197 - dense_2_6_accuracy: 0.9108 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 200/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.2463 - dense_2_loss: 3.5056 - dense_2_1_loss: 4.7444 - dense_2_2_loss: 4.6141 - dense_2_3_loss: 2.6300 - dense_2_4_loss: 1.4661 - dense_2_5_loss: 0.7602 - dense_2_6_loss: 0.3676 - dense_2_7_loss: 0.1561 - dense_2_accuracy: 0.2808 - dense_2_1_accuracy: 0.1715 - dense_2_2_accuracy: 0.2893 - dense_2_3_accuracy: 0.5587 - dense_2_4_accuracy: 0.6975 - dense_2_5_accuracy: 0.8190 - dense_2_6_accuracy: 0.9111 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 201/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.2434 - dense_2_loss: 3.5066 - dense_2_1_loss: 4.7444 - dense_2_2_loss: 4.6146 - dense_2_3_loss: 2.6301 - dense_2_4_loss: 1.4652 - dense_2_5_loss: 0.7590 - dense_2_6_loss: 0.3669 - dense_2_7_loss: 0.1560 - dense_2_accuracy: 0.2807 - dense_2_1_accuracy: 0.1715 - dense_2_2_accuracy: 0.2895 - dense_2_3_accuracy: 0.5587 - dense_2_4_accuracy: 0.6975 - dense_2_5_accuracy: 0.8195 - dense_2_6_accuracy: 0.9103 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 202/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.2394 - dense_2_loss: 3.5046 - dense_2_1_loss: 4.7446 - dense_2_2_loss: 4.6148 - dense_2_3_loss: 2.6271 - dense_2_4_loss: 1.4653 - dense_2_5_loss: 0.7597 - dense_2_6_loss: 0.3677 - dense_2_7_loss: 0.1563 - dense_2_accuracy: 0.2810 - dense_2_1_accuracy: 0.1718 - dense_2_2_accuracy: 0.2900 - dense_2_3_accuracy: 0.5578 - dense_2_4_accuracy: 0.6982 - dense_2_5_accuracy: 0.8191 - dense_2_6_accuracy: 0.9106 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 203/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.2363 - dense_2_loss: 3.5046 - dense_2_1_loss: 4.7438 - dense_2_2_loss: 4.6132 - dense_2_3_loss: 2.6288 - dense_2_4_loss: 1.4657 - dense_2_5_loss: 0.7588 - dense_2_6_loss: 0.3670 - dense_2_7_loss: 0.1559 - dense_2_accuracy: 0.2812 - dense_2_1_accuracy: 0.1717 - dense_2_2_accuracy: 0.2894 - dense_2_3_accuracy: 0.5586 - dense_2_4_accuracy: 0.6977 - dense_2_5_accuracy: 0.8199 - dense_2_6_accuracy: 0.9114 - dense_2_7_accuracy: 0.9668\n",
            "Epoch 204/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.2334 - dense_2_loss: 3.5026 - dense_2_1_loss: 4.7442 - dense_2_2_loss: 4.6120 - dense_2_3_loss: 2.6264 - dense_2_4_loss: 1.4635 - dense_2_5_loss: 0.7585 - dense_2_6_loss: 0.3667 - dense_2_7_loss: 0.1558 - dense_2_accuracy: 0.2813 - dense_2_1_accuracy: 0.1718 - dense_2_2_accuracy: 0.2897 - dense_2_3_accuracy: 0.5581 - dense_2_4_accuracy: 0.6985 - dense_2_5_accuracy: 0.8192 - dense_2_6_accuracy: 0.9102 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 205/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.2298 - dense_2_loss: 3.5018 - dense_2_1_loss: 4.7418 - dense_2_2_loss: 4.6103 - dense_2_3_loss: 2.6265 - dense_2_4_loss: 1.4648 - dense_2_5_loss: 0.7599 - dense_2_6_loss: 0.3673 - dense_2_7_loss: 0.1563 - dense_2_accuracy: 0.2812 - dense_2_1_accuracy: 0.1717 - dense_2_2_accuracy: 0.2900 - dense_2_3_accuracy: 0.5581 - dense_2_4_accuracy: 0.6977 - dense_2_5_accuracy: 0.8195 - dense_2_6_accuracy: 0.9111 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 206/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.2266 - dense_2_loss: 3.4995 - dense_2_1_loss: 4.7410 - dense_2_2_loss: 4.6098 - dense_2_3_loss: 2.6275 - dense_2_4_loss: 1.4648 - dense_2_5_loss: 0.7599 - dense_2_6_loss: 0.3677 - dense_2_7_loss: 0.1562 - dense_2_accuracy: 0.2815 - dense_2_1_accuracy: 0.1723 - dense_2_2_accuracy: 0.2899 - dense_2_3_accuracy: 0.5595 - dense_2_4_accuracy: 0.6977 - dense_2_5_accuracy: 0.8199 - dense_2_6_accuracy: 0.9107 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 207/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.2232 - dense_2_loss: 3.4987 - dense_2_1_loss: 4.7388 - dense_2_2_loss: 4.6106 - dense_2_3_loss: 2.6265 - dense_2_4_loss: 1.4648 - dense_2_5_loss: 0.7590 - dense_2_6_loss: 0.3673 - dense_2_7_loss: 0.1559 - dense_2_accuracy: 0.2816 - dense_2_1_accuracy: 0.1719 - dense_2_2_accuracy: 0.2897 - dense_2_3_accuracy: 0.5577 - dense_2_4_accuracy: 0.6983 - dense_2_5_accuracy: 0.8192 - dense_2_6_accuracy: 0.9106 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 208/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.2195 - dense_2_loss: 3.4972 - dense_2_1_loss: 4.7387 - dense_2_2_loss: 4.6104 - dense_2_3_loss: 2.6261 - dense_2_4_loss: 1.4637 - dense_2_5_loss: 0.7579 - dense_2_6_loss: 0.3664 - dense_2_7_loss: 0.1557 - dense_2_accuracy: 0.2820 - dense_2_1_accuracy: 0.1720 - dense_2_2_accuracy: 0.2899 - dense_2_3_accuracy: 0.5595 - dense_2_4_accuracy: 0.6980 - dense_2_5_accuracy: 0.8197 - dense_2_6_accuracy: 0.9113 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 209/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.2175 - dense_2_loss: 3.4962 - dense_2_1_loss: 4.7374 - dense_2_2_loss: 4.6116 - dense_2_3_loss: 2.6243 - dense_2_4_loss: 1.4625 - dense_2_5_loss: 0.7581 - dense_2_6_loss: 0.3666 - dense_2_7_loss: 0.1558 - dense_2_accuracy: 0.2817 - dense_2_1_accuracy: 0.1723 - dense_2_2_accuracy: 0.2901 - dense_2_3_accuracy: 0.5588 - dense_2_4_accuracy: 0.6978 - dense_2_5_accuracy: 0.8196 - dense_2_6_accuracy: 0.9109 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 210/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.2129 - dense_2_loss: 3.4972 - dense_2_1_loss: 4.7381 - dense_2_2_loss: 4.6080 - dense_2_3_loss: 2.6246 - dense_2_4_loss: 1.4635 - dense_2_5_loss: 0.7584 - dense_2_6_loss: 0.3672 - dense_2_7_loss: 0.1561 - dense_2_accuracy: 0.2817 - dense_2_1_accuracy: 0.1725 - dense_2_2_accuracy: 0.2908 - dense_2_3_accuracy: 0.5583 - dense_2_4_accuracy: 0.6985 - dense_2_5_accuracy: 0.8198 - dense_2_6_accuracy: 0.9109 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 211/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.2107 - dense_2_loss: 3.4953 - dense_2_1_loss: 4.7372 - dense_2_2_loss: 4.6082 - dense_2_3_loss: 2.6249 - dense_2_4_loss: 1.4626 - dense_2_5_loss: 0.7581 - dense_2_6_loss: 0.3664 - dense_2_7_loss: 0.1555 - dense_2_accuracy: 0.2820 - dense_2_1_accuracy: 0.1722 - dense_2_2_accuracy: 0.2903 - dense_2_3_accuracy: 0.5591 - dense_2_4_accuracy: 0.6977 - dense_2_5_accuracy: 0.8188 - dense_2_6_accuracy: 0.9109 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 212/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.2075 - dense_2_loss: 3.4947 - dense_2_1_loss: 4.7360 - dense_2_2_loss: 4.6070 - dense_2_3_loss: 2.6236 - dense_2_4_loss: 1.4628 - dense_2_5_loss: 0.7579 - dense_2_6_loss: 0.3668 - dense_2_7_loss: 0.1558 - dense_2_accuracy: 0.2821 - dense_2_1_accuracy: 0.1725 - dense_2_2_accuracy: 0.2908 - dense_2_3_accuracy: 0.5594 - dense_2_4_accuracy: 0.6991 - dense_2_5_accuracy: 0.8199 - dense_2_6_accuracy: 0.9106 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 213/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.2034 - dense_2_loss: 3.4931 - dense_2_1_loss: 4.7337 - dense_2_2_loss: 4.6086 - dense_2_3_loss: 2.6243 - dense_2_4_loss: 1.4644 - dense_2_5_loss: 0.7579 - dense_2_6_loss: 0.3668 - dense_2_7_loss: 0.1558 - dense_2_accuracy: 0.2830 - dense_2_1_accuracy: 0.1718 - dense_2_2_accuracy: 0.2902 - dense_2_3_accuracy: 0.5586 - dense_2_4_accuracy: 0.6988 - dense_2_5_accuracy: 0.8203 - dense_2_6_accuracy: 0.9114 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 214/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.2008 - dense_2_loss: 3.4922 - dense_2_1_loss: 4.7348 - dense_2_2_loss: 4.6070 - dense_2_3_loss: 2.6238 - dense_2_4_loss: 1.4638 - dense_2_5_loss: 0.7578 - dense_2_6_loss: 0.3669 - dense_2_7_loss: 0.1557 - dense_2_accuracy: 0.2827 - dense_2_1_accuracy: 0.1726 - dense_2_2_accuracy: 0.2912 - dense_2_3_accuracy: 0.5587 - dense_2_4_accuracy: 0.6992 - dense_2_5_accuracy: 0.8207 - dense_2_6_accuracy: 0.9111 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 215/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1979 - dense_2_loss: 3.4915 - dense_2_1_loss: 4.7337 - dense_2_2_loss: 4.6060 - dense_2_3_loss: 2.6223 - dense_2_4_loss: 1.4610 - dense_2_5_loss: 0.7572 - dense_2_6_loss: 0.3666 - dense_2_7_loss: 0.1556 - dense_2_accuracy: 0.2828 - dense_2_1_accuracy: 0.1723 - dense_2_2_accuracy: 0.2909 - dense_2_3_accuracy: 0.5592 - dense_2_4_accuracy: 0.6985 - dense_2_5_accuracy: 0.8200 - dense_2_6_accuracy: 0.9106 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 216/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.1950 - dense_2_loss: 3.4911 - dense_2_1_loss: 4.7322 - dense_2_2_loss: 4.6042 - dense_2_3_loss: 2.6232 - dense_2_4_loss: 1.4626 - dense_2_5_loss: 0.7572 - dense_2_6_loss: 0.3663 - dense_2_7_loss: 0.1556 - dense_2_accuracy: 0.2828 - dense_2_1_accuracy: 0.1724 - dense_2_2_accuracy: 0.2910 - dense_2_3_accuracy: 0.5593 - dense_2_4_accuracy: 0.6978 - dense_2_5_accuracy: 0.8206 - dense_2_6_accuracy: 0.9109 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 217/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1915 - dense_2_loss: 3.4919 - dense_2_1_loss: 4.7331 - dense_2_2_loss: 4.6047 - dense_2_3_loss: 2.6221 - dense_2_4_loss: 1.4625 - dense_2_5_loss: 0.7570 - dense_2_6_loss: 0.3664 - dense_2_7_loss: 0.1557 - dense_2_accuracy: 0.2831 - dense_2_1_accuracy: 0.1723 - dense_2_2_accuracy: 0.2913 - dense_2_3_accuracy: 0.5603 - dense_2_4_accuracy: 0.6992 - dense_2_5_accuracy: 0.8211 - dense_2_6_accuracy: 0.9117 - dense_2_7_accuracy: 0.9662\n",
            "Epoch 218/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1881 - dense_2_loss: 3.4889 - dense_2_1_loss: 4.7295 - dense_2_2_loss: 4.6031 - dense_2_3_loss: 2.6230 - dense_2_4_loss: 1.4619 - dense_2_5_loss: 0.7580 - dense_2_6_loss: 0.3681 - dense_2_7_loss: 0.1563 - dense_2_accuracy: 0.2837 - dense_2_1_accuracy: 0.1724 - dense_2_2_accuracy: 0.2904 - dense_2_3_accuracy: 0.5582 - dense_2_4_accuracy: 0.6982 - dense_2_5_accuracy: 0.8207 - dense_2_6_accuracy: 0.9110 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 219/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1856 - dense_2_loss: 3.4895 - dense_2_1_loss: 4.7312 - dense_2_2_loss: 4.6061 - dense_2_3_loss: 2.6228 - dense_2_4_loss: 1.4612 - dense_2_5_loss: 0.7571 - dense_2_6_loss: 0.3663 - dense_2_7_loss: 0.1555 - dense_2_accuracy: 0.2842 - dense_2_1_accuracy: 0.1723 - dense_2_2_accuracy: 0.2915 - dense_2_3_accuracy: 0.5596 - dense_2_4_accuracy: 0.6988 - dense_2_5_accuracy: 0.8207 - dense_2_6_accuracy: 0.9112 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 220/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1828 - dense_2_loss: 3.4878 - dense_2_1_loss: 4.7283 - dense_2_2_loss: 4.6028 - dense_2_3_loss: 2.6208 - dense_2_4_loss: 1.4609 - dense_2_5_loss: 0.7566 - dense_2_6_loss: 0.3662 - dense_2_7_loss: 0.1555 - dense_2_accuracy: 0.2842 - dense_2_1_accuracy: 0.1723 - dense_2_2_accuracy: 0.2916 - dense_2_3_accuracy: 0.5586 - dense_2_4_accuracy: 0.6985 - dense_2_5_accuracy: 0.8204 - dense_2_6_accuracy: 0.9113 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 221/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1803 - dense_2_loss: 3.4876 - dense_2_1_loss: 4.7295 - dense_2_2_loss: 4.6033 - dense_2_3_loss: 2.6225 - dense_2_4_loss: 1.4617 - dense_2_5_loss: 0.7572 - dense_2_6_loss: 0.3663 - dense_2_7_loss: 0.1556 - dense_2_accuracy: 0.2840 - dense_2_1_accuracy: 0.1723 - dense_2_2_accuracy: 0.2904 - dense_2_3_accuracy: 0.5585 - dense_2_4_accuracy: 0.6990 - dense_2_5_accuracy: 0.8204 - dense_2_6_accuracy: 0.9111 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 222/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1768 - dense_2_loss: 3.4856 - dense_2_1_loss: 4.7289 - dense_2_2_loss: 4.6030 - dense_2_3_loss: 2.6187 - dense_2_4_loss: 1.4609 - dense_2_5_loss: 0.7565 - dense_2_6_loss: 0.3663 - dense_2_7_loss: 0.1555 - dense_2_accuracy: 0.2843 - dense_2_1_accuracy: 0.1726 - dense_2_2_accuracy: 0.2922 - dense_2_3_accuracy: 0.5593 - dense_2_4_accuracy: 0.7000 - dense_2_5_accuracy: 0.8209 - dense_2_6_accuracy: 0.9106 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 223/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1738 - dense_2_loss: 3.4838 - dense_2_1_loss: 4.7274 - dense_2_2_loss: 4.6009 - dense_2_3_loss: 2.6201 - dense_2_4_loss: 1.4607 - dense_2_5_loss: 0.7564 - dense_2_6_loss: 0.3661 - dense_2_7_loss: 0.1554 - dense_2_accuracy: 0.2846 - dense_2_1_accuracy: 0.1724 - dense_2_2_accuracy: 0.2905 - dense_2_3_accuracy: 0.5587 - dense_2_4_accuracy: 0.6982 - dense_2_5_accuracy: 0.8213 - dense_2_6_accuracy: 0.9113 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 224/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1708 - dense_2_loss: 3.4833 - dense_2_1_loss: 4.7254 - dense_2_2_loss: 4.6001 - dense_2_3_loss: 2.6215 - dense_2_4_loss: 1.4623 - dense_2_5_loss: 0.7579 - dense_2_6_loss: 0.3671 - dense_2_7_loss: 0.1564 - dense_2_accuracy: 0.2842 - dense_2_1_accuracy: 0.1726 - dense_2_2_accuracy: 0.2914 - dense_2_3_accuracy: 0.5600 - dense_2_4_accuracy: 0.6997 - dense_2_5_accuracy: 0.8214 - dense_2_6_accuracy: 0.9117 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 225/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1676 - dense_2_loss: 3.4834 - dense_2_1_loss: 4.7257 - dense_2_2_loss: 4.6005 - dense_2_3_loss: 2.6188 - dense_2_4_loss: 1.4613 - dense_2_5_loss: 0.7569 - dense_2_6_loss: 0.3665 - dense_2_7_loss: 0.1554 - dense_2_accuracy: 0.2848 - dense_2_1_accuracy: 0.1728 - dense_2_2_accuracy: 0.2912 - dense_2_3_accuracy: 0.5601 - dense_2_4_accuracy: 0.6988 - dense_2_5_accuracy: 0.8215 - dense_2_6_accuracy: 0.9114 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 226/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1653 - dense_2_loss: 3.4834 - dense_2_1_loss: 4.7252 - dense_2_2_loss: 4.6011 - dense_2_3_loss: 2.6193 - dense_2_4_loss: 1.4616 - dense_2_5_loss: 0.7573 - dense_2_6_loss: 0.3666 - dense_2_7_loss: 0.1559 - dense_2_accuracy: 0.2846 - dense_2_1_accuracy: 0.1727 - dense_2_2_accuracy: 0.2916 - dense_2_3_accuracy: 0.5594 - dense_2_4_accuracy: 0.6988 - dense_2_5_accuracy: 0.8213 - dense_2_6_accuracy: 0.9111 - dense_2_7_accuracy: 0.9663\n",
            "Epoch 227/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1621 - dense_2_loss: 3.4819 - dense_2_1_loss: 4.7246 - dense_2_2_loss: 4.5988 - dense_2_3_loss: 2.6171 - dense_2_4_loss: 1.4598 - dense_2_5_loss: 0.7569 - dense_2_6_loss: 0.3665 - dense_2_7_loss: 0.1559 - dense_2_accuracy: 0.2847 - dense_2_1_accuracy: 0.1729 - dense_2_2_accuracy: 0.2913 - dense_2_3_accuracy: 0.5599 - dense_2_4_accuracy: 0.6992 - dense_2_5_accuracy: 0.8217 - dense_2_6_accuracy: 0.9110 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 228/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1596 - dense_2_loss: 3.4797 - dense_2_1_loss: 4.7225 - dense_2_2_loss: 4.5984 - dense_2_3_loss: 2.6206 - dense_2_4_loss: 1.4628 - dense_2_5_loss: 0.7578 - dense_2_6_loss: 0.3678 - dense_2_7_loss: 0.1562 - dense_2_accuracy: 0.2846 - dense_2_1_accuracy: 0.1730 - dense_2_2_accuracy: 0.2909 - dense_2_3_accuracy: 0.5595 - dense_2_4_accuracy: 0.6982 - dense_2_5_accuracy: 0.8218 - dense_2_6_accuracy: 0.9117 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 229/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.1561 - dense_2_loss: 3.4812 - dense_2_1_loss: 4.7227 - dense_2_2_loss: 4.5986 - dense_2_3_loss: 2.6166 - dense_2_4_loss: 1.4591 - dense_2_5_loss: 0.7558 - dense_2_6_loss: 0.3658 - dense_2_7_loss: 0.1554 - dense_2_accuracy: 0.2847 - dense_2_1_accuracy: 0.1725 - dense_2_2_accuracy: 0.2914 - dense_2_3_accuracy: 0.5605 - dense_2_4_accuracy: 0.6990 - dense_2_5_accuracy: 0.8210 - dense_2_6_accuracy: 0.9121 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 230/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1531 - dense_2_loss: 3.4795 - dense_2_1_loss: 4.7214 - dense_2_2_loss: 4.5965 - dense_2_3_loss: 2.6185 - dense_2_4_loss: 1.4591 - dense_2_5_loss: 0.7556 - dense_2_6_loss: 0.3659 - dense_2_7_loss: 0.1553 - dense_2_accuracy: 0.2851 - dense_2_1_accuracy: 0.1732 - dense_2_2_accuracy: 0.2907 - dense_2_3_accuracy: 0.5601 - dense_2_4_accuracy: 0.6996 - dense_2_5_accuracy: 0.8212 - dense_2_6_accuracy: 0.9121 - dense_2_7_accuracy: 0.9668\n",
            "Epoch 231/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1500 - dense_2_loss: 3.4775 - dense_2_1_loss: 4.7205 - dense_2_2_loss: 4.5960 - dense_2_3_loss: 2.6162 - dense_2_4_loss: 1.4590 - dense_2_5_loss: 0.7551 - dense_2_6_loss: 0.3657 - dense_2_7_loss: 0.1553 - dense_2_accuracy: 0.2849 - dense_2_1_accuracy: 0.1729 - dense_2_2_accuracy: 0.2914 - dense_2_3_accuracy: 0.5605 - dense_2_4_accuracy: 0.6990 - dense_2_5_accuracy: 0.8219 - dense_2_6_accuracy: 0.9119 - dense_2_7_accuracy: 0.9671\n",
            "Epoch 232/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1475 - dense_2_loss: 3.4765 - dense_2_1_loss: 4.7199 - dense_2_2_loss: 4.5973 - dense_2_3_loss: 2.6171 - dense_2_4_loss: 1.4598 - dense_2_5_loss: 0.7565 - dense_2_6_loss: 0.3656 - dense_2_7_loss: 0.1556 - dense_2_accuracy: 0.2849 - dense_2_1_accuracy: 0.1731 - dense_2_2_accuracy: 0.2913 - dense_2_3_accuracy: 0.5613 - dense_2_4_accuracy: 0.6995 - dense_2_5_accuracy: 0.8226 - dense_2_6_accuracy: 0.9120 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 233/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1449 - dense_2_loss: 3.4775 - dense_2_1_loss: 4.7204 - dense_2_2_loss: 4.5970 - dense_2_3_loss: 2.6178 - dense_2_4_loss: 1.4593 - dense_2_5_loss: 0.7566 - dense_2_6_loss: 0.3663 - dense_2_7_loss: 0.1556 - dense_2_accuracy: 0.2854 - dense_2_1_accuracy: 0.1731 - dense_2_2_accuracy: 0.2914 - dense_2_3_accuracy: 0.5606 - dense_2_4_accuracy: 0.6990 - dense_2_5_accuracy: 0.8214 - dense_2_6_accuracy: 0.9116 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 234/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1423 - dense_2_loss: 3.4770 - dense_2_1_loss: 4.7199 - dense_2_2_loss: 4.5957 - dense_2_3_loss: 2.6172 - dense_2_4_loss: 1.4593 - dense_2_5_loss: 0.7572 - dense_2_6_loss: 0.3660 - dense_2_7_loss: 0.1558 - dense_2_accuracy: 0.2850 - dense_2_1_accuracy: 0.1732 - dense_2_2_accuracy: 0.2917 - dense_2_3_accuracy: 0.5616 - dense_2_4_accuracy: 0.6989 - dense_2_5_accuracy: 0.8210 - dense_2_6_accuracy: 0.9116 - dense_2_7_accuracy: 0.9667\n",
            "Epoch 235/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1399 - dense_2_loss: 3.4758 - dense_2_1_loss: 4.7188 - dense_2_2_loss: 4.5936 - dense_2_3_loss: 2.6150 - dense_2_4_loss: 1.4583 - dense_2_5_loss: 0.7560 - dense_2_6_loss: 0.3660 - dense_2_7_loss: 0.1555 - dense_2_accuracy: 0.2851 - dense_2_1_accuracy: 0.1734 - dense_2_2_accuracy: 0.2919 - dense_2_3_accuracy: 0.5611 - dense_2_4_accuracy: 0.6986 - dense_2_5_accuracy: 0.8216 - dense_2_6_accuracy: 0.9113 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 236/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1365 - dense_2_loss: 3.4749 - dense_2_1_loss: 4.7176 - dense_2_2_loss: 4.5949 - dense_2_3_loss: 2.6177 - dense_2_4_loss: 1.4594 - dense_2_5_loss: 0.7557 - dense_2_6_loss: 0.3659 - dense_2_7_loss: 0.1554 - dense_2_accuracy: 0.2848 - dense_2_1_accuracy: 0.1733 - dense_2_2_accuracy: 0.2917 - dense_2_3_accuracy: 0.5620 - dense_2_4_accuracy: 0.6993 - dense_2_5_accuracy: 0.8215 - dense_2_6_accuracy: 0.9118 - dense_2_7_accuracy: 0.9668\n",
            "Epoch 237/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1341 - dense_2_loss: 3.4725 - dense_2_1_loss: 4.7183 - dense_2_2_loss: 4.5914 - dense_2_3_loss: 2.6157 - dense_2_4_loss: 1.4590 - dense_2_5_loss: 0.7564 - dense_2_6_loss: 0.3659 - dense_2_7_loss: 0.1556 - dense_2_accuracy: 0.2857 - dense_2_1_accuracy: 0.1736 - dense_2_2_accuracy: 0.2916 - dense_2_3_accuracy: 0.5607 - dense_2_4_accuracy: 0.6988 - dense_2_5_accuracy: 0.8218 - dense_2_6_accuracy: 0.9116 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 238/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1310 - dense_2_loss: 3.4735 - dense_2_1_loss: 4.7157 - dense_2_2_loss: 4.5923 - dense_2_3_loss: 2.6145 - dense_2_4_loss: 1.4567 - dense_2_5_loss: 0.7547 - dense_2_6_loss: 0.3654 - dense_2_7_loss: 0.1553 - dense_2_accuracy: 0.2855 - dense_2_1_accuracy: 0.1733 - dense_2_2_accuracy: 0.2910 - dense_2_3_accuracy: 0.5613 - dense_2_4_accuracy: 0.6989 - dense_2_5_accuracy: 0.8221 - dense_2_6_accuracy: 0.9114 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 239/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1284 - dense_2_loss: 3.4705 - dense_2_1_loss: 4.7141 - dense_2_2_loss: 4.5938 - dense_2_3_loss: 2.6143 - dense_2_4_loss: 1.4578 - dense_2_5_loss: 0.7555 - dense_2_6_loss: 0.3663 - dense_2_7_loss: 0.1556 - dense_2_accuracy: 0.2852 - dense_2_1_accuracy: 0.1735 - dense_2_2_accuracy: 0.2912 - dense_2_3_accuracy: 0.5605 - dense_2_4_accuracy: 0.6997 - dense_2_5_accuracy: 0.8215 - dense_2_6_accuracy: 0.9123 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 240/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1260 - dense_2_loss: 3.4697 - dense_2_1_loss: 4.7139 - dense_2_2_loss: 4.5910 - dense_2_3_loss: 2.6112 - dense_2_4_loss: 1.4563 - dense_2_5_loss: 0.7544 - dense_2_6_loss: 0.3654 - dense_2_7_loss: 0.1551 - dense_2_accuracy: 0.2859 - dense_2_1_accuracy: 0.1734 - dense_2_2_accuracy: 0.2904 - dense_2_3_accuracy: 0.5613 - dense_2_4_accuracy: 0.6991 - dense_2_5_accuracy: 0.8221 - dense_2_6_accuracy: 0.9115 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 241/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1231 - dense_2_loss: 3.4692 - dense_2_1_loss: 4.7132 - dense_2_2_loss: 4.5920 - dense_2_3_loss: 2.6137 - dense_2_4_loss: 1.4577 - dense_2_5_loss: 0.7550 - dense_2_6_loss: 0.3656 - dense_2_7_loss: 0.1553 - dense_2_accuracy: 0.2854 - dense_2_1_accuracy: 0.1736 - dense_2_2_accuracy: 0.2909 - dense_2_3_accuracy: 0.5613 - dense_2_4_accuracy: 0.7000 - dense_2_5_accuracy: 0.8229 - dense_2_6_accuracy: 0.9122 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 242/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.1208 - dense_2_loss: 3.4698 - dense_2_1_loss: 4.7124 - dense_2_2_loss: 4.5890 - dense_2_3_loss: 2.6140 - dense_2_4_loss: 1.4597 - dense_2_5_loss: 0.7561 - dense_2_6_loss: 0.3663 - dense_2_7_loss: 0.1555 - dense_2_accuracy: 0.2858 - dense_2_1_accuracy: 0.1734 - dense_2_2_accuracy: 0.2912 - dense_2_3_accuracy: 0.5621 - dense_2_4_accuracy: 0.6990 - dense_2_5_accuracy: 0.8215 - dense_2_6_accuracy: 0.9114 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 243/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.1183 - dense_2_loss: 3.4697 - dense_2_1_loss: 4.7119 - dense_2_2_loss: 4.5903 - dense_2_3_loss: 2.6125 - dense_2_4_loss: 1.4573 - dense_2_5_loss: 0.7555 - dense_2_6_loss: 0.3658 - dense_2_7_loss: 0.1556 - dense_2_accuracy: 0.2858 - dense_2_1_accuracy: 0.1733 - dense_2_2_accuracy: 0.2913 - dense_2_3_accuracy: 0.5615 - dense_2_4_accuracy: 0.7004 - dense_2_5_accuracy: 0.8219 - dense_2_6_accuracy: 0.9118 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 244/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.1147 - dense_2_loss: 3.4676 - dense_2_1_loss: 4.7113 - dense_2_2_loss: 4.5912 - dense_2_3_loss: 2.6147 - dense_2_4_loss: 1.4573 - dense_2_5_loss: 0.7548 - dense_2_6_loss: 0.3654 - dense_2_7_loss: 0.1552 - dense_2_accuracy: 0.2858 - dense_2_1_accuracy: 0.1738 - dense_2_2_accuracy: 0.2916 - dense_2_3_accuracy: 0.5619 - dense_2_4_accuracy: 0.7012 - dense_2_5_accuracy: 0.8225 - dense_2_6_accuracy: 0.9118 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 245/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1132 - dense_2_loss: 3.4665 - dense_2_1_loss: 4.7105 - dense_2_2_loss: 4.5889 - dense_2_3_loss: 2.6117 - dense_2_4_loss: 1.4567 - dense_2_5_loss: 0.7550 - dense_2_6_loss: 0.3655 - dense_2_7_loss: 0.1552 - dense_2_accuracy: 0.2861 - dense_2_1_accuracy: 0.1737 - dense_2_2_accuracy: 0.2905 - dense_2_3_accuracy: 0.5620 - dense_2_4_accuracy: 0.7002 - dense_2_5_accuracy: 0.8219 - dense_2_6_accuracy: 0.9119 - dense_2_7_accuracy: 0.9667\n",
            "Epoch 246/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.1102 - dense_2_loss: 3.4662 - dense_2_1_loss: 4.7080 - dense_2_2_loss: 4.5890 - dense_2_3_loss: 2.6104 - dense_2_4_loss: 1.4570 - dense_2_5_loss: 0.7549 - dense_2_6_loss: 0.3657 - dense_2_7_loss: 0.1557 - dense_2_accuracy: 0.2858 - dense_2_1_accuracy: 0.1734 - dense_2_2_accuracy: 0.2916 - dense_2_3_accuracy: 0.5617 - dense_2_4_accuracy: 0.6999 - dense_2_5_accuracy: 0.8217 - dense_2_6_accuracy: 0.9115 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 247/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1079 - dense_2_loss: 3.4669 - dense_2_1_loss: 4.7099 - dense_2_2_loss: 4.5866 - dense_2_3_loss: 2.6115 - dense_2_4_loss: 1.4574 - dense_2_5_loss: 0.7551 - dense_2_6_loss: 0.3659 - dense_2_7_loss: 0.1553 - dense_2_accuracy: 0.2858 - dense_2_1_accuracy: 0.1738 - dense_2_2_accuracy: 0.2907 - dense_2_3_accuracy: 0.5622 - dense_2_4_accuracy: 0.7001 - dense_2_5_accuracy: 0.8229 - dense_2_6_accuracy: 0.9118 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 248/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1051 - dense_2_loss: 3.4656 - dense_2_1_loss: 4.7090 - dense_2_2_loss: 4.5864 - dense_2_3_loss: 2.6109 - dense_2_4_loss: 1.4566 - dense_2_5_loss: 0.7542 - dense_2_6_loss: 0.3659 - dense_2_7_loss: 0.1562 - dense_2_accuracy: 0.2859 - dense_2_1_accuracy: 0.1740 - dense_2_2_accuracy: 0.2915 - dense_2_3_accuracy: 0.5624 - dense_2_4_accuracy: 0.7002 - dense_2_5_accuracy: 0.8226 - dense_2_6_accuracy: 0.9119 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 249/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1023 - dense_2_loss: 3.4641 - dense_2_1_loss: 4.7085 - dense_2_2_loss: 4.5871 - dense_2_3_loss: 2.6115 - dense_2_4_loss: 1.4560 - dense_2_5_loss: 0.7535 - dense_2_6_loss: 0.3651 - dense_2_7_loss: 0.1550 - dense_2_accuracy: 0.2858 - dense_2_1_accuracy: 0.1739 - dense_2_2_accuracy: 0.2909 - dense_2_3_accuracy: 0.5622 - dense_2_4_accuracy: 0.7000 - dense_2_5_accuracy: 0.8224 - dense_2_6_accuracy: 0.9121 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 250/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.1001 - dense_2_loss: 3.4644 - dense_2_1_loss: 4.7082 - dense_2_2_loss: 4.5865 - dense_2_3_loss: 2.6113 - dense_2_4_loss: 1.4560 - dense_2_5_loss: 0.7536 - dense_2_6_loss: 0.3650 - dense_2_7_loss: 0.1551 - dense_2_accuracy: 0.2861 - dense_2_1_accuracy: 0.1739 - dense_2_2_accuracy: 0.2909 - dense_2_3_accuracy: 0.5629 - dense_2_4_accuracy: 0.6991 - dense_2_5_accuracy: 0.8223 - dense_2_6_accuracy: 0.9121 - dense_2_7_accuracy: 0.9667\n",
            "Epoch 251/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0976 - dense_2_loss: 3.4612 - dense_2_1_loss: 4.7074 - dense_2_2_loss: 4.5859 - dense_2_3_loss: 2.6102 - dense_2_4_loss: 1.4561 - dense_2_5_loss: 0.7544 - dense_2_6_loss: 0.3654 - dense_2_7_loss: 0.1550 - dense_2_accuracy: 0.2863 - dense_2_1_accuracy: 0.1738 - dense_2_2_accuracy: 0.2914 - dense_2_3_accuracy: 0.5616 - dense_2_4_accuracy: 0.6998 - dense_2_5_accuracy: 0.8225 - dense_2_6_accuracy: 0.9118 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 252/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0960 - dense_2_loss: 3.4613 - dense_2_1_loss: 4.7055 - dense_2_2_loss: 4.5864 - dense_2_3_loss: 2.6134 - dense_2_4_loss: 1.4572 - dense_2_5_loss: 0.7542 - dense_2_6_loss: 0.3658 - dense_2_7_loss: 0.1552 - dense_2_accuracy: 0.2856 - dense_2_1_accuracy: 0.1742 - dense_2_2_accuracy: 0.2912 - dense_2_3_accuracy: 0.5624 - dense_2_4_accuracy: 0.7012 - dense_2_5_accuracy: 0.8220 - dense_2_6_accuracy: 0.9122 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 253/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.0930 - dense_2_loss: 3.4621 - dense_2_1_loss: 4.7064 - dense_2_2_loss: 4.5861 - dense_2_3_loss: 2.6115 - dense_2_4_loss: 1.4563 - dense_2_5_loss: 0.7549 - dense_2_6_loss: 0.3662 - dense_2_7_loss: 0.1557 - dense_2_accuracy: 0.2856 - dense_2_1_accuracy: 0.1741 - dense_2_2_accuracy: 0.2903 - dense_2_3_accuracy: 0.5626 - dense_2_4_accuracy: 0.7005 - dense_2_5_accuracy: 0.8227 - dense_2_6_accuracy: 0.9118 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 254/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0900 - dense_2_loss: 3.4608 - dense_2_1_loss: 4.7050 - dense_2_2_loss: 4.5851 - dense_2_3_loss: 2.6119 - dense_2_4_loss: 1.4547 - dense_2_5_loss: 0.7535 - dense_2_6_loss: 0.3648 - dense_2_7_loss: 0.1550 - dense_2_accuracy: 0.2861 - dense_2_1_accuracy: 0.1740 - dense_2_2_accuracy: 0.2909 - dense_2_3_accuracy: 0.5625 - dense_2_4_accuracy: 0.6997 - dense_2_5_accuracy: 0.8217 - dense_2_6_accuracy: 0.9123 - dense_2_7_accuracy: 0.9667\n",
            "Epoch 255/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0878 - dense_2_loss: 3.4598 - dense_2_1_loss: 4.7036 - dense_2_2_loss: 4.5848 - dense_2_3_loss: 2.6083 - dense_2_4_loss: 1.4553 - dense_2_5_loss: 0.7533 - dense_2_6_loss: 0.3650 - dense_2_7_loss: 0.1549 - dense_2_accuracy: 0.2863 - dense_2_1_accuracy: 0.1745 - dense_2_2_accuracy: 0.2919 - dense_2_3_accuracy: 0.5627 - dense_2_4_accuracy: 0.6988 - dense_2_5_accuracy: 0.8232 - dense_2_6_accuracy: 0.9118 - dense_2_7_accuracy: 0.9667\n",
            "Epoch 256/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0853 - dense_2_loss: 3.4603 - dense_2_1_loss: 4.7043 - dense_2_2_loss: 4.5831 - dense_2_3_loss: 2.6106 - dense_2_4_loss: 1.4542 - dense_2_5_loss: 0.7532 - dense_2_6_loss: 0.3648 - dense_2_7_loss: 0.1550 - dense_2_accuracy: 0.2865 - dense_2_1_accuracy: 0.1742 - dense_2_2_accuracy: 0.2908 - dense_2_3_accuracy: 0.5630 - dense_2_4_accuracy: 0.7006 - dense_2_5_accuracy: 0.8238 - dense_2_6_accuracy: 0.9118 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 257/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0826 - dense_2_loss: 3.4599 - dense_2_1_loss: 4.7028 - dense_2_2_loss: 4.5850 - dense_2_3_loss: 2.6091 - dense_2_4_loss: 1.4568 - dense_2_5_loss: 0.7535 - dense_2_6_loss: 0.3653 - dense_2_7_loss: 0.1549 - dense_2_accuracy: 0.2864 - dense_2_1_accuracy: 0.1744 - dense_2_2_accuracy: 0.2915 - dense_2_3_accuracy: 0.5631 - dense_2_4_accuracy: 0.7000 - dense_2_5_accuracy: 0.8229 - dense_2_6_accuracy: 0.9120 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 258/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0805 - dense_2_loss: 3.4591 - dense_2_1_loss: 4.7019 - dense_2_2_loss: 4.5819 - dense_2_3_loss: 2.6091 - dense_2_4_loss: 1.4553 - dense_2_5_loss: 0.7535 - dense_2_6_loss: 0.3649 - dense_2_7_loss: 0.1549 - dense_2_accuracy: 0.2864 - dense_2_1_accuracy: 0.1741 - dense_2_2_accuracy: 0.2916 - dense_2_3_accuracy: 0.5636 - dense_2_4_accuracy: 0.7001 - dense_2_5_accuracy: 0.8228 - dense_2_6_accuracy: 0.9119 - dense_2_7_accuracy: 0.9667\n",
            "Epoch 259/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0773 - dense_2_loss: 3.4566 - dense_2_1_loss: 4.7020 - dense_2_2_loss: 4.5815 - dense_2_3_loss: 2.6096 - dense_2_4_loss: 1.4558 - dense_2_5_loss: 0.7544 - dense_2_6_loss: 0.3660 - dense_2_7_loss: 0.1557 - dense_2_accuracy: 0.2870 - dense_2_1_accuracy: 0.1742 - dense_2_2_accuracy: 0.2909 - dense_2_3_accuracy: 0.5628 - dense_2_4_accuracy: 0.7004 - dense_2_5_accuracy: 0.8233 - dense_2_6_accuracy: 0.9121 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 260/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0755 - dense_2_loss: 3.4557 - dense_2_1_loss: 4.7001 - dense_2_2_loss: 4.5808 - dense_2_3_loss: 2.6066 - dense_2_4_loss: 1.4539 - dense_2_5_loss: 0.7529 - dense_2_6_loss: 0.3649 - dense_2_7_loss: 0.1549 - dense_2_accuracy: 0.2868 - dense_2_1_accuracy: 0.1740 - dense_2_2_accuracy: 0.2916 - dense_2_3_accuracy: 0.5631 - dense_2_4_accuracy: 0.7010 - dense_2_5_accuracy: 0.8241 - dense_2_6_accuracy: 0.9120 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 261/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0730 - dense_2_loss: 3.4552 - dense_2_1_loss: 4.6987 - dense_2_2_loss: 4.5822 - dense_2_3_loss: 2.6087 - dense_2_4_loss: 1.4543 - dense_2_5_loss: 0.7529 - dense_2_6_loss: 0.3647 - dense_2_7_loss: 0.1550 - dense_2_accuracy: 0.2866 - dense_2_1_accuracy: 0.1740 - dense_2_2_accuracy: 0.2909 - dense_2_3_accuracy: 0.5633 - dense_2_4_accuracy: 0.7006 - dense_2_5_accuracy: 0.8228 - dense_2_6_accuracy: 0.9124 - dense_2_7_accuracy: 0.9667\n",
            "Epoch 262/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0707 - dense_2_loss: 3.4549 - dense_2_1_loss: 4.7005 - dense_2_2_loss: 4.5798 - dense_2_3_loss: 2.6061 - dense_2_4_loss: 1.4553 - dense_2_5_loss: 0.7538 - dense_2_6_loss: 0.3649 - dense_2_7_loss: 0.1550 - dense_2_accuracy: 0.2868 - dense_2_1_accuracy: 0.1743 - dense_2_2_accuracy: 0.2907 - dense_2_3_accuracy: 0.5626 - dense_2_4_accuracy: 0.7005 - dense_2_5_accuracy: 0.8235 - dense_2_6_accuracy: 0.9121 - dense_2_7_accuracy: 0.9668\n",
            "Epoch 263/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0680 - dense_2_loss: 3.4525 - dense_2_1_loss: 4.6988 - dense_2_2_loss: 4.5820 - dense_2_3_loss: 2.6072 - dense_2_4_loss: 1.4531 - dense_2_5_loss: 0.7524 - dense_2_6_loss: 0.3645 - dense_2_7_loss: 0.1549 - dense_2_accuracy: 0.2865 - dense_2_1_accuracy: 0.1742 - dense_2_2_accuracy: 0.2913 - dense_2_3_accuracy: 0.5634 - dense_2_4_accuracy: 0.7010 - dense_2_5_accuracy: 0.8233 - dense_2_6_accuracy: 0.9120 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 264/300\n",
            "10000/10000 [==============================] - 32s 3ms/sample - loss: 18.0656 - dense_2_loss: 3.4549 - dense_2_1_loss: 4.6991 - dense_2_2_loss: 4.5819 - dense_2_3_loss: 2.6048 - dense_2_4_loss: 1.4533 - dense_2_5_loss: 0.7526 - dense_2_6_loss: 0.3647 - dense_2_7_loss: 0.1549 - dense_2_accuracy: 0.2866 - dense_2_1_accuracy: 0.1747 - dense_2_2_accuracy: 0.2907 - dense_2_3_accuracy: 0.5633 - dense_2_4_accuracy: 0.7002 - dense_2_5_accuracy: 0.8233 - dense_2_6_accuracy: 0.9120 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 265/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0640 - dense_2_loss: 3.4529 - dense_2_1_loss: 4.6967 - dense_2_2_loss: 4.5791 - dense_2_3_loss: 2.6059 - dense_2_4_loss: 1.4541 - dense_2_5_loss: 0.7537 - dense_2_6_loss: 0.3653 - dense_2_7_loss: 0.1550 - dense_2_accuracy: 0.2867 - dense_2_1_accuracy: 0.1743 - dense_2_2_accuracy: 0.2915 - dense_2_3_accuracy: 0.5639 - dense_2_4_accuracy: 0.7004 - dense_2_5_accuracy: 0.8219 - dense_2_6_accuracy: 0.9119 - dense_2_7_accuracy: 0.9668\n",
            "Epoch 266/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0609 - dense_2_loss: 3.4518 - dense_2_1_loss: 4.6973 - dense_2_2_loss: 4.5758 - dense_2_3_loss: 2.6055 - dense_2_4_loss: 1.4526 - dense_2_5_loss: 0.7524 - dense_2_6_loss: 0.3645 - dense_2_7_loss: 0.1548 - dense_2_accuracy: 0.2867 - dense_2_1_accuracy: 0.1741 - dense_2_2_accuracy: 0.2915 - dense_2_3_accuracy: 0.5633 - dense_2_4_accuracy: 0.7008 - dense_2_5_accuracy: 0.8241 - dense_2_6_accuracy: 0.9121 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 267/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0589 - dense_2_loss: 3.4515 - dense_2_1_loss: 4.6950 - dense_2_2_loss: 4.5783 - dense_2_3_loss: 2.6057 - dense_2_4_loss: 1.4549 - dense_2_5_loss: 0.7528 - dense_2_6_loss: 0.3652 - dense_2_7_loss: 0.1549 - dense_2_accuracy: 0.2872 - dense_2_1_accuracy: 0.1744 - dense_2_2_accuracy: 0.2910 - dense_2_3_accuracy: 0.5638 - dense_2_4_accuracy: 0.7010 - dense_2_5_accuracy: 0.8227 - dense_2_6_accuracy: 0.9120 - dense_2_7_accuracy: 0.9668\n",
            "Epoch 268/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0568 - dense_2_loss: 3.4522 - dense_2_1_loss: 4.6978 - dense_2_2_loss: 4.5771 - dense_2_3_loss: 2.6051 - dense_2_4_loss: 1.4523 - dense_2_5_loss: 0.7523 - dense_2_6_loss: 0.3645 - dense_2_7_loss: 0.1547 - dense_2_accuracy: 0.2866 - dense_2_1_accuracy: 0.1743 - dense_2_2_accuracy: 0.2916 - dense_2_3_accuracy: 0.5636 - dense_2_4_accuracy: 0.7005 - dense_2_5_accuracy: 0.8227 - dense_2_6_accuracy: 0.9117 - dense_2_7_accuracy: 0.9667\n",
            "Epoch 269/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0539 - dense_2_loss: 3.4490 - dense_2_1_loss: 4.6942 - dense_2_2_loss: 4.5757 - dense_2_3_loss: 2.6044 - dense_2_4_loss: 1.4534 - dense_2_5_loss: 0.7519 - dense_2_6_loss: 0.3646 - dense_2_7_loss: 0.1548 - dense_2_accuracy: 0.2869 - dense_2_1_accuracy: 0.1744 - dense_2_2_accuracy: 0.2910 - dense_2_3_accuracy: 0.5637 - dense_2_4_accuracy: 0.7011 - dense_2_5_accuracy: 0.8227 - dense_2_6_accuracy: 0.9127 - dense_2_7_accuracy: 0.9670\n",
            "Epoch 270/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0519 - dense_2_loss: 3.4490 - dense_2_1_loss: 4.6946 - dense_2_2_loss: 4.5772 - dense_2_3_loss: 2.6045 - dense_2_4_loss: 1.4529 - dense_2_5_loss: 0.7522 - dense_2_6_loss: 0.3645 - dense_2_7_loss: 0.1548 - dense_2_accuracy: 0.2870 - dense_2_1_accuracy: 0.1746 - dense_2_2_accuracy: 0.2908 - dense_2_3_accuracy: 0.5640 - dense_2_4_accuracy: 0.7007 - dense_2_5_accuracy: 0.8237 - dense_2_6_accuracy: 0.9120 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 271/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0495 - dense_2_loss: 3.4498 - dense_2_1_loss: 4.6941 - dense_2_2_loss: 4.5761 - dense_2_3_loss: 2.6048 - dense_2_4_loss: 1.4524 - dense_2_5_loss: 0.7528 - dense_2_6_loss: 0.3645 - dense_2_7_loss: 0.1549 - dense_2_accuracy: 0.2880 - dense_2_1_accuracy: 0.1744 - dense_2_2_accuracy: 0.2914 - dense_2_3_accuracy: 0.5633 - dense_2_4_accuracy: 0.7007 - dense_2_5_accuracy: 0.8238 - dense_2_6_accuracy: 0.9115 - dense_2_7_accuracy: 0.9667\n",
            "Epoch 272/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0478 - dense_2_loss: 3.4475 - dense_2_1_loss: 4.6947 - dense_2_2_loss: 4.5755 - dense_2_3_loss: 2.6047 - dense_2_4_loss: 1.4522 - dense_2_5_loss: 0.7523 - dense_2_6_loss: 0.3645 - dense_2_7_loss: 0.1548 - dense_2_accuracy: 0.2875 - dense_2_1_accuracy: 0.1745 - dense_2_2_accuracy: 0.2917 - dense_2_3_accuracy: 0.5640 - dense_2_4_accuracy: 0.7010 - dense_2_5_accuracy: 0.8237 - dense_2_6_accuracy: 0.9124 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 273/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0452 - dense_2_loss: 3.4481 - dense_2_1_loss: 4.6930 - dense_2_2_loss: 4.5746 - dense_2_3_loss: 2.6026 - dense_2_4_loss: 1.4520 - dense_2_5_loss: 0.7517 - dense_2_6_loss: 0.3644 - dense_2_7_loss: 0.1548 - dense_2_accuracy: 0.2878 - dense_2_1_accuracy: 0.1742 - dense_2_2_accuracy: 0.2913 - dense_2_3_accuracy: 0.5644 - dense_2_4_accuracy: 0.7009 - dense_2_5_accuracy: 0.8234 - dense_2_6_accuracy: 0.9120 - dense_2_7_accuracy: 0.9664\n",
            "Epoch 274/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0432 - dense_2_loss: 3.4479 - dense_2_1_loss: 4.6919 - dense_2_2_loss: 4.5757 - dense_2_3_loss: 2.6036 - dense_2_4_loss: 1.4526 - dense_2_5_loss: 0.7526 - dense_2_6_loss: 0.3645 - dense_2_7_loss: 0.1548 - dense_2_accuracy: 0.2881 - dense_2_1_accuracy: 0.1744 - dense_2_2_accuracy: 0.2915 - dense_2_3_accuracy: 0.5644 - dense_2_4_accuracy: 0.7014 - dense_2_5_accuracy: 0.8232 - dense_2_6_accuracy: 0.9119 - dense_2_7_accuracy: 0.9668\n",
            "Epoch 275/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0402 - dense_2_loss: 3.4466 - dense_2_1_loss: 4.6906 - dense_2_2_loss: 4.5739 - dense_2_3_loss: 2.6032 - dense_2_4_loss: 1.4526 - dense_2_5_loss: 0.7525 - dense_2_6_loss: 0.3655 - dense_2_7_loss: 0.1550 - dense_2_accuracy: 0.2880 - dense_2_1_accuracy: 0.1742 - dense_2_2_accuracy: 0.2913 - dense_2_3_accuracy: 0.5636 - dense_2_4_accuracy: 0.7013 - dense_2_5_accuracy: 0.8241 - dense_2_6_accuracy: 0.9119 - dense_2_7_accuracy: 0.9668\n",
            "Epoch 276/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0380 - dense_2_loss: 3.4467 - dense_2_1_loss: 4.6920 - dense_2_2_loss: 4.5721 - dense_2_3_loss: 2.6051 - dense_2_4_loss: 1.4518 - dense_2_5_loss: 0.7523 - dense_2_6_loss: 0.3647 - dense_2_7_loss: 0.1547 - dense_2_accuracy: 0.2874 - dense_2_1_accuracy: 0.1744 - dense_2_2_accuracy: 0.2917 - dense_2_3_accuracy: 0.5645 - dense_2_4_accuracy: 0.7015 - dense_2_5_accuracy: 0.8237 - dense_2_6_accuracy: 0.9125 - dense_2_7_accuracy: 0.9671\n",
            "Epoch 277/300\n",
            "10000/10000 [==============================] - 34s 3ms/sample - loss: 18.0358 - dense_2_loss: 3.4469 - dense_2_1_loss: 4.6901 - dense_2_2_loss: 4.5725 - dense_2_3_loss: 2.6020 - dense_2_4_loss: 1.4513 - dense_2_5_loss: 0.7520 - dense_2_6_loss: 0.3652 - dense_2_7_loss: 0.1551 - dense_2_accuracy: 0.2875 - dense_2_1_accuracy: 0.1745 - dense_2_2_accuracy: 0.2920 - dense_2_3_accuracy: 0.5648 - dense_2_4_accuracy: 0.7019 - dense_2_5_accuracy: 0.8233 - dense_2_6_accuracy: 0.9116 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 278/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0334 - dense_2_loss: 3.4444 - dense_2_1_loss: 4.6885 - dense_2_2_loss: 4.5724 - dense_2_3_loss: 2.6014 - dense_2_4_loss: 1.4510 - dense_2_5_loss: 0.7519 - dense_2_6_loss: 0.3645 - dense_2_7_loss: 0.1551 - dense_2_accuracy: 0.2878 - dense_2_1_accuracy: 0.1745 - dense_2_2_accuracy: 0.2925 - dense_2_3_accuracy: 0.5645 - dense_2_4_accuracy: 0.7018 - dense_2_5_accuracy: 0.8234 - dense_2_6_accuracy: 0.9120 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 279/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0315 - dense_2_loss: 3.4442 - dense_2_1_loss: 4.6896 - dense_2_2_loss: 4.5727 - dense_2_3_loss: 2.6034 - dense_2_4_loss: 1.4542 - dense_2_5_loss: 0.7520 - dense_2_6_loss: 0.3647 - dense_2_7_loss: 0.1547 - dense_2_accuracy: 0.2885 - dense_2_1_accuracy: 0.1746 - dense_2_2_accuracy: 0.2919 - dense_2_3_accuracy: 0.5649 - dense_2_4_accuracy: 0.7022 - dense_2_5_accuracy: 0.8231 - dense_2_6_accuracy: 0.9119 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 280/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0294 - dense_2_loss: 3.4441 - dense_2_1_loss: 4.6880 - dense_2_2_loss: 4.5733 - dense_2_3_loss: 2.6040 - dense_2_4_loss: 1.4512 - dense_2_5_loss: 0.7519 - dense_2_6_loss: 0.3640 - dense_2_7_loss: 0.1546 - dense_2_accuracy: 0.2880 - dense_2_1_accuracy: 0.1746 - dense_2_2_accuracy: 0.2920 - dense_2_3_accuracy: 0.5652 - dense_2_4_accuracy: 0.7024 - dense_2_5_accuracy: 0.8227 - dense_2_6_accuracy: 0.9123 - dense_2_7_accuracy: 0.9669\n",
            "Epoch 281/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0265 - dense_2_loss: 3.4427 - dense_2_1_loss: 4.6888 - dense_2_2_loss: 4.5711 - dense_2_3_loss: 2.6009 - dense_2_4_loss: 1.4511 - dense_2_5_loss: 0.7513 - dense_2_6_loss: 0.3643 - dense_2_7_loss: 0.1546 - dense_2_accuracy: 0.2884 - dense_2_1_accuracy: 0.1746 - dense_2_2_accuracy: 0.2917 - dense_2_3_accuracy: 0.5635 - dense_2_4_accuracy: 0.7016 - dense_2_5_accuracy: 0.8245 - dense_2_6_accuracy: 0.9125 - dense_2_7_accuracy: 0.9672\n",
            "Epoch 282/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0251 - dense_2_loss: 3.4430 - dense_2_1_loss: 4.6896 - dense_2_2_loss: 4.5702 - dense_2_3_loss: 2.6002 - dense_2_4_loss: 1.4506 - dense_2_5_loss: 0.7511 - dense_2_6_loss: 0.3641 - dense_2_7_loss: 0.1547 - dense_2_accuracy: 0.2874 - dense_2_1_accuracy: 0.1746 - dense_2_2_accuracy: 0.2922 - dense_2_3_accuracy: 0.5650 - dense_2_4_accuracy: 0.7017 - dense_2_5_accuracy: 0.8236 - dense_2_6_accuracy: 0.9127 - dense_2_7_accuracy: 0.9668\n",
            "Epoch 283/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0228 - dense_2_loss: 3.4422 - dense_2_1_loss: 4.6876 - dense_2_2_loss: 4.5711 - dense_2_3_loss: 2.5984 - dense_2_4_loss: 1.4502 - dense_2_5_loss: 0.7508 - dense_2_6_loss: 0.3641 - dense_2_7_loss: 0.1546 - dense_2_accuracy: 0.2884 - dense_2_1_accuracy: 0.1744 - dense_2_2_accuracy: 0.2924 - dense_2_3_accuracy: 0.5648 - dense_2_4_accuracy: 0.7017 - dense_2_5_accuracy: 0.8234 - dense_2_6_accuracy: 0.9120 - dense_2_7_accuracy: 0.9665\n",
            "Epoch 284/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0209 - dense_2_loss: 3.4397 - dense_2_1_loss: 4.6848 - dense_2_2_loss: 4.5707 - dense_2_3_loss: 2.6007 - dense_2_4_loss: 1.4509 - dense_2_5_loss: 0.7514 - dense_2_6_loss: 0.3646 - dense_2_7_loss: 0.1548 - dense_2_accuracy: 0.2883 - dense_2_1_accuracy: 0.1750 - dense_2_2_accuracy: 0.2921 - dense_2_3_accuracy: 0.5643 - dense_2_4_accuracy: 0.7013 - dense_2_5_accuracy: 0.8236 - dense_2_6_accuracy: 0.9125 - dense_2_7_accuracy: 0.9668\n",
            "Epoch 285/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0185 - dense_2_loss: 3.4402 - dense_2_1_loss: 4.6850 - dense_2_2_loss: 4.5697 - dense_2_3_loss: 2.5986 - dense_2_4_loss: 1.4511 - dense_2_5_loss: 0.7513 - dense_2_6_loss: 0.3641 - dense_2_7_loss: 0.1546 - dense_2_accuracy: 0.2881 - dense_2_1_accuracy: 0.1749 - dense_2_2_accuracy: 0.2925 - dense_2_3_accuracy: 0.5643 - dense_2_4_accuracy: 0.7024 - dense_2_5_accuracy: 0.8233 - dense_2_6_accuracy: 0.9123 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 286/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0164 - dense_2_loss: 3.4402 - dense_2_1_loss: 4.6851 - dense_2_2_loss: 4.5688 - dense_2_3_loss: 2.6000 - dense_2_4_loss: 1.4519 - dense_2_5_loss: 0.7521 - dense_2_6_loss: 0.3653 - dense_2_7_loss: 0.1550 - dense_2_accuracy: 0.2886 - dense_2_1_accuracy: 0.1746 - dense_2_2_accuracy: 0.2922 - dense_2_3_accuracy: 0.5640 - dense_2_4_accuracy: 0.7016 - dense_2_5_accuracy: 0.8233 - dense_2_6_accuracy: 0.9124 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 287/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0141 - dense_2_loss: 3.4387 - dense_2_1_loss: 4.6837 - dense_2_2_loss: 4.5682 - dense_2_3_loss: 2.6003 - dense_2_4_loss: 1.4497 - dense_2_5_loss: 0.7509 - dense_2_6_loss: 0.3638 - dense_2_7_loss: 0.1546 - dense_2_accuracy: 0.2884 - dense_2_1_accuracy: 0.1750 - dense_2_2_accuracy: 0.2919 - dense_2_3_accuracy: 0.5655 - dense_2_4_accuracy: 0.7022 - dense_2_5_accuracy: 0.8244 - dense_2_6_accuracy: 0.9124 - dense_2_7_accuracy: 0.9667\n",
            "Epoch 288/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0126 - dense_2_loss: 3.4382 - dense_2_1_loss: 4.6843 - dense_2_2_loss: 4.5691 - dense_2_3_loss: 2.6006 - dense_2_4_loss: 1.4507 - dense_2_5_loss: 0.7517 - dense_2_6_loss: 0.3648 - dense_2_7_loss: 0.1550 - dense_2_accuracy: 0.2884 - dense_2_1_accuracy: 0.1748 - dense_2_2_accuracy: 0.2919 - dense_2_3_accuracy: 0.5647 - dense_2_4_accuracy: 0.7012 - dense_2_5_accuracy: 0.8239 - dense_2_6_accuracy: 0.9122 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 289/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0097 - dense_2_loss: 3.4394 - dense_2_1_loss: 4.6841 - dense_2_2_loss: 4.5682 - dense_2_3_loss: 2.6011 - dense_2_4_loss: 1.4504 - dense_2_5_loss: 0.7515 - dense_2_6_loss: 0.3642 - dense_2_7_loss: 0.1545 - dense_2_accuracy: 0.2884 - dense_2_1_accuracy: 0.1748 - dense_2_2_accuracy: 0.2924 - dense_2_3_accuracy: 0.5649 - dense_2_4_accuracy: 0.7022 - dense_2_5_accuracy: 0.8240 - dense_2_6_accuracy: 0.9122 - dense_2_7_accuracy: 0.9667\n",
            "Epoch 290/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0081 - dense_2_loss: 3.4406 - dense_2_1_loss: 4.6838 - dense_2_2_loss: 4.5679 - dense_2_3_loss: 2.5999 - dense_2_4_loss: 1.4500 - dense_2_5_loss: 0.7505 - dense_2_6_loss: 0.3638 - dense_2_7_loss: 0.1546 - dense_2_accuracy: 0.2884 - dense_2_1_accuracy: 0.1751 - dense_2_2_accuracy: 0.2924 - dense_2_3_accuracy: 0.5643 - dense_2_4_accuracy: 0.7019 - dense_2_5_accuracy: 0.8234 - dense_2_6_accuracy: 0.9124 - dense_2_7_accuracy: 0.9669\n",
            "Epoch 291/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0055 - dense_2_loss: 3.4377 - dense_2_1_loss: 4.6833 - dense_2_2_loss: 4.5667 - dense_2_3_loss: 2.6012 - dense_2_4_loss: 1.4492 - dense_2_5_loss: 0.7513 - dense_2_6_loss: 0.3640 - dense_2_7_loss: 0.1548 - dense_2_accuracy: 0.2883 - dense_2_1_accuracy: 0.1752 - dense_2_2_accuracy: 0.2925 - dense_2_3_accuracy: 0.5642 - dense_2_4_accuracy: 0.7019 - dense_2_5_accuracy: 0.8242 - dense_2_6_accuracy: 0.9125 - dense_2_7_accuracy: 0.9668\n",
            "Epoch 292/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0037 - dense_2_loss: 3.4374 - dense_2_1_loss: 4.6826 - dense_2_2_loss: 4.5654 - dense_2_3_loss: 2.5987 - dense_2_4_loss: 1.4500 - dense_2_5_loss: 0.7506 - dense_2_6_loss: 0.3639 - dense_2_7_loss: 0.1546 - dense_2_accuracy: 0.2886 - dense_2_1_accuracy: 0.1749 - dense_2_2_accuracy: 0.2921 - dense_2_3_accuracy: 0.5651 - dense_2_4_accuracy: 0.7022 - dense_2_5_accuracy: 0.8247 - dense_2_6_accuracy: 0.9119 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 293/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 18.0022 - dense_2_loss: 3.4361 - dense_2_1_loss: 4.6808 - dense_2_2_loss: 4.5666 - dense_2_3_loss: 2.5978 - dense_2_4_loss: 1.4494 - dense_2_5_loss: 0.7503 - dense_2_6_loss: 0.3640 - dense_2_7_loss: 0.1545 - dense_2_accuracy: 0.2889 - dense_2_1_accuracy: 0.1752 - dense_2_2_accuracy: 0.2920 - dense_2_3_accuracy: 0.5640 - dense_2_4_accuracy: 0.7021 - dense_2_5_accuracy: 0.8242 - dense_2_6_accuracy: 0.9121 - dense_2_7_accuracy: 0.9667\n",
            "Epoch 294/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 17.9993 - dense_2_loss: 3.4355 - dense_2_1_loss: 4.6811 - dense_2_2_loss: 4.5662 - dense_2_3_loss: 2.6003 - dense_2_4_loss: 1.4500 - dense_2_5_loss: 0.7510 - dense_2_6_loss: 0.3644 - dense_2_7_loss: 0.1545 - dense_2_accuracy: 0.2885 - dense_2_1_accuracy: 0.1752 - dense_2_2_accuracy: 0.2924 - dense_2_3_accuracy: 0.5648 - dense_2_4_accuracy: 0.7026 - dense_2_5_accuracy: 0.8232 - dense_2_6_accuracy: 0.9123 - dense_2_7_accuracy: 0.9667\n",
            "Epoch 295/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 17.9974 - dense_2_loss: 3.4372 - dense_2_1_loss: 4.6824 - dense_2_2_loss: 4.5667 - dense_2_3_loss: 2.5972 - dense_2_4_loss: 1.4499 - dense_2_5_loss: 0.7510 - dense_2_6_loss: 0.3641 - dense_2_7_loss: 0.1549 - dense_2_accuracy: 0.2889 - dense_2_1_accuracy: 0.1756 - dense_2_2_accuracy: 0.2924 - dense_2_3_accuracy: 0.5646 - dense_2_4_accuracy: 0.7029 - dense_2_5_accuracy: 0.8242 - dense_2_6_accuracy: 0.9131 - dense_2_7_accuracy: 0.9668\n",
            "Epoch 296/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 17.9951 - dense_2_loss: 3.4335 - dense_2_1_loss: 4.6801 - dense_2_2_loss: 4.5649 - dense_2_3_loss: 2.5962 - dense_2_4_loss: 1.4509 - dense_2_5_loss: 0.7505 - dense_2_6_loss: 0.3643 - dense_2_7_loss: 0.1547 - dense_2_accuracy: 0.2885 - dense_2_1_accuracy: 0.1752 - dense_2_2_accuracy: 0.2923 - dense_2_3_accuracy: 0.5643 - dense_2_4_accuracy: 0.7027 - dense_2_5_accuracy: 0.8241 - dense_2_6_accuracy: 0.9119 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 297/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 17.9932 - dense_2_loss: 3.4343 - dense_2_1_loss: 4.6803 - dense_2_2_loss: 4.5657 - dense_2_3_loss: 2.5983 - dense_2_4_loss: 1.4489 - dense_2_5_loss: 0.7501 - dense_2_6_loss: 0.3638 - dense_2_7_loss: 0.1544 - dense_2_accuracy: 0.2886 - dense_2_1_accuracy: 0.1752 - dense_2_2_accuracy: 0.2920 - dense_2_3_accuracy: 0.5655 - dense_2_4_accuracy: 0.7027 - dense_2_5_accuracy: 0.8237 - dense_2_6_accuracy: 0.9121 - dense_2_7_accuracy: 0.9669\n",
            "Epoch 298/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 17.9914 - dense_2_loss: 3.4333 - dense_2_1_loss: 4.6774 - dense_2_2_loss: 4.5650 - dense_2_3_loss: 2.5971 - dense_2_4_loss: 1.4503 - dense_2_5_loss: 0.7504 - dense_2_6_loss: 0.3642 - dense_2_7_loss: 0.1544 - dense_2_accuracy: 0.2892 - dense_2_1_accuracy: 0.1754 - dense_2_2_accuracy: 0.2922 - dense_2_3_accuracy: 0.5655 - dense_2_4_accuracy: 0.7023 - dense_2_5_accuracy: 0.8240 - dense_2_6_accuracy: 0.9123 - dense_2_7_accuracy: 0.9666\n",
            "Epoch 299/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 17.9895 - dense_2_loss: 3.4318 - dense_2_1_loss: 4.6793 - dense_2_2_loss: 4.5643 - dense_2_3_loss: 2.5965 - dense_2_4_loss: 1.4494 - dense_2_5_loss: 0.7500 - dense_2_6_loss: 0.3639 - dense_2_7_loss: 0.1545 - dense_2_accuracy: 0.2885 - dense_2_1_accuracy: 0.1756 - dense_2_2_accuracy: 0.2925 - dense_2_3_accuracy: 0.5656 - dense_2_4_accuracy: 0.7030 - dense_2_5_accuracy: 0.8241 - dense_2_6_accuracy: 0.9119 - dense_2_7_accuracy: 0.9667\n",
            "Epoch 300/300\n",
            "10000/10000 [==============================] - 33s 3ms/sample - loss: 17.9872 - dense_2_loss: 3.4314 - dense_2_1_loss: 4.6779 - dense_2_2_loss: 4.5636 - dense_2_3_loss: 2.5975 - dense_2_4_loss: 1.4505 - dense_2_5_loss: 0.7508 - dense_2_6_loss: 0.3639 - dense_2_7_loss: 0.1548 - dense_2_accuracy: 0.2890 - dense_2_1_accuracy: 0.1757 - dense_2_2_accuracy: 0.2928 - dense_2_3_accuracy: 0.5651 - dense_2_4_accuracy: 0.7028 - dense_2_5_accuracy: 0.8238 - dense_2_6_accuracy: 0.9119 - dense_2_7_accuracy: 0.9667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f28a35f4a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEkz_vLGOhqs",
        "outputId": "8f19cb84-275a-4980-9102-2a6944a85274"
      },
      "source": [
        "sentences=[\"who?\"]\n",
        "def convert_to_input(sentences):\n",
        "    out=[]\n",
        "    for s in sentences:\n",
        "        l=s.lower().split(\" \")\n",
        "        end_mark=l[-1][-1]\n",
        "        l[-1]=l[-1][:-1]\n",
        "        l.append(end_mark)\n",
        "\n",
        "        out.append([src_vocab[w] for w in l])\n",
        "    out = [truncate_pad(i, num_steps=8, padding_token=src_vocab['pad']) for i in out]\n",
        "    return out\n",
        "X_test=tf.one_hot(convert_to_input(sentences),depth=len(src_vocab),axis=-1)\n",
        "s00=np.zeros((1,n_s))\n",
        "c00=np.zeros((1,n_s))\n",
        "y=model.predict([X_test,s00,c00])\n",
        "print(tgt_vocab.token_to_idx)\n",
        "y=np.array(y).swapaxes(0,1)\n",
        "print(y.shape)\n",
        "pred=np.argmax(y,axis=-1)\n",
        "print(pred)\n",
        "print(\" \".join([tgt_vocab.idx_to_token[i] for i in pred[0]]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<unk>': 0, '<pad>': 1, '<bos>': 2, '<eos>': 3, '.': 4, 'je': 5, '!': 6, '?': 7, 'suis': 8, 'nous': 9, 'pas': 10, 'il': 11, 'vous': 12, 'tom': 13, \"c'est\": 14, 'ne': 15, \"j'ai\": 16, 'de': 17, 'est': 18, 'le': 19, 'me': 20, 'un': 21, 'en': 22, 'tu': 23, 'à': 24, 'la': 25, 'ça': 26, 'les': 27, 'a': 28, 'sommes': 29, 'une': 30, 'êtes': 31, 'est-ce': 32, 'elle': 33, 'qui': 34, 'es': 35, ',': 36, 'que': 37, 'sont': 38, 'fait': 39, 'ils': 40, 'êtes-vous': 41, 'bien': 42, 'elles': 43, 'soyez': 44, 'y': 45, 'des': 46, 'faut': 47, 'été': 48, 'ce': 49, 'besoin': 50, 'te': 51, 'aller': 52, 'ici': 53, 'du': 54, 'ai': 55, 'va': 56, 'sois': 57, \"l'ai\": 58, 'avons': 59, 'moi': 60, \"j'aime\": 61, 'train': 62, \"n'est\": 63, 'tout': 64, 'es-tu': 65, \"l'air\": 66, 'partir': 67, \"j'étais\": 68, 'mon': 69, 'fais': 70, 'veux': 71, 'sens': 72, 'ont': 73, 'peux': 74, 'se': 75, 'puis-je': 76, 'toi': 77, 'on': 78, \"m'a\": 79, 'au': 80, \"j'adore\": 81, 'cela': 82, 'est-il': 83, \"c'était\": 84, 'personne': 85, 'mal': 86, 'maintenant': 87, \"m'en\": 88, 'déteste': 89, 'faire': 90, 'ceci': 91, 'vu': 92, 'vais': 93, \"l'a\": 94, 'trop': 95, 'ma': 96, 'voir': 97, 'arrête': 98, \"j'en\": 99, 'dois': 100, 'maison': 101, 'là': 102, 'chez': 103, 'as': 104, 'tous': 105, \"n'ai\": 106, 'très': 107, 'dans': 108, 'faites': 109, 'était': 110, 'bon': 111, 'prends': 112, 'lui': 113, 'viens': 114, 'si': 115, 'dit': 116, 'toutes': 117, 'porte': 118, 'avez': 119, 'reste': 120, 'ton': 121, \"s'il\": 122, \"d'un\": 123, 'votre': 124, 'juste': 125, 'tomber': 126, 'plus': 127, 'malade': 128, \"s'est\": 129, 'ai-je': 130, 'eu': 131, 'restez': 132, 'prenez': 133, 'plaît': 134, 'heureux': 135, \"d'une\": 136, 'comme': 137, 'nouveau': 138, 'laissez-moi': 139, 'comment': 140, 'perdu': 141, 'seul': 142, 'tellement': 143, 'avec': 144, 'venez': 145, 'quelle': 146, 'voiture': 147, 'chercher': 148, 'sécurité': 149, 'confiance': 150, 'laisse-moi': 151, 'quel': 152, \"j'y\": 153, 'prie': 154, 'arrêtez': 155, \"t'es\": 156, 'terminé': 157, 'chien': 158, 'non': 159, 'suis-je': 160, 'occupé': 161, \"t'ai\": 162, 'prêt': 163, 'temps': 164, 'j’ai': 165, 'sais': 166, 'allez': 167, 'pouvons': 168, 'pour': 169, 'bonne': 170, 'nager': 171, 'blessé': 172, 'grand': 173, 'gagné': 174, \"n'en\": 175, \"j'irai\": 176, 'rien': 177, 'travail': 178, 'regarde': 179, \"qu'est-ce\": 180, 'pris': 181, 'fatigué': 182, 'sait': 183, 'sommes-nous': 184, \"s'agit\": 185, \"s'en\": 186, 'où': 187, 'avez-vous': 188, 'beaucoup': 189, 'yeux': 190, 'bizarre': 191, 'travailler': 192, 'tranquille': 193, 'tort': 194, 'senti': 195, 'a-t-il': 196, 'fini': 197, 'sûr': 198, 'venir': 199, 'dispose': 200, 'calme': 201, 'triste': 202, 'boulot': 203, 'retard': 204, \"d'accord\": 205, 'lit': 206, 'vie': 207, 'fou': 208, 'main': 209, 'faim': 210, 'heureuse': 211, 'livre': 212, 'tes': 213, 'gros': 214, 'idée': 215, 'continue': 216, 'occupée': 217, 'mes': 218, 'seule': 219, 'entrer': 220, 'coup': 221, 'mourir': 222, 'vite': 223, 'as-tu': 224, \"quelqu'un\": 225, \"t'en\": 226, 'timide': 227, 'froid': 228, 'attention': 229, 'parle': 230, 'mort': 231, 'vieux': 232, 'courir': 233, 'raison': 234, 'dur': 235, 'regardez': 236, \"n'y\": 237, 'manger': 238, 'marcher': 239, \"l'amour\": 240, 'blague': 241, 'pourquoi': 242, 'peut': 243, 'continuez': 244, 'gentil': 245, 'laisse': 246, 'laissé': 247, 'essayer': 248, 'pouvons-nous': 249, 'voici': 250, 'avoir': 251, 'parler': 252, 'colère': 253, 'prête': 254, 'aider': 255, 'deux': 256, 'fais-le': 257, 'peur': 258, 'jamais': 259, 'serai': 260, 'veut': 261, 'merci': 262, 'vraiment': 263, 'vrai': 264, 'tard': 265, 'essaie': 266, 'quoi': 267, 'chance': 268, 'voilà': 269, 'chaud': 270, 'mien': 271, 'dis': 272, 'prudente': 273, 'monde': 274, 'lire': 275, 'sentis': 276, 'mieux': 277, 'simplement': 278, 'pleurer': 279, 'idiot': 280, 'dormir': 281, 'attends': 282, 'essayé': 283, 'ferme': 284, 'avance': 285, 'riche': 286, 'fort': 287, 'faites-le': 288, 'vue': 289, 'saoul': 290, 'prudent': 291, 'cassé': 292, 'chanter': 293, 'mange': 294, 'connais': 295, \"l'intérieur\": 296, 'pouvez': 297, 'bière': 298, 'aime': 299, \"l'argent\": 300, 'sont-ils': 301, 'avait': 302, 'parti': 303, 'peu': 304, 'trouve': 305, 'paresseux': 306, 'marche': 307, 'chiens': 308, 'chat': 309, 'sérieux': 310, 'vis': 311, 'vois': 312, 'folle': 313, 'premier': 314, 'mauvais': 315, 'vin': 316, 'attendre': 317, 'sentie': 318, \"j'apprécie\": 319, 'aimé': 320, 'oui': 321, 'tôt': 322, 'drôle': 323, 'garçon': 324, 'gagner': 325, \"l'as-tu\": 326, 'également': 327, 'allé': 328, 'contrarié': 329, \"n'a\": 330, 'appelé': 331, 'arme': 332, \"s'agit-il\": 333, 'facile': 334, 'vos': 335, 'sans': 336, 'aucune': 337, \"l'avons\": 338, 'demande': 339, 'pars': 340, 'debout': 341, 'homme': 342, 'faible': 343, \"m'y\": 344, 'venu': 345, 'mis': 346, 'désolé': 347, 'marché': 348, 'sommeil': 349, 'sur': 350, 'occupées': 351, 'pouvez-vous': 352, 'mangé': 353, \"l'avez-vous\": 354, 'jeune': 355, 'contrariée': 356, 'enfants': 357, 'davantage': 358, 'naïf': 359, 'super': 360, 'sont-elles': 361, 'peux-tu': 362, 'verre': 363, 'prendre': 364, 'semblez': 365, 'cette': 366, 'attendez': 367, 'emporté': 368, 'bras': 369, 'sors': 370, 'pue': 371, 'signe': 372, 'tête': 373, 'c’est': 374, 'assieds-toi': 375, 'essayez': 376, 'attrape': 377, 'reviens': 378, 'mienne': 379, 'lis': 380, 'encore': 381, 'trouvé': 382, 'devenu': 383, 'sortir': 384, 'voulons': 385, 'prêts': 386, 'prêtes': 387, 'arrêter': 388, 'place': 389, \"qu'il\": 390, 'naïve': 391, 'travaille': 392, 'sympa': 393, \"l'école\": 394, 'hurler': 395, 'fallait': 396, 'chambre': 397, \"l'aide\": 398, 'santé': 399, 'payé': 400, 'gentille': 401, 'entrez': 402, 'pleuré': 403, 'aussi': 404, 'ouvre': 405, 'libre': 406, 'marrant': 407, 'réveillé': 408, 'ferai': 409, 'aveugle': 410, 'nourriture': 411, \"l'heure\": 412, 'quiconque': 413, 'assez': 414, 'thé': 415, 'payer': 416, 'occupés': 417, 'soit': 418, 'sais-tu': 419, 'endormi': 420, 'demandé': 421, 'dire': 422, 'chats': 423, 'mary': 424, 'dessus': 425, 'soif': 426, 'pourrait': 427, \"l'ont\": 428, 'tour': 429, 'blessée': 430, 'avais': 431, 'laissée': 432, 'ceux-ci': 433, 'flics': 434, 'par': 435, 'étions': 436, 'fermez': 437, 'plan': 438, 'feu': 439, 'compris': 440, 'partie': 441, 'ans': 442, 'laissez': 443, 'laisse-le': 444, 'tiens': 445, 'parfait': 446, 'aide': 447, 'parlé': 448, 'content': 449, 'grande': 450, 'joue': 451, 'ivre': 452, 'mentir': 453, 'désolée': 454, 'heures': 455, 'et': 456, 'problème': 457, 'apporte': 458, 'rester': 459, 'hommes': 460, 'vieille': 461, 'souviens': 462, 'perdre': 463, 'faux': 464, 'fois': 465, 'âge': 466, 'rendu': 467, 'fatiguée': 468, 'enfant': 469, 'honte': 470, 'savoir': 471, 'déjeuner': 472, 'carte': 473, 'devrais-je': 474, 'dingue': 475, 'filles': 476, 'regarder': 477, 'coupable': 478, 'mesure': 479, 'ta': 480, 'dieu': 481, 'fut': 482, 'manque': 483, 'fallut': 484, 'lacet': 485, 'sembles': 486, \"n'êtes\": 487, 'semble': 488, \"m'ont\": 489, 'bonjour': 490, 'essaye': 491, 'détendu': 492, 'entre': 493, 'laissa': 494, 'savons': 495, 'appelle': 496, 'beau': 497, 'sourd': 498, 'certain': 499, 'sûre': 500, 'neuf': 501, 'allons-y': 502, 'asseyez-vous': 503, 'génial': 504, 'menti': 505, 'ment': 506, 'après': 507, \"l'ai-je\": 508, 'énervé': 509, 'trente': 510, 'ainsi': 511, 'réussi': 512, 'préparé': 513, 'héros': 514, 'normal': 515, 'vôtre': 516, 'bus': 517, 'seconde': 518, 'devons': 519, 'allons': 520, 'riches': 521, 'savez-vous': 522, \"j'arrive\": 523, 'fâché': 524, 'gagne': 525, 'souvent': 526, \"j'avais\": 527, 'étais': 528, 'amoureuse': 529, 'doit': 530, 'chanson': 531, 'veuillez': 532, \"m'aider\": 533, 'médecin': 534, 'vient': 535, 'pied': 536, 'moment': 537, 'fis': 538, 'bois': 539, 'stupide': 540, 'musique': 541, 'entendu': 542, 'manqué': 543, 'justice': 544, 'fumer': 545, 'ri': 546, \"aujourd'hui\": 547, \"t'a\": 548, 'chose': 549, 'adore': 550, 'fils': 551, 'café': 552, 'invité': 553, 'ouvrez': 554, 'paix': 555, \"n'es\": 556, 'combien': 557, 'entendre': 558, 'salut': 559, 'laissez-le': 560, 'sortez': 561, 'conduis': 562, 'promis': 563, 'forme': 564, 'mignon': 565, 'sorti': 566, 'échoué': 567, 'aidé': 568, 'détendue': 569, 'rapide': 570, 'partit': 571, 'attrapez': 572, 'touche': 573, 'oublie': 574, 'abandonné': 575, 'propre': 576, 'difficile': 577, 'télé': 578, 'simple': 579, 'garde': 580, 'derrière': 581, 'miens': 582, 'cuisine': 583, \"n'importe\": 584, 'avons-nous': 585, 'chante': 586, 'sentais': 587, \"l'aime\": 588, 'rappelle': 589, 'fus': 590, 'menteur': 591, 'forte': 592, 'compte': 593, 'petit': 594, 'voté': 595, \"l'as\": 596, 'idiote': 597, 'peut-il': 598, 'souris': 599, 'aux': 600, 'danser': 601, 'attrapé': 602, 'fruits': 603, 'commencé': 604, 'poisson': 605, 'lait': 606, 'devrais': 607, 'crédule': 608, 'régime': 609, 'conduire': 610, 'amoureux': 611, 'jalouse': 612, 'marié': 613, 'service': 614, 'bourré': 615, 'est-elle': 616, \"t'aider\": 617, 'liste': 618, 'réveillée': 619, 'bonnes': 620, 'joindre': 621, 'dehors': 622, 'donne-moi': 623, 'laissés': 624, 'laissées': 625, 'horreur': 626, 'crois': 627, 'plaisir': 628, 'vérifier': 629, 'clé': 630, 'celles-ci': 631, 'procès': 632, 'patron': 633, \"n'était\": 634, 'notre': 635, 'tirer': 636, 'heureuses': 637, 'dîner': 638, 'bu': 639, 'cesser': 640, 'français': 641, 'accord': 642, \"n'est-ce\": 643, 'chaussure': 644, 'étais-tu': 645, 'étiez-vous': 646, 'quand': 647, 'photo': 648, \"t'ai-je\": 649, 'veulent': 650, 'cours': 651, 'suffit': 652, 'vas-y': 653, 'possible': 654, 'fous': 655, 'rentre': 656, 'tenez': 657, 'court': 658, 'bouge': 659, 'quittez': 660, 'câlin': 661, 'grosse': 662, 'détends-toi': 663, 'joli': 664, 'sortie': 665, 'oublié': 666, 'téléphoné': 667, 'resté': 668, 'chauve': 669, 'clair': 670, 'paresseuse': 671, 'fonctionne': 672, 'sien': 673, 'sienne': 674, 'rendre': 675, 'revenez': 676, 'meurs': 677, 'mens': 678, 'emploi': 679, 'serais': 680, 'vivant': 681, 'tourne': 682, 'dure': 683, 'grave': 684, 'sent': 685, 'gratuit': 686, 'nôtre': 687, 'baissé': 688, 'soin': 689, 'miennes': 690, 'souri': 691, 'vas': 692, 'vérifie': 693, 'seuls': 694, 'seules': 695, \"l'extérieur\": 696, 'pauvre': 697, 'tiens-toi': 698, 'tenez-vous': 699, 'cuisiner': 700, \"t'aime\": 701, 'apprécié': 702, 'riz': 703, 'rencontrés': 704, 'perdue': 705, 'écrit': 706, 'honnête': 707, 'célibataire': 708, 'nuit': 709, 'tien': 710, \"d'essayer\": 711, 'dites': 712, 'près': 713, \"l'emporter\": 714, 'retour': 715, 'faibles': 716, \"qu'est\": 717, 'raisonnable': 718, 'donner': 719, 'avant': 720, 'méchant': 721, \"m'aime\": 722, 'type': 723, 'plaisante': 724, 'arriver': 725, 'parviens': 726, 'nez': 727, 'sauvé': 728, 'sauvée': 729, 'sauvés': 730, 'rends': 731, 'œufs': 732, 'égoïste': 733, 'discuter': 734, 'faisons': 735, 'mercis': 736, 'cool': 737, 'eue': 738, 'changé': 739, 'thomas': 740, 'refusé': 741, 'lentement': 742, 'était-ce': 743, 'équipe': 744, 'triché': 745, 'sûres': 746, 'demander': 747, \"d'argent\": 748, 'toujours': 749, 'réparer': 750, 'largué': 751, 'plans': 752, 'donné': 753, \"l'eau\": 754, 'endormie': 755, 'reviendrai': 756, 'drogué': 757, 'affaire': 758, 'pieds': 759, 'cruel': 760, 'apeuré': 761, 'pourrions': 762, 'avions': 763, \"n'avons\": 764, 'femme': 765, 'chef': 766, 'talent': 767, 'contente': 768, \"n'abandonne\": 769, 'pousse': 770, 'mangez': 771, 'quelque': 772, 'affaires': 773, 'donnez-moi': 774, 'arrêté': 775, 'rêve': 776, 'jouer': 777, 'boston': 778, 'conclu': 779, 'résister': 780, 'bateau': 781, 'malchanceux': 782, 'ses': 783, 'sera': 784, 'complètement': 785, 'contact': 786, 'verrouille': 787, 'noue': 788, \"jusqu'à\": 789, 'étaient': 790, 'plaisantes': 791, 'plaisantez': 792, 'connaissez-vous': 793, 'connais-tu': 794, \"d'elle\": 795, 'grimpe': 796, 'camionnette': 797, 'chapeau': 798, 'parole': 799, 'jaloux': 800, 'oh': 801, 'monte': 802, 'montez': 803, 'tombé': 804, 'aucun': 805, 'manière': 806, 'calmes': 807, 'dégage': 808, 'même': 809, 'tenue': 810, 'gras': 811, 'touché': 812, 'mouillé': 813, 'joignez-vous': 814, 'réveille-toi': 815, 'fûmes': 816, 'bienvenue': 817, 'reculez': 818, 'appelez': 819, 'rouler': 820, 'trouvez': 821, 'descends': 822, 'descendez': 823, 'passe': 824, 'mecs': 825, 'fais-moi': 826, 'regardé': 827, 'obéi': 828, 'l’ai': 829, 'sourde': 830, 'fainéant': 831, 'mince': 832, 'laid': 833, 'laisse-nous': 834, 'parlez': 835, 'pleure': 836, 'oubliez': 837, 'cessez': 838, 'va-t-il': 839, 'skier': 840, 'mouvement': 841, 'mise': 842, 'amusé': 843, 'amusée': 844, 'vues': 845, 'vus': 846, 'sac': 847, 'soûl': 848, 'tire': 849, 'veinard': 850, 'veinarde': 851, 'chanceux': 852, 'nu': 853, 'nue': 854, 'loin': 855, 'fonctionné': 856, 'sombre': 857, 'gardez': 858, 'immobile': 859, 'pleurait': 860, 'pleura': 861, 'signez': 862, 'soucie': 863, 'commencez': 864, 'engagé': 865, 'trompe': 866, 'levé': 867, 'demandez': 868, 'prudents': 869, 'prudentes': 870, 'satisfait': 871, 'apportez': 872, 'rendez-vous': 873, 'plein': 874, 'dépêchez-vous': 875, 'crevé': 876, 'annulé': 877, 'souci': 878, 'envie': 879, 'suppose': 880, 'rencontrées': 881, 'paie': 882, 'connu': 883, 'cache': 884, 'maigrichon': 885, 'maigrichonne': 886, 'sournois': 887, 'danger': 888, 'passé': 889, 'silencieux': 890, 'maman': 891, '«': 892, '»': 893, 'commence': 894, \"l'abri\": 895, 'amusant': 896, \"t'avons\": 897, 'perdus': 898, 'perdues': 899, 'impitoyable': 900, 'commencer': 901, 'ski': 902, 'boîte': 903, 'œil': 904, 'mec': 905, 'curieux': 906, 'brûlé': 907, 'attrapée': 908, 'pourrais': 909, 'rendue': 910, 'vertiges': 911, 'fâchée': 912, 'liquide': 913, 'j’aime': 914, 'apprécie': 915, 'merdé': 916, \"l'emporte\": 917, 'soupe': 918, 'trouvais': 919, 'viré': 920, 'tenterai': 921, 'patient': 922, 'sincère': 923, 'sale': 924, 'peut-être': 925, 'commençons': 926, 'mille': 927, 'vint': 928, 'plait': 929, 'pommes': 930, 'bain': 931, 'exact': 932, 'impoli': 933, 'quitté': 934, 'écoute': 935, 'guerre': 936, 'garçons': 937, 'aimons': 938, 'fauchés': 939, 'jumeaux': 940, 'cinglé': 941, 'dommage': 942, 'ailles': 943, 'libres': 944, 'bons': 945, 'route': 946, 'blessés': 947, 'blessées': 948, 'sûrs': 949, 'immédiatement': 950, 'baisse': 951, 'beignet': 952, 'stylo': 953, 'excuses': 954, 'facilement': 955, 'fille': 956, 'affreusement': 957, 'pari': 958, 'prévenue': 959, 'poursuivrai': 960, 'divorcé': 961, 'meilleur': 962, 'patronne': 963, 'vérité': 964, 'faisait': 965, 'injuste': 966, 'noir': 967, 'défaut': 968, 'neige': 969, 'chemin': 970, 'partons': 971, 'marie': 972, 'nos': 973, 'fit': 974, 'cesse': 975, 'pause': 976, 'fera': 977, 'détendus': 978, 'détendues': 979, 'là-bas': 980, 'volé': 981, 'célèbre': 982, 'incroyable': 983, 'savions': 984, \"d'aide\": 985, 'devrions': 986, 'devez': 987, 'matinal': 988, 'matinale': 989, 'idiots': 990, 'morts': 991, 'chic': 992, 'poissons': 993, 'bouchon': 994, 'poussez': 995, 'nourris': 996, 'matériel': 997, 'bénisse': 998, 'adorable': 999, 'déjà': 1000, 'acheter': 1001, 'chienne': 1002, \"l'aise\": 1003, 'dû': 1004, 'fallu': 1005, \"l'hiver\": 1006, 'cinéma': 1007, 'perdis': 1008, 'clef': 1009, 'objection': 1010, 'semaine': 1011, 'cheval': 1012, 'courus': 1013, 'dormi': 1014, 'malchanceuse': 1015, \"d'y\": 1016, 'artiste': 1017, 'fuite': 1018, 'être': 1019, 'verrouillez': 1020, \"qu'elle\": 1021, 'voix': 1022, 'vanter': 1023, 'droit': 1024, 'attache': 1025, 'espoir': 1026, 'tiré': 1027, 'trouver': 1028, 'répondre': 1029, 'toucher': 1030, 'demain': 1031, 'changer': 1032, 'désormais': 1033, 'droite': 1034, 'seulement': 1035, 'décider': 1036, 'portes': 1037, 'découvert': 1038, 'laissèrent': 1039, 'précis': 1040, 'félicitations': 1041, 'saute': 1042, 'comprends': 1043, 'allez-y': 1044, \"t'as\": 1045, 'serre-moi': 1046, 'tombée': 1047, 'cas': 1048, 'hors': 1049, 'question': 1050, 'équitable': 1051, \"d'ici\": 1052, 'doucement': 1053, 'aide-moi': 1054, 'fume': 1055, 'ronfle': 1056, 'tenté': 1057, 'touchée': 1058, 'lavez-vous': 1059, 'battus': 1060, 'recule\\u2009': 1061, 'avancez': 1062, 'ailleurs': 1063, 'réaliste': 1064, 'joué': 1065, 'amuse-toi': 1066, 'chouette': 1067, 'rire': 1068, 'dépêche-toi': 1069, 'paierai': 1070, 'rigolo': 1071, 'rouge': 1072, 'laissez-nous': 1073, 'sauve': 1074, 'morte': 1075, 'gagnèrent': 1076, 'savait': 1077, \"qu'on\": 1078, 'oiseaux': 1079, 'bientôt': 1080, 'oublie-le': 1081, 'affreux': 1082, 'langue': 1083, 'frappé': 1084, 'savais': 1085, 'remarqué': 1086, 'retraite': 1087, 'crié': 1088, 'éveillé': 1089, \"j'attendrai\": 1090, 'travaillerai': 1091, 'flic': 1092, 'armé': 1093, 'tatillon': 1094, 'tatillonne': 1095, 'j’y': 1096, 'poil': 1097, 'ouvert': 1098, 'sable': 1099, 'lâche-moi': 1100, 'tombés': 1101, 'partis': 1102, 'heure': 1103, 'magnifique': 1104, 'écrivez': 1105, 'espèce': 1106, 'bord': 1107, 'engagée': 1108, 'satisfaite': 1109, 'sérieuse': 1110, 'chantez': 1111, 'devoir': 1112, 'suivez': 1113, 'intelligent': 1114, 'hais': 1115, \"l'art\": 1116, 'confectionné': 1117, 'glace': 1118, 'couru': 1119, 'survécu': 1120, \"n'étais\": 1121, 'dernière': 1122, 'resterai': 1123, 'jumeau': 1124, 'connue': 1125, 'alité': 1126, 'alitée': 1127, 'rigole': 1128, 'déménager': 1129, 'normale': 1130, 'sournoise': 1131, 'bleu': 1132, 'important': 1133, 'terrible': 1134, 'proche': 1135, 'cd': 1136, 'détendez-vous': 1137, 'tranquilles': 1138, 'travaillons': 1139, 'relaxe': 1140, \"t'inquiète\": 1141, 'jambes': 1142, ':': 1143, 'malin': 1144, 'siens': 1145, 'conduit': 1146, 'mourons': 1147, 'journée': 1148, 'grands': 1149, 'grandes': 1150, 'marrante': 1151, 'vieilles': 1152, 'créative': 1153, 'créatif': 1154, 'ponctuelle': 1155, 'ponctuel': 1156, 'compter': 1157, 'nombre': 1158, 'souriez': 1159, 'pièce': 1160, 'jette': 1161, 'jetez': 1162, 'devint': 1163, 'arrive': 1164, \"d'arriver\": 1165, 'allons-nous': 1166, 'allée': 1167, 'pain': 1168, 'déprimé': 1169, 'prise': 1170, 'golf': 1171, 'aimée': 1172, 'foiré': 1173, 'pagaille': 1174, 'obéir': 1175, 'remis': 1176, 'sauvées': 1177, 'vends': 1178, 'fie': 1179, 'licencié': 1180, 'troisième': 1181, 'excité': 1182, 'diète': 1183, 'mariée': 1184, 'piégée': 1185, 'piégé': 1186, 'légal': 1187, 'arrivé': 1188, 'long': 1189, 'règle': 1190, 'arnaque': 1191, 'bête': 1192, 'faisons-le': 1193, \"s'y\": 1194, 'choisissez': 1195, 'choisis': 1196, 'revoir': 1197, 'réveille': 1198, 'renard': 1199, 'embrassés': 1200, 'transpiré': 1201, 'connaît': 1202, 'fauchées': 1203, 'désolés': 1204, 'fatigués': 1205, 'fatiguées': 1206, 'étais-je': 1207, 'grossier': 1208, 'sauf': 1209, 'coupé': 1210, 'eut': 1211, 'actuellement': 1212, 'hé': 1213, 'bouger': 1214, 'incapable': 1215, 'pouvais': 1216, 'mérite': 1217, 'effet': 1218, \"m'est\": 1219, 'égal': 1220, 'chatte': 1221, 'preuve': 1222, \"d'être\": 1223, 'sucre': 1224, 'femmes': 1225, 'dépêcher': 1226, 'preuves': 1227, \"d'eau\": 1228, 'perds': 1229, 'lion': 1230, 'chaussures': 1231, \"j'enseigne\": 1232, 'esseulé': 1233, 'esseulée': 1234, 'prévenu': 1235, 'joindrai': 1236, 'canadien': 1237, 'ouïe': 1238, 'dix-huit': 1239, 'paris': 1240, 'innocent': 1241, 'saint': 1242, 'méchante': 1243, 'enceinte': 1244, 'fiable': 1245, 'épuisé': 1246, 'environs': 1247, 'chiqué': 1248, 'rumeur': 1249, 'loi': 1250, 'écrire': 1251, \"d'abord\": 1252, 'devine': 1253, 'viande': 1254, 'cochons': 1255, 'dois-je': 1256, 'font': 1257, 'buvez': 1258, 'mensonge': 1259, 'connaissent': 1260, 'meurt': 1261, 'réveil': 1262, 'point': 1263, 'essayons': 1264, 'étiez': 1265, 'mentez': 1266, 'rêver': 1267, 'mortes': 1268, 'respectueuse': 1269, 'respectueux': 1270, \"j'aimerais\": 1271, 'nettoyez': 1272, 'capable': 1273, \"s'est-il\": 1274, 'peuvent': 1275, 'savent': 1276, 'impolie': 1277, 'cercle': 1278, 'petits': 1279, \"l'oiseau\": 1280, 'cheveux': 1281, 'trompé': 1282, 'ignoré': 1283, 'voleur': 1284, 'tué': 1285, 'lapidé': 1286, 'américain': 1287, 'japonais': 1288, 'diabétique': 1289, 'expliquer': 1290, 'méprise': 1291, 'boire': 1292, 'nourri': 1293, \"j'arrête\": 1294, 'jumelle': 1295, 'jogging': 1296, \"l'automne\": 1297, 'dépasse': 1298, 'possède': 1299, 'respecte': 1300, \"l'avais\": 1301, 'voulais': 1302, 'droguée': 1303, 'invitée': 1304, 'domicile': 1305, 'prendrai': 1306, 'touriste': 1307, 'toute': 1308, 'belle': 1309, 'fourbu': 1310, 'leurs': 1311, 'assuré': 1312, 'fuit': 1313, 'cadeau': 1314, \"c'en\": 1315, \"l'étage\": 1316, 'minute': 1317, 'restons': 1318, 'là-haut': 1319, 'nom': 1320, 'vit': 1321, 'française': 1322, 'mannequin': 1323, 'clairement': 1324, 'arrivent': 1325, 'voulait': 1326, 'astucieux': 1327, 'aiment': 1328, 'folles': 1329, 'sucré': 1330, 'nouez': 1331, 'sentit': 1332, 'son': 1333, 'ennuyeux': 1334, 'ville': 1335, 'effrayant': 1336, 'instant': 1337, 'six': 1338, 'surveille': 1339, 'auparavant': 1340, 'médecins': 1341, 'jalouses': 1342, 'couler': 1343, \"qu'ai-je\": 1344, 'recruté': 1345, 'recrutée': 1346, 'volant': 1347, 'menteuse': 1348, 'malins': 1349, 'fric': 1350, 'jolie': 1351, 'embrasser': 1352, \"m'asseoir\": 1353, 'changement': 1354, 'vaches': 1355, \"l'a-t-il\": 1356, \"m'entendez-vous\": 1357, 'aimes': 1358, 'contrariées': 1359, 'contrariés': 1360, 'quitte': 1361, 'pêcher': 1362, 'grimpez': 1363, \"l'appareil\": 1364, 'année': 1365, 'paralysé': 1366, 'coûte': 1367, 'apporté': 1368, 'capte': 1369, 'suivi': 1370, 'hoquet': 1371, \"d'aucune\": 1372, 'biscuits': 1373, 'fleurs': 1374, 'causer': 1375, 'voyage': 1376, 'plutôt': 1377, 'fonctionnait': 1378, 'déplacement': 1379, 'prix': 1380, 'réserve-moi': 1381, 'détruit': 1382, 'volontaires': 1383, 'cravate': 1384, 'chinois': 1385, \"n'aie\": 1386, \"n'ayez\": 1387, 'courez': 1388, 'stop': 1389, 'arrête-toi': 1390, 'poursuis': 1391, \"j'essaye\": 1392, 'lève-toi': 1393, 'pigé': 1394, 'capté': 1395, 'serrez-moi': 1396, 'écoutez': 1397, 'façons': 1398, 'fantastique': 1399, 'justes': 1400, 'appelle-moi': 1401, 'foutre': 1402, 'allez-vous': 1403, 'rentrez': 1404, 'aidez-moi': 1405, 'tenu': 1406, 'garde-le': 1407, 'ferme-la': 1408, 'dis-moi': 1409, 'dites-moi': 1410, 'réveillez-vous': 1411, 'lave-toi': 1412, 'battues': 1413, 'défaits': 1414, 'défaites': 1415, 'répare': 1416, 'lâche-toi': 1417, 'attrapez-le': 1418, 'profondeur': 1419, 'agréable': 1420, 'refuse': 1421, 'reposé': 1422, 'reposée': 1423, \"j'essaierai\": 1424, 'revenu': 1425, 'claire': 1426, 'disponible': 1427, 'rassasié': 1428, 'fainéante': 1429, 'laide': 1430, 'donc': 1431, 'venue': 1432, 'dis-le': 1433, 'faites-moi': 1434, 'effort': 1435, 'regarde-moi': 1436, 'irons': 1437, 'volent': 1438, 'calmez-vous': 1439, 'calme-toi': 1440, 'aboient': 1441, 'excuse-moi': 1442, 'excusez-moi': 1443, 'sentez': 1444, 'touchez': 1445, 'oubliez-le': 1446, 'prépare-toi': 1447, 'préparez-vous': 1448, 'dj': 1449, 'sexy': 1450, \"j'eus\": 1451, 'recul': 1452, 'rentré': 1453, 'moi-même': 1454, 'donne': 1455, 'marré': 1456, 'marrée': 1457, \"j'espère\": 1458, 'aille': 1459, \"j'aiderai\": 1460, \"j'obéirai\": 1461, 'passerai': 1462, 'marcherai': 1463, 'armée': 1464, 'fauché': 1465, 'chanceuse': 1466, 'sobre': 1467, 'coincée': 1468, 'cuire': 1469, 'neigé': 1470, 'correct': 1471, 'ok': 1472, 'huit': 1473, 'lâchez-moi': 1474, 'allongé': 1475, 'allongée': 1476, 'immobiles': 1477, 'pardon': 1478, 'voyez': 1479, 'ci-dessous': 1480, 'arrière': 1481, 'reculez\\u2009': 1482, 'tombées': 1483, 'parties': 1484, 'nageaient': 1485, 'nagèrent': 1486, 'écoulé': 1487, 'timides': 1488, 'ira': 1489, 'conduisez': 1490, 'mettez': 1491, 'levée': 1492, 'alentour': 1493, 'gaffe': 1494, 'satisfaits': 1495, 'satisfaites': 1496, 'sérieuses': 1497, 'vérifiez': 1498, 'choisis-en': 1499, 'creuse': 1500, 'tracasse': 1501, 'tracassez': 1502, 'bougez': 1503, \"m'appelle\": 1504, 'faits': 1505, 'face': 1506, \"l'évidence\": 1507, 'ruiné': 1508, 'vers': 1509, 'nord': 1510, 'charmant': 1511, \"d'aller\": 1512, 'cassée': 1513, 'construit': 1514, 'construite': 1515, 'sauter': 1516, 'doute': 1517, \"l'envie\": 1518, 'ressenti': 1519, 'réparai': 1520, 'devenue': 1521, \"j'imagine\": 1522, \"l'apprécie\": 1523, 'plais': 1524, \"j'adorais\": 1525, 'épaules': 1526, \"j'utilise\": 1527, 'dernier': 1528, 'tirerai': 1529, 'grassouillet': 1530, 'remué': 1531, 'remuée': 1532, \"j'essaie\": 1533, 'décédé': 1534, 'inoffensif': 1535, 'fonctionnera': 1536, 'marchera': 1537, 'pipeau': 1538, 'tienne': 1539, 'jésus': 1540, 'permettez-moi': 1541, 'discutons': 1542, 'sauve-toi': 1543, 'sauvez-vous': 1544, 'cou': 1545, 'gardes': 1546, 'écarte-toi': 1547, 'écartez-vous': 1548, 'étudie': 1549, 'application': 1550, 'notes': 1551, 'parle-moi': 1552, 'parlez-moi': 1553, 'goûte': 1554, 'goûtez': 1555, 'trichent': 1556, 'triche': 1557, 'boit': 1558, 'regarda': 1559, 'obéit': 1560, 'peint': 1561, 'paiera': 1562, 'achetons': 1563, \"l'apprécions\": 1564, 'réussirons': 1565, 'quittes': 1566, 'foutu': 1567, \"l'avez\": 1568, 'voulez': 1569, 'discret': 1570, 'discrète': 1571, 'amicale': 1572, 'amical': 1573, 'clément': 1574, 'clémente': 1575, 'miséricordieuse': 1576, 'miséricordieux': 1577, 'ponctuelles': 1578, 'ponctuels': 1579, 'impitoyables': 1580, 'raisonnables': 1581, 'vous-même': 1582, 'arrives-tu': 1583, 'arrivez-vous': 1584, 'péter': 1585, 'char': 1586, 'battez': 1587, 'tirez': 1588, 'crie': 1589, 'fumez': 1590, 'finis': 1591, 'finissez': 1592, 'lance': 1593, 'pardonne': 1594, 'siège': 1595, 'tripes': 1596, 'mit': 1597, 'binoclard': 1598, 'flemmard': 1599, 'pété': 1600, 'vas-tu': 1601, 'cuisinier': 1602, 'moine': 1603, 'acheté': 1604, 'brûlée': 1605, 'puis': 1606, 'confessé': 1607, 'séché': 1608, 'désaccord': 1609, 'amende': 1610, 'prune': 1611, 'contravention': 1612, 'contredanse': 1613, 'nouvelles': 1614, 'hésité': 1615, 'gâteaux': 1616, 'rock': 1617, \"j'habite\": 1618, 'cacher': 1619, 'cloué': 1620, 'skie': 1621, 'remise': 1622, 'voitures': 1623, 'tournait': 1624, 'saqué': 1625, 'ému': 1626, 'lavée': 1627, 'viendrai': 1628, 'crierai': 1629, 'déciderai': 1630, 'toubib': 1631, 'perplexe': 1632, 'foies': 1633, 'curieuse': 1634, 'excitée': 1635, 'tombe': 1636, 'furieux': 1637, 'nerveux': 1638, 'nerveuse': 1639, 'patiente': 1640, 'remonté': 1641, 'voyant': 1642, 'voyante': 1643, 'retraité': 1644, 'bourrée': 1645, 'taquine': 1646, 'désarmé': 1647, 'emporter': 1648, 'briser': 1649, 'casser': 1650, 'lundi': 1651, 'poupée': 1652, 'verrouillé': 1653, 'secret': 1654, 'urgent': 1655, 'dépêchons-nous': 1656, 'amusante': 1657, 'autour': 1658, 'souhait': 1659, 'pile': 1660, 'moins': 1661, 'd’accord': 1662, 'date': 1663, 'plantes': 1664, 'remets-le': 1665, \"l'écart\": 1666, 'bouchée': 1667, 'minable': 1668, 'noyé': 1669, 'lent': 1670, 'rit': 1671, 'm’a': 1672, 'viendra': 1673, 'démissionner': 1674, 'mourant': 1675, 'reposer': 1676, 'demi-tour': 1677, 'mauvaise': 1678, 'avais-je': 1679, 'démissionnons': 1680, 'arrêtons': 1681, 'rencontrer': 1682, 'agir': 1683, 'souvenons': 1684, 'combattrons': 1685, 'armés': 1686, 'armées': 1687, 'intelligents': 1688, 'intelligentes': 1689, 'désolées': 1690, 'jumelles': 1691, 'naze': 1692, 'bordel': 1693, \"qu'y\": 1694, 'échappé': 1695, \"t'y\": 1696, 'travaillez': 1697, 'asseoir': 1698, \"m'avez\": 1699, 'givré': 1700, 'givrée': 1701, 'grossière': 1702, 'conduis-toi': 1703, 'comporte-toi': 1704, 'attentif': 1705, 'attentive': 1706, 'confiant': 1707, 'confiante': 1708, 'bœuf': 1709, 'amène': 1710, 'finir': 1711, 'savez': 1712, 'rejoindre': 1713, 'pourrions-nous': 1714, 'chanté': 1715, 'fumes': 1716, 'enseignante': 1717, 'fait-il': 1718, 'malheureux': 1719, 'dérange': 1720, 'levez': 1721, 'résiste': 1722, 'prudemment': 1723, 'lâche': 1724, \"l'arme\": 1725, 'fusil': 1726, 'carabine': 1727, 'fantômes': 1728, 'jouez': 1729, 'boisson': 1730, 'en-cas': 1731, 'autre': 1732, \"m'évite\": 1733, 'meure': 1734, 'poète': 1735, 'donna': 1736, 'brave': 1737, 'courageux': 1738, 'devrait': 1739, 'souffre': 1740, 'embêtant': 1741, 'appelés': 1742, 'appelées': 1743, 'appelée': 1744, 'impatient': 1745, 'impatiente': 1746, 'effectué': 1747, 'malaise': 1748, 'larguée': 1749, 'doutes': 1750, 'su': 1751, \"j'entends\": 1752, \"j'élève\": 1753, 'échecs': 1754, 'miel': 1755, 'livres': 1756, 'blagues': 1757, 'projets': 1758, \"m'as\": 1759, 'taxi': 1760, 'peinture': 1761, 'nage': 1762, 'compatis': 1763, 'forces': 1764, 'ceux-là': 1765, 'tendu': 1766, 'piège': 1767, 'reprises': 1768, 'demanderai': 1769, 'tuerai': 1770, '99%': 1771, 'canadienne': 1772, 'agriculteur': 1773, 'ami': 1774, 'génie': 1775, 'membre': 1776, 'accro': 1777, 'assuétude': 1778, 'mélange': 1779, 'divorcée': 1780, 'noyer': 1781, 'affamé': 1782, 'bats': 1783, 'reconnaissant': 1784, 'pays': 1785, 'innocente': 1786, 'ingénu': 1787, 'ingénue': 1788, 'erreur': 1789, 'offensé': 1790, 'offensée': 1791, 'indigné': 1792, 'puissant': 1793, 'las': 1794, 'meilleure': 1795, 'affairé': 1796, 'affairée': 1797, 'au-dessus': 1798, 'cerf': 1799, 'loup': 1800, 'brisé': 1801, 'cancer': 1802, 'blanc': 1803, 'lieu': 1804, 'malédiction': 1805, 'gaspillage': 1806, 'véritable': 1807, 'hideux': 1808, 'évident': 1809, 'contrôler': 1810, 'attentivement': 1811, 'mignonne': 1812, \"l'essayer\": 1813, 'égoïstes': 1814, 'continuer': 1815, 'bougé': 1816, 'vide': 1817, 'videz': 1818, \"l'apprécia\": 1819, 'viendra-t-elle': 1820, 'tira': 1821, 'devrions-nous': 1822, 'disputer': 1823, 'quereller': 1824, 'fixer': 1825, 'râler': 1826, 'beaux': 1827, 'rêves': 1828, \"l'affaire\": 1829, 'approuvent': 1830, 'abandonnèrent': 1831, 'détestent': 1832, 'dirent': 1833, 'grandiront': 1834, 'mignons': 1835, 'choses': 1836, 'effrayé': 1837, 'défoncé': 1838, 'stone': 1839, 'utilise-les': 1840, 'utilisez-les': 1841, 'veux-tu': 1842, \"l'espoir\": 1843, 'repos': 1844, 'mourrons': 1845, 'préjugés': 1846, 'venons': 1847, 'sortons': 1848, 'ensemble': 1849, 'condamnés': 1850, 'plaisantons': 1851, 'perdons': 1852, 'sournoises': 1853, 'forts': 1854, 'fortes': 1855, 'bienvenu': 1856, 'raté': 1857, 'envoyé': 1858, 'envoyée': 1859, 'disparu': 1860, 'écris': 1861, 'cruelle': 1862, 'cruels': 1863, 'saoule': 1864, 'saouls': 1865, 'saoules': 1866, 'manières': 1867, 'naïfs': 1868, 'naïves': 1869, 'planté': 1870, 'plantée': 1871, 'bizarres': 1872, 'jeunes': 1873, \"n'est-il\": 1874, 'futon': 1875, 'doté': 1876, 'questions': 1877, 'lancer': 1878, 'patiner': 1879, 'note': 1880, 'serais-je': 1881, 'criminalité': 1882, 'danse': 1883, 'faveur': 1884, 'captes': 1885, 'captez': 1886, 'vois-tu': 1887, 'mesquin': 1888, 'mesquine': 1889, 'deviens': 1890, 'égard': 1891, 'trace': 1892, 'pois': 1893, 'manteau': 1894, 'donne-le-moi': 1895, 'accroche-toi': 1896, 'accrochez-vous': 1897, 'biscuit': 1898, 'jambon': 1899, 'trou': 1900, \"l'enlaça\": 1901, 'anglais': 1902, 'genre': 1903, 'aima': 1904, 'apprécia': 1905, 'pâle': 1906, 'vend': 1907, 'arnaqué': 1908, 'arnaquée': 1909, 'rapidement': 1910, 'ancien': 1911, 'tokyo': 1912, \"d'étudier\": 1913, 'saignait': 1914, 'corde': 1915, 'excitant': 1916, 'presque': 1917, 'musulman': 1918, 'acquérir': 1919, 'ressentir': 1920, 'causé': 1921, 'contribué': 1922, 'mérité': 1923, 'part': 1924, 'crains': 1925, 'cœur': 1926, 'renaître': 1927, 'apeurée': 1928, 'obtenu': 1929, 'moindre': 1930, \"n'avais\": 1931, 'voler': 1932, 'visa': 1933, 'claque': 1934, 'droits': 1935, 'raconte': 1936, 'craques': 1937, 'gens': 1938, 'chameaux': 1939, 'printemps': 1940, 'proximité': 1941, 'coin': 1942, \"l'été\": 1943, 'copie': 1944, 'insister': 1945, 'émettre': 1946, 'formuler': 1947, 'refuser': 1948, 'préséance': 1949, 'priorité': 1950, 'quant': 1951, 'abandonner': 1952, 'fumée': 1953, 'pense': 1954, 't’ai': 1955, 'porté': 1956, 'volontaire': 1957, 'piscine': 1958, 'écrasé': 1959, 'excursion': 1960, 'entré': 1961, 'réveillées': 1962, 'réveillés': 1963, 'brève': 1964, 'appellerai': 1965, 'manquer': 1966, 'sauverai': 1967, 'dirai': 1968, 'étudiant': 1969, 'professeur': 1970, 'vivre': 1971, 'épuisée': 1972, 'vanné': 1973, 'vannée': 1974, 'événement': 1975, 'admirateurs': 1976, 'vote': 1977, \"d'yeux\": 1978, 'douloureux': 1979, 'plaisanterie': 1980, 'présente': 1981, 'logique': 1982, 'rend': 1983, 'prend': 1984, 'bombe': 1985, 'épidémie': 1986, 'soulagement': 1987, 'location': 1988, 'dépassé': 1989, 'vol': 1990, 'sec': 1991, 'bas': 1992, 'laisse-la': 1993, 'fiez-vous': 1994, 'apprends': 1995, 'laissez-la': 1996, 'laissons': 1997, 'choix': 1998, 'offre': 1999, 'rends-moi': 2000, 'rendez-moi': 2001, 'coffre': 2002, 'lisez': 2003, 'cloche': 2004, 'scellez': 2005, 'scelle': 2006, 'plaqué': 2007, 'hait': 2008, 'embauché': 2009, 'paraît': 2010, 'côté': 2011, 'crier': 2012, 'nettoyer': 2013, 'numéro': 2014, 'douche': 2015, 'mythe': 2016, 'risque': 2017, 'savaient': 2018, 'trouvèrent': 2019, 'trouvés': 2020, 'trouvées': 2021, 'asiatiques': 2022, 'propres': 2023, 'mentent': 2024, 'japon': 2025, 'dvd': 2026, 'mots': 2027, 'attachez': 2028, 'sentait': 2029, 'coincé': 2030, 'bagages': 2031, 'valises': 2032, 'gâteau': 2033, 'page': 2034, 'changeons': 2035, 'règles': 2036, 'voulions': 2037, 'perplexes': 2038, 'amis': 2039, 'amies': 2040, 'amoureuses': 2041, 'veinards': 2042, 'veinardes': 2043, 'bourrés': 2044, 'bourrées': 2045, 'piégés': 2046, 'piégées': 2047, 'malchanceuses': 2048, 'inutiles': 2049, \"d'attendre\": 2050, 'arrivés': 2051, 'poisse': 2052, \"qu'en\": 2053, 'étions-nous': 2054, 'courrier': 2055, 'amour': 2056, 'snob': 2057, 'célébrité': 2058, 'brillant': 2059, 'brillante': 2060, 'maline': 2061, 'rusé': 2062, 'rusée': 2063, 'astucieuse': 2064, 'sinistre': 2065, 'avide': 2066, 'bougon': 2067, 'bougonne': 2068, 'grognon': 2069, 'endormis': 2070, 'endormies': 2071, 'sens-tu': 2072, 'sentez-vous': 2073, \"n'avez-vous\": 2074, 'appareil': 2075, 'offre-moi': 2076, 'offrez-moi': 2077, 'plombier': 2078, 'annuler': 2079, 'jongler': 2080, 'balle': 2081, \"t'ennuie\": 2082, 'ennuie': 2083, 'plaira': 2084, \"m'aimes\": 2085, 'recyclage': 2086, 'salace': 2087, 'lève': 2088, 'tentez': 2089, 'match': 2090, 'spectacle': 2091, 'donne-le-lui': 2092, 'bisou': 2093, 'retourne': 2094, 'promenade': 2095, 'passe-moi': 2096, 'vacances': 2097, 'failli': 2098, 'l’a': 2099, 'lèvre': 2100, 'poste': 2101, 'vidéo': 2102, 'détestait': 2103, 'visage': 2104, 'visible': 2105, 'joueur': 2106, 'auteur': 2107, 'prison': 2108, 'taille': 2109, 'passe-t-il': 2110, 'endroit': 2111, 'cru': 2112, 'crue': 2113, 'vélo': 2114, \"t'entendre\": 2115, 'prouver': 2116, 'honteux': 2117, 'honoré': 2118, 'honorée': 2119, 'inutile': 2120, 'trahie': 2121, 'trompée': 2122, 'trahi': 2123, 'énervée': 2124, 'suivie': 2125, 'arrêtée': 2126, 'nausée': 2127, 'repasser': 2128, 'fêtes': 2129, 'secrets': 2130, 'dépourvu': 2131, 'sœurs': 2132, 'pique-niques': 2133, 'énigmes': 2134, 'allumé': 2135, 'kobe': 2136, 'contrôle': 2137, 'soleil': 2138, 'rencontré': 2139, 'nostalgie': 2140, 'soulever': 2141, 'protestation': 2142, 'augmentation': 2143, 'réponses': 2144, 'fermer': 2145, \"j'étudie\": 2146, 'reprends': 2147, 'leur': 2148, 'haut': 2149, 'guiderai': 2150, 'chargerai': 2151, \"j'aurai\": 2152, 'fierai': 2153, 'vire': 2154, \"m'amuse\": 2155, 'suffisamment': 2156, \"l'un\": 2157, 'habitué': 2158, 'là-dedans': 2159, 'tient': 2160, 'mercredi': 2161, 'miracle': 2162, 'dangereux': 2163, 'dépend': 2164, \"n'as\": 2165, \"qu'à\": 2166, \"l'ignorer\": 2167, \"n'avez\": 2168, 'soyons': 2169, 'rentrons': 2170, 'nombreux': 2171, 'mouillés': 2172, 'prie\\u2009': 2173, 'augmenté': 2174, 'pousser': 2175, 'roses': 2176, 'bach': 2177, 'attend': 2178, 'famille': 2179, 'montre-le-lui\\u2009': 2180, 'esprits': 2181, 'mêle': 2182, 'mêlez': 2183, 'absurde': 2184, 'bébé': 2185, 'adorent': 2186, 'burent': 2187, \"s'ennuient\": 2188, 'truc': 2189, 'démasqué': 2190, 'disposent': 2191, 'viennent': 2192, 'puent': 2193, 'morflé': 2194, 'positivement': 2195, 'mord': 2196, 'dé': 2197, 'lacets': 2198, \"m'arrêter\": 2199, 'acclamèrent': 2200, 'rîmes': 2201, 'arrêtions': 2202, 'cessions': 2203, 'invités': 2204, 'échapper': 2205, 'serons': 2206, 'bravo': 2207, 'fais-tu': 2208, 'faites-vous': 2209, 'essuie-toi': 2210, 'intelligente': 2211, 'passera': 2212, 'puritain': 2213, 'puritaine': 2214, 'voleuse': 2215, 'marrer': 2216, 'géniale': 2217, 'insensible': 2218, 'insaisissable': 2219, 'imprudent': 2220, 'imprudente': 2221, 'professionnel': 2222, 'gagnes': 2223, 'boissons': 2224, 'gratuites': 2225, 'vôtres': 2226, 'fantôme': 2227, 'habillé': 2228, 'habillée': 2229, 'envieux': 2230, 'envieuse': 2231, \"n'es-tu\": 2232, \"n'êtes-vous\": 2233, 'demande-moi': 2234, 'dents': 2235, 'bouillir': 2236, 'police': 2237, 'peuvent-ils': 2238, 'peuvent-elles': 2239, 'montrer': 2240, 'lâcher': 2241, 'nettoie': 2242, 'trappe': 2243, 'débarqué': 2244, 'manges-tu': 2245, 'mangez-vous': 2246, 'massage': 2247, 'cardiaque': 2248, 'connaissez': 2249, 'souvenez': 2250, 'penses-tu': 2251}\n",
            "(1, 8, 2252)\n",
            "[[14 18  0  0  7  7  3  1]]\n",
            "c'est est <unk> <unk> ? ? <eos> <pad>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "723x3IAEgZAW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}